<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>《END-TO-END ACCENT CONVERSION WITHOUT USING NATIVE UTTERANCES》论文总结</title>
    <url>/2020/08/17/0817-%E7%BB%84%E4%BC%9A%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200816133725.png" alt="image-20200816133724321"></p>
<p>展示demo：<a href="https://liusongxiang.github.io/end2endAC/" target="_blank" rel="noopener">https://liusongxiang.github.io/end2endAC/</a></p>
<a id="more"></a>

<ul>
<li>是在 VC 之上，再做的进一步 口音修正：</li>
<li>source 语音在带有口音（e.g. 咖喱味的英语）的前提下，做VC，但是 我们除了想要 target 的身份，还要 <strong>目标说话人口音</strong>（e.g. 纯正的母语英语）</li>
<li>所提到的整个网络模型，综合了 TTS 、VC、ASR 的方法，也有一种采众家之长的意思，但是麻烦的是，四个模型部分，需要分别训练</li>
</ul>
<hr>
<h2 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h2><ol>
<li>传统的口音转换：<ol>
<li>内容（content）、发音（pronounciation） 不变</li>
<li>把 本地source说话人 的口音（accent），转换成 非本地target说话人 的口音</li>
</ol>
</li>
<li>本文尝试source非母语：北印度人说的英语口音—&gt;北美正统英语口音</li>
<li>传统的局限：做转换时，需要具备的条件：<ol>
<li>需要有 印度人说的英语 作为source</li>
<li>需要有美国人说的英语作为 target</li>
<li>这导致了，在实际上也用途时，很臃肿难用</li>
</ol>
</li>
<li>本文想法：<ol>
<li>在转换阶段，提出 端到端 方法，使得不需要 美国人英语target 也能做正确的 AC （accent conversion）</li>
</ol>
</li>
<li>贡献点：<ol>
<li>说是目前为止第一家实现在 转换阶段 不需要目标（美国target英语语音）就能实现转换的方案</li>
<li>细化实现了对 <strong>韵律特征</strong> 的建模：（例如说话速度和持续时间）</li>
<li>non-parallel</li>
</ol>
</li>
</ol>
<hr>
<h2 id="网络结构：（四部分）"><a href="#网络结构：（四部分）" class="headerlink" title="网络结构：（四部分）"></a>网络结构：（四部分）</h2><ol>
<li>a speaker encoder</li>
<li>a multi-speaker TTS model</li>
<li>an accented ASR model</li>
<li>a neural vocoder</li>
</ol>
<hr>
<ol>
<li>encoder 部分作用：生成speaker-embedding</li>
<li>TTS 部分 用的是tacotron2（音素 + embedding 预测 mel）</li>
<li></li>
</ol>
<hr>
<h2 id="Speaker-encoder"><a href="#Speaker-encoder" class="headerlink" title="Speaker encoder"></a>Speaker encoder</h2><ol>
<li>引用的模型：<img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200816222235.png" alt="image-20200816222233997"></li>
<li>作用是：生成 <strong>speaker-embedding</strong>，用来和 TTS 结合，保证了生成语音 和 target 说话人 身份一致（类似VC和TTS结合？）</li>
<li>GE2E（generalized end-to-end）speaker veriﬁcation loss</li>
<li><strong>Baseline训练过程</strong>：</li>
<li><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200817111542.png" alt="image-20200817111540876"></li>
<li><strong>训练阶段训练两个转换模型</strong>：（DTW）<ol>
<li>Trans 1 : 将 <strong>印度英语</strong> 的ppg 和 <strong>美式英语</strong> 的ppg 利用 DTW 做对齐</li>
<li>Trans 2 ：将 <strong>印度英语</strong> 的 ppg 和 mel谱 做对应匹配</li>
<li>转换阶段：<ol>
<li>输入 <strong>印度英语</strong>到 Trans1</li>
<li>得到 <strong>美式英语</strong>ppg</li>
<li>将ppg 继续送入 Trans2，得到对应的 mel谱</li>
<li>用wave-Net 生成语音波形</li>
</ol>
</li>
</ol>
</li>
</ol>
<hr>
<h2 id="Multi-speaker-TTS-model-amp-amp-Multi-task-accented-ASR-model"><a href="#Multi-speaker-TTS-model-amp-amp-Multi-task-accented-ASR-model" class="headerlink" title="Multi-speaker TTS model  &amp;&amp;  Multi-task accented ASR model"></a>Multi-speaker TTS model  &amp;&amp;  Multi-task accented ASR model</h2><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200817114458.png" alt="image-20200817114456342"></p>
<ol>
<li>其中的TTS网络，摘用的这篇：（<strong>attention-based</strong> encoder-decoder model）<img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200817114716.png" alt="image-20200817114714573"></li>
<li><strong>text transcripts</strong> into <strong>phoneme sequences</strong>：TTS 中用phone 序列，加速收敛过程；</li>
</ol>
<h3 id="口音识别：Multi-task-accented-ASR-model"><a href="#口音识别：Multi-task-accented-ASR-model" class="headerlink" title="口音识别：Multi-task accented ASR model"></a>口音识别：Multi-task accented ASR model</h3><p>训练思路：</p>
<ol>
<li>前面有，用单说话人（美式英语）训练好的 <strong>speaker encoder</strong></li>
<li>接着有 用全部都是（美式英语）训练的 多说话人 <strong>TTS</strong> <strong>模型</strong>（TTS-loss）</li>
<li>在上面两个步骤基础上，本环节 用多个 <strong>美式英语</strong> &amp;&amp; 一个 <strong>印度英语</strong> 一起进行 <strong>多说话人</strong> 预训练</li>
<li>完成之后，再 <strong>全部</strong> 换成 <strong>印度口音英语多说话人</strong> 进行调整</li>
</ol>
<p>实践中的细节：</p>
<ol>
<li><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200817143548.png" alt="image-20200817143546689">)<img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200817143604.png" alt="image-20200817143601305"></li>
<li><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200817143645.png" alt="image-20200817140608795"></li>
</ol>
<p><strong>结构上</strong>：</p>
<ul>
<li>E2E attentioned encoder-decoder 结构：如上图（引用以前的文章思路）</li>
</ul>
<p><strong>改进 1 ：</strong></p>
<ul>
<li>为了增加 <strong>训练稳定性</strong>，参考了文献：<img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200817144039.png" alt="image-20200817144038371"></li>
<li>在 Encoder 之前，增加了一个 <strong>全连接</strong>，并增加了一个 <strong>CTC loss</strong></li>
</ul>
<p><strong>改进 2 ：</strong></p>
<ul>
<li><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200817144505.png" alt="image-20200817144503756"></li>
<li>在口音问题的思路上， 借鉴这篇论文：</li>
<li>在送给 ASR 之前，<strong>每帧</strong> 都concate上一个 <strong>accent embedding</strong>（这是由第一个步骤 <strong>speaker encoder</strong> 里面产生的 <strong>speaker-embedding</strong> 做一个 对单人所有语音的embedding整体均值 的结果）</li>
<li>并且在ASR的encoder最开始，再增加一个 <strong>accent classifier 口音分类器</strong>（上一步已经加过一次 FC 了）；这也能使面对口音时，有更好的健壮性</li>
</ul>
<hr>
<h2 id="🌟-Loss-环节"><a href="#🌟-Loss-环节" class="headerlink" title="🌟 Loss 环节"></a>🌟 Loss 环节</h2><ul>
<li><p>λ 1= <strong>0.5</strong>, λ 2= 0.1, λ 3= <strong>0.5</strong> and λ 4= 0.1</p>
</li>
<li><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200817145536.png" alt="image-20200817145535742"></p>
</li>
<li><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200817145554.png" alt="image-20200817145553156"></p>
</li>
</ul>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200817145627.png" alt="image-20200817145626236"></p>
<ol>
<li><strong>TTSE-loss</strong>：<strong>MSE损失</strong>，对象是：1⃣️上一步已训好的 TTS 产生的声学序列（美式英语） &amp;&amp; ASR识别出的声学序列 做一个 <strong>均方差损失</strong></li>
<li><strong>CE-loss</strong>：phoneme label prediction （phone音素 的标签预测损失）</li>
<li><strong>ACC-loss</strong>：口音分类器的损失（类似stargan-vc里面的 speaker-classifier）</li>
</ol>
<hr>
<h2 id="4-后端声码器"><a href="#4-后端声码器" class="headerlink" title="4. 后端声码器"></a>4. 后端声码器</h2><ul>
<li>本文直接采用开源的 <a href="https://github.com/fatchord/WaveRNN" target="_blank" rel="noopener">WaveRNN</a> </li>
<li>没有额外加任何的embedding信息，觉得说 mel频谱已经能包含所有需要的声学细节了</li>
<li>语料：全部采用 <strong>美式英语</strong> 数据来训</li>
</ul>
<hr>
<h2 id="5-转换阶段"><a href="#5-转换阶段" class="headerlink" title="5. 转换阶段"></a>5. 转换阶段</h2><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200817153318.png" alt="image-20200817153317898"></p>
<ol>
<li>hs：一段语音，经过 speaker-encoder之后得到的 speaker-embedding</li>
<li>accent-embedding：针对同一个人的所有语音，做所有的 <strong>speaker-embedding</strong>的 <strong>均值</strong>（多个语音理解为多个通道计算）</li>
<li>（Accent embedding is the averaged speaker embeddings of the non-native-accented speaker.）</li>
<li>注：accnet-embedding 是 <strong>逐帧都要插入</strong>，speaker-embedding 是最后再concate上</li>
</ol>
<hr>
<h2 id="一些实现参数细节"><a href="#一些实现参数细节" class="headerlink" title="一些实现参数细节"></a>一些实现参数细节</h2><p>5.1部分（不复赘述）</p>
<hr>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>（笑容满面实验，是去掉 <strong>accent embedding</strong> 和 <strong>accent classiﬁer</strong>）</p>
<ul>
<li><p>MOS得分很高</p>
</li>
<li><p>相似性上，比baseline差很多（作者猜测是数据量还是不够大的缘故）</p>
</li>
<li><p>（但他们用的VCTK 比 VCC 的几十条还是多很多的）</p>
</li>
<li></li>
</ul>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200817161213.png" alt="image-20200817161212167"></p>
]]></content>
      <categories>
        <category>论文阅读笔记</category>
      </categories>
      <tags>
        <tag>VC</tag>
        <tag>论文阅读笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>《PITCHNET —— UNSUPERVISED SINGING VOICE CONVERSION WITH PITCH ADVERSARIAL NETWORK》</title>
    <url>/2020/09/07/0906%E7%BB%84%E4%BC%9A%E5%88%86%E4%BA%AB%EF%BC%9A%E6%AD%8C%E5%94%B1%E8%BD%AC%E6%8D%A2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>0906组会分享</p>
<h2 id="0906组会分享：歌唱转换-singing-voice-conversion"><a href="#0906组会分享：歌唱转换-singing-voice-conversion" class="headerlink" title="0906组会分享：歌唱转换 singing voice conversion"></a>0906组会分享：<strong>歌唱转换 singing voice conversion</strong></h2><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200905170752.png" alt="image-20200905170750870"></p>
<ul>
<li><p>效果概览：<a href="https://tencent-ailab.github.io/pitch-net/" target="_blank" rel="noopener">https://tencent-ailab.github.io/pitch-net/</a></p>
</li>
<li><p>MOS评分：</p>
<ul>
<li>Baseline ：2.92</li>
<li>PitchNet：3.75</li>
</ul>
</li>
</ul>
<a id="more"></a>



<ul>
<li><h2 id="论文的-baseline-对象："><a href="#论文的-baseline-对象：" class="headerlink" title="论文的 baseline 对象："></a>论文的 <strong>baseline</strong> 对象：<img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200905171530.png" alt="image-20200905171528462"></h2></li>
<li><h2 id="BaseLine-的贡献和缺点"><a href="#BaseLine-的贡献和缺点" class="headerlink" title="BaseLine 的贡献和缺点"></a><strong>BaseLine 的贡献和缺点</strong></h2></li>
</ul>
<p>贡献：</p>
<ol>
<li>利用 AE 模式下的无监督方式，解决了 平行语料的问题</li>
<li>组成模块：<strong>WaveNetlike Encoder</strong> &amp;&amp;  <strong>WaveNet  autoregressive Decoder</strong> &amp;&amp; <strong>Speaker-Embedding Table</strong>（leanable）</li>
</ol>
<p>缺点：</p>
<ol>
<li>和StarGan-VC之类的 单纯说话VC 任务不同，歌唱转换的效果重点是：说话人相似性 &amp;&amp; 音调合理性</li>
<li>BaseLine 在音调处理上差强人意，总而言之，“<strong>语音和音调的联合表示</strong>”是难点</li>
</ol>
<hr>
<ul>
<li><h2 id="解决的问题："><a href="#解决的问题：" class="headerlink" title="解决的问题："></a><strong>解决的问题</strong>：</h2></li>
</ul>
<ol>
<li>走调（音高 Pitch 失控现象）问题的缓解<ol>
<li>在 Baseline 的 <strong>AE无监督</strong> 模式下，附带一个额外的<strong>音调回归网络（GAN）</strong>可以将音调信息从潜在空间中分离出来</li>
<li><strong>目的是</strong>：让原本的<strong>Encoder</strong>在单纯学习 <strong>说话人无关的语言信息</strong> 基础上，再额外剥离掉 <strong>音高信息</strong> （<strong>not only singer-invariant but also pitch-invariant representation</strong>）</li>
</ol>
</li>
<li>至于音高信息，当成一个独立问题来解决：设立独立模块来提取 <strong>source</strong> 的<strong>音高信息</strong>，以此配合 <strong>Decoder</strong> ，来<strong>操控</strong> <strong>生成语音</strong> 的<strong>音高</strong> <ol>
<li>（根据作者相关 Git 项目下的 issue 讨论，这部分工作借用 Kaldi 来完成）</li>
<li>【实现 <strong>音高可控性</strong> 】</li>
</ol>
</li>
</ol>
<hr>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a><strong>模型</strong></h2><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200905223846.png" alt="image-20200905223845590"></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200905223859.png" alt="image-20200905223857883"></p>
<ul>
<li><strong>Singer Classiﬁcation Network</strong> <strong>Pitch Regression Network</strong> 是为了使得 <strong>Encoder</strong> 能够在抽取特征向量 <strong>z</strong> 时，把 说话人信息 &amp;&amp; 音调信息 都剥离掉</li>
<li></li>
<li></li>
</ul>
<hr>
<h2 id="Training-Loss：三个Loss"><a href="#Training-Loss：三个Loss" class="headerlink" title="Training Loss：三个Loss"></a><strong>Training Loss：三个Loss</strong></h2><ol>
<li><strong>singer classiﬁcation loss</strong></li>
<li><strong>pitch regression loss</strong></li>
<li><strong>reconstruction loss</strong></li>
</ol>
<h2 id="几个公式的清晰理解："><a href="#几个公式的清晰理解：" class="headerlink" title="几个公式的清晰理解："></a>几个公式的清晰理解：</h2><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200906141104.png" alt="image-20200906141103220"></p>
<ol>
<li>说明了AE网络的Decoder产生结果 所需要的输入元素（Encoder结果+Kaldi抽取的音高+Embedding信息）</li>
<li>介绍重构损失：在Decoder时配合<strong>source</strong>的embedding，和<strong>source</strong>语音做<strong>Loss</strong></li>
</ol>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200906141139.png" alt="image-20200906141138234"></p>
<ol start="3">
<li>一个 <strong>说话人分类器</strong>，同理为 StarGan-VC 的Domain-Classification，分类对象，是<strong>Encoder</strong>结果&amp;&amp;<strong>Embedding</strong></li>
<li>另一个<strong>音高分类器</strong>，Pitch信息由 Kaldi 提取</li>
<li>总的<strong>Loss</strong>结构：因为重构损失⬇️越好，另一方面，对于两个分类器，我们希望我们的 <strong>Encoder</strong>提取出来的隐变量 能彻底剥离 说话人信息 &amp;&amp; Pitch信息，所以这两个的误差，对于结果来说，应该越大越好。（所以这两个部分是配合 负号）</li>
<li>上述两个 C分类器的损失，对于<strong>Encoder</strong>和<strong>Classifier</strong>来说，是完全相反的，【<strong>就是典型的GAN对抗思路</strong>】，所以他们的训练，采取“你一次我一次的过程”<ul>
<li>训练中，缩小 $$L_{total}$$ 时，促进的是 <strong>Encoder</strong> 将两个元素剥离</li>
<li>缩小 $L_{ad}$ 时，促进的是 <strong>Classifier</strong> 具有更强的分类能力，能看透隐变量 <strong>z</strong> 的实质和归属</li>
</ul>
</li>
</ol>
<p>Ps.整体思路比较清晰，就是<strong>自回归</strong>那个部分不知道是怎么具体实现的</p>
<hr>
<p>Quantitative and Qualitative Experiments**【定量 和 定性 实验】</p>
<hr>
<p>Tencent :LPCNet, </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python convert_tfrecord_to_lmdb.py --dataset&#x3D;celeba --tfr_path&#x3D;&#x2F;data&#x2F;hsj&#x2F;NVAE&#x2F;DATA_DIR&#x2F;celeba&#x2F;celeba-tfr --lmdb_path&#x3D;&#x2F;data&#x2F;hsj&#x2F;NVAE&#x2F;DATA_DIR&#x2F;celeba&#x2F;celeba-lmdb --split&#x3D;train</span><br><span class="line">python convert_tfrecord_to_lmdb.py --dataset&#x3D;celeba --tfr_path&#x3D;&#x2F;data&#x2F;hsj&#x2F;NVAE&#x2F;DATA_DIR&#x2F;celeba&#x2F;celeba-tfr --lmdb_path&#x3D;&#x2F;data&#x2F;hsj&#x2F;NVAE&#x2F;DATA_DIR&#x2F;celeba&#x2F;celeba-lmdb --split&#x3D;validation</span><br></pre></td></tr></table></figure>





<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export EXPR_ID&#x3D;&#x2F;data&#x2F;hsj&#x2F;NVAE&#x2F;EXPR_ID</span><br><span class="line">export DATA_DIR&#x3D;&#x2F;data&#x2F;hsj&#x2F;NVAE&#x2F;DATA_DIR&#x2F;celeba&#x2F;celeba-lmdb</span><br><span class="line">export CHECKPOINT_DIR&#x3D;&#x2F;data&#x2F;hsj&#x2F;NVAE&#x2F;CHECKPOINT_DIR</span><br><span class="line">export CODE_DIR&#x3D;&#x2F;data&#x2F;hsj&#x2F;NVAE</span><br><span class="line">cd &#x2F;data&#x2F;hsj&#x2F;NVAE</span><br><span class="line">CUDA_VISIBLE_DEVICES&#x3D;1  </span><br><span class="line">python train.py --data &#x2F;data&#x2F;hsj&#x2F;NVAE&#x2F;DATA_DIR&#x2F;celeba&#x2F;celeba-lmdb --root &#x2F;data&#x2F;hsj&#x2F;NVAE&#x2F;CHECKPOINT_DIR --save &#x2F;data&#x2F;hsj&#x2F;NVAE&#x2F;EXPR_ID --dataset celeba_64 \</span><br><span class="line">        --num_channels_enc 64 --num_channels_dec 64 --epochs 90 --num_postprocess_cells 2 --num_preprocess_cells 2 \</span><br><span class="line">        --num_latent_scales 3 --num_latent_per_group 20 --num_cell_per_cond_enc 2 --num_cell_per_cond_dec 2 \</span><br><span class="line">        --num_preprocess_blocks 1 --num_postprocess_blocks 1 --weight_decay_norm 1e-1 --num_groups_per_scale 20 \</span><br><span class="line">        --batch_size 16 --num_nf 1 --ada_groups --num_process_per_node 8 --use_se --res_dist --fast_adamax</span><br></pre></td></tr></table></figure>



<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CelebA64 数据预处理</span><br><span class="line"></span><br><span class="line">cd $CODE_DIR&#x2F;scripts</span><br><span class="line">python create_celeba64_lmdb.py --split train --img_path .&#x2F;DATA_DIR&#x2F;celeba_org&#x2F;celeba --lmdb_path  .&#x2F;DATA_DIR&#x2F;celeba64_lmdb</span><br><span class="line">python create_celeba64_lmdb.py --split valid --img_path .&#x2F;DATA_DIR&#x2F;celeba_org&#x2F;celeba --lmdb_path  .&#x2F;DATA_DIR&#x2F;celeba64_lmdb</span><br><span class="line">python create_celeba64_lmdb.py --split test  --img_path .&#x2F;DATA_DIR&#x2F;celeba_org&#x2F;celeba --lmdb_path  .&#x2F;DATA_DIR&#x2F;celeba64_lmdb</span><br></pre></td></tr></table></figure>



<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python create_celeba64_lmdb.py --split train --img_path ..&#x2F;DATA_DIR&#x2F;celeba_org&#x2F;celeba --lmdb_path ..&#x2F;DATA_DIR&#x2F;celeba64_lmdb</span><br></pre></td></tr></table></figure>



<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python convert_tfrecord_to_lmdb.py --dataset&#x3D;celeba --split&#x3D;validation</span><br></pre></td></tr></table></figure>



<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python train.py --data $DATA_DIR&#x2F;celeba64_lmdb --root $CHECKPOINT_DIR --save $EXPR_ID --dataset celeba_64 \</span><br><span class="line">        --num_channels_enc 64 --num_channels_dec 64 --epochs 90 --num_postprocess_cells 2 --num_preprocess_cells 2 \</span><br><span class="line">        --num_latent_scales 3 --num_latent_per_group 20 --num_cell_per_cond_enc 2 --num_cell_per_cond_dec 2 \</span><br><span class="line">        --num_preprocess_blocks 1 --num_postprocess_blocks 1 --weight_decay_norm 1e-1 --num_groups_per_scale 20 \</span><br><span class="line">        --batch_size 16 --num_nf 1 --ada_groups --num_process_per_node 8 --use_se --res_dist --fast_adamax</span><br></pre></td></tr></table></figure>

<p>/Users/huangshengjie/Desktop/NVAE/scripts/data1/datasets/imagenet-oord</p>
]]></content>
      <categories>
        <category>论文阅读笔记</category>
      </categories>
      <tags>
        <tag>VC</tag>
        <tag>论文阅读笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>《EMOTIONAL VOICE CONVERSION USING MULTITASK LEARNING WITH TEXT-TO-SPEECH》</title>
    <url>/2020/09/20/0920-EMOTIONAL%20VOICE%20CONVERSION%20USING%20MULTITASK%20LEARNING%20WITH%20TEXT-TO-SPEECH/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>0920-论文总结</p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200921003657.png" alt="image-20200916195211586"></p>
<p>2020.09.20</p>
<a id="more"></a>

<h2 id="本周完成的工作："><a href="#本周完成的工作：" class="headerlink" title="本周完成的工作："></a>本周完成的工作：</h2><p>（写了比较多的<strong>验证实验代码</strong>，助于理解原理）</p>
<ol>
<li><p>学习掌握了 <strong>LMDB</strong> 格式数据的处理（创建/插入/读取/修改）</p>
</li>
<li><p>实现了 <strong>Numpy 类型数据转 lmdb</strong>（<strong>librosa</strong>提取出来的<strong>mel</strong>数据需要处理成 <strong>连续存储</strong> <strong>np.ascontiguousarray（）</strong>）</p>
</li>
<li><p>从 lmdb 读取数据，并转换成 numpy（<strong>np.fromstring(value, dtype=np.float32)</strong>），并完整复原成语音。</p>
</li>
<li><p><strong>Mel —&gt;(griffin)—&gt;wav</strong>：对比试验了几个版本的 tacotron 的语音数据处理代码， 结合网上资料，总结一套转换效果质量较好的 代码：（mag -&gt; mel ; <strong>mel -&gt; mag</strong>; mag -&gt;wave）【很多资料版本在借用<strong>griffin</strong>实现 <strong>mel 转 幅度谱 mag</strong> 环节，写的不够好甚至没写清楚】</p>
<hr>
</li>
<li><p>数据处理环节：NVAE 中的 图像处理是【n，n】，所以采用 【<strong>256帧，n_mels=256</strong>】的参数来提取 <strong>mel</strong>（<strong>80 维的griffin复原效果太差</strong></p>
<hr>
</li>
<li><p>🌟<strong>NVAE图像**</strong>训爆了<strong>：和作者联系，问题定位在 batch太小（原32，咱们用 4【GPU限制】）情况下，</strong>learning_rate太大：1e-2 改 1e-3</p>
</li>
<li><p>在epoch <strong>5</strong> 掉链子：<strong>warm_up</strong>环节刚过，学习率有变，所以导致数据算成了 <strong>NAN</strong>；模型保存也只保存到 <strong>epoch 1</strong>，<strong>改部分代码，先 一个epoch一个epoch保存 ckpt</strong></p>
</li>
</ol>
<hr>
<h2 id="可改进："><a href="#可改进：" class="headerlink" title="可改进："></a>可改进：</h2><ol>
<li>晚上先试着跑起来</li>
<li>后面尝试改进 NVAE 代码成 <strong>自适应 数据尺寸【m，n】（m != n）</strong></li>
<li>在tensorboard上看下怎么展示中间步骤语音 .wav</li>
</ol>
<hr>
<hr>
<h2 id="论文涉猎"><a href="#论文涉猎" class="headerlink" title="论文涉猎"></a>论文涉猎</h2><h2 id="情感语音转换（TTS-VC-多任务学习）"><a href="#情感语音转换（TTS-VC-多任务学习）" class="headerlink" title="情感语音转换（TTS + VC 多任务学习）"></a><strong>情感语音转换</strong>（TTS + VC 多任务学习）</h2><ul>
<li><h3 id="VC领域-痛点：保存语言信息，情感信息-和-多对多VC方面，VC的性能仍然很差"><a href="#VC领域-痛点：保存语言信息，情感信息-和-多对多VC方面，VC的性能仍然很差" class="headerlink" title="VC领域 痛点：保存语言信息，情感信息 和 多对多VC方面，VC的性能仍然很差"></a>VC领域 <strong>痛点</strong>：<strong>保存语言信息</strong>，<strong>情感信息</strong> 和 <strong>多对多VC</strong>方面，VC的性能仍然很差</h3></li>
<li><h3 id="解决的问题：在-2017-年一篇-“情感VC转换”-基础上，提升“转换后内容保留程度”（即，降低WER）（retaining-linguistic-contents）"><a href="#解决的问题：在-2017-年一篇-“情感VC转换”-基础上，提升“转换后内容保留程度”（即，降低WER）（retaining-linguistic-contents）" class="headerlink" title="解决的问题：在 2017 年一篇 “情感VC转换” 基础上，提升“转换后内容保留程度”（即，降低WER）（retaining linguistic contents）"></a><strong>解决的问题</strong>：在 2017 年一篇 “情感VC转换” 基础上，<strong>提升“转换后内容保留程度”</strong>（即，降低WER）（retaining linguistic contents）</h3></li>
</ul>
<hr>
<ul>
<li>有<strong>提供源码</strong>，缺 demo 展示（文件夹下载需代理，网速极其慢， 300+m 大小 /  3kb/s）</li>
</ul>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200916195217.png" alt="image-20200916195211586"></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200919174026.png" alt="image-20200919174025442"></p>
<hr>
<ul>
<li>最新的 VC 思路是 序列到序列（Sequence 2 Seq），但是容易丢失语音信息<ul>
<li>可以通过文本监督来矫正：<ul>
<li>但是对齐是个问题；</li>
<li>另外这样也失去了 S2S 的优势了</li>
</ul>
</li>
</ul>
</li>
<li>本文思路：<ul>
<li>利用 <strong>多任务学习的 TTS 模型</strong>，来帮助 VC 模型 <strong>捕获语言信息</strong>并<strong>保持训练稳定性</strong>。</li>
<li>TTS 框架来源 tacotron（有局部的稍微改动）：（Style Encoder 也是借鉴这篇）<img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200921003719.png" alt="image-20200919190909558"></li>
<li>VC 框架：另外并联一个 “Content Encoder”</li>
</ul>
</li>
</ul>
<hr>
<h2 id="要点："><a href="#要点：" class="headerlink" title="要点："></a>要点：</h2><ul>
<li><strong>并不像</strong>传统做 <strong>情感转换</strong>那样，在训练阶段就提取 情感标签（one-hot形式）；</li>
<li>在整个网络中，也不会将 <strong>情感标签</strong> 当作一个条件作为输入 （<strong>联想一下之前的 pitch 标签</strong>）</li>
<li></li>
<li>可以在<strong>单个模型中</strong>执行<strong>VC</strong>和<strong>TTS</strong></li>
</ul>
<hr>
<h2 id="网络结构："><a href="#网络结构：" class="headerlink" title="网络结构："></a>网络结构：</h2><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200919173504.png" alt="image-20200919173502738"></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200919185336.png" alt="image-20200919185334992"></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200919204207.png" alt="image-20200919204205843"></p>
<hr>
<h2 id="TTS-支线：（以-tacotron-为原型）"><a href="#TTS-支线：（以-tacotron-为原型）" class="headerlink" title="TTS 支线：（以 tacotron 为原型）"></a>TTS 支线：（以 tacotron 为原型）</h2><ol>
<li><strong>模仿的是</strong>：</li>
</ol>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200919190911.png" alt="image-20200919190909558"></p>
<ol start="2">
<li><strong>框架</strong>：</li>
</ol>
<ul>
<li>text encoder, </li>
<li>decoder,</li>
<li>attention, </li>
<li>and post processor</li>
</ul>
<ol start="3">
<li><strong>改动：(参考 [17] 文献)</strong><ol>
<li>文字向量<strong>context vector $C_t$</strong> 被用在 <strong>AttentionRNN</strong> 的每个循环内（context vector c (t)utilizes is used for every iteration in attention RNN）[原本是怎么样的？查一下]</li>
<li>在 <strong>CBHG</strong> (Convolution Bank + Highway + bi-GRU) 模块中，增加了 *<em>残余连接 (residual connection) *</em>模块</li>
</ol>
</li>
</ol>
<hr>
<hr>
<h2 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h2><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200919194706.png" alt="image-20200919194704841"></p>
<ul>
<li>Loss 就是直接比较： <strong>mel谱</strong> 差距 &amp;&amp; <strong>线性谱</strong> 差距</li>
</ul>
<hr>
<h2 id="实验参数："><a href="#实验参数：" class="headerlink" title="实验参数："></a>实验参数：</h2><ol>
<li>大体上都是和 taco 部分的语音预处理手法相似</li>
<li>数据集：<ol>
<li>韩国某个30岁男子，用七种情绪，每种情绪说 3k 句；共 2.1w 句；</li>
<li>其中情感：（neutral, happiness, sadness, anger, fear, surprise, and disgust)</li>
<li>去除静音之后，共约 29.2 h</li>
</ol>
</li>
<li>🌟值得一提的几点：<ol>
<li>去除静音，不是像taco那样，用 <strong>librosa.effect.trim()</strong> ，而是用voice activity detection algorithm （VAD 算法：开源）</li>
<li>在做 TTS-taco-like 部分里，<strong>字符处理</strong>有特点：【在转换为 <strong>one-hot embedding</strong> 这种表示形式之前会分解为 <strong>开始</strong>，<strong>核心</strong> 和 <strong>尾声</strong>（<strong>onset, nucleus, and coda</strong>）】</li>
<li>256 character embedding, 32 dimensions for $h_c$</li>
</ol>
</li>
</ol>
<hr>
<h2 id="🌟重要的一个验证实验"><a href="#🌟重要的一个验证实验" class="headerlink" title="🌟重要的一个验证实验"></a>🌟重要的一个验证实验</h2><p>——（<strong>内容一致性</strong>验证 <strong>Linguistic consistency</strong>）</p>
<ol>
<li>每种情感 取20条句子</li>
<li>用 StyleEncoder 提取 “<strong>style vector</strong>”，并用<strong>余弦相似度</strong>来查看<strong>情感分离程度</strong>（验证情感特征提取的有效性）</li>
</ol>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200920161149.png" alt="image-20200920161147834"></p>
<ol>
<li>每种情感 句子 的<strong>内容 $X_s$</strong> 保持不变，选取七种句子（同内容），做“从中性情感”到“其他六种情感”的转换</li>
<li>结果上看，<strong>log mel</strong> 语谱图 <strong>尺寸形状大差不差</strong></li>
<li>有些许差异的地方：<ol>
<li>时间偏移，</li>
<li>频率偏移，</li>
<li>暂停持续时间</li>
</ol>
</li>
<li>总体上能实现，<strong>由一种情感，随意 VC 转换到其他情感</strong> 的能力</li>
</ol>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200920161207.png" alt="image-20200920161206290"></p>
<hr>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200920145005.png" alt="image-20200920145003900"></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200919205459.png" alt="image-20200919205457583"></p>
<ol>
<li>在联合训练的帮助下：<ol>
<li>VCTTS-VC 在内容保留能力上的效果，比单纯的 VC ，正确率要提高不少</li>
<li>另一方面，VCTTS-TTS 比单纯的 TTS 没有太大进步，甚至有一点点下降</li>
</ol>
</li>
</ol>
]]></content>
      <categories>
        <category>论文阅读笔记</category>
        <category>test</category>
      </categories>
      <tags>
        <tag>VC</tag>
        <tag>论文阅读笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>1.两数之和</title>
    <url>/2020/06/21/1.%20%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200626183100.jpg" alt="img"></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200626183108.png" alt="image-20200621235419362"></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200626183128.png" alt="image-20200621235438971"></p>
<h1 id="1-HashMap"><a href="#1-HashMap" class="headerlink" title="1. HashMap"></a>1. HashMap</h1><ul>
<li>发现很多接发都用到了map，其中C++的vector容器，java是HashMap</li>
<li>涉及到之前数据结构盲区 <strong>红黑树</strong> <a href="https://www.cnblogs.com/shoulinniao/p/11966194.html" target="_blank" rel="noopener">https://www.cnblogs.com/shoulinniao/p/11966194.html</a></li>
<li></li>
</ul>
<hr>
<h1 id="2-《Java核心技术卷一》P372，chap9-3：映射"><a href="#2-《Java核心技术卷一》P372，chap9-3：映射" class="headerlink" title="2.《Java核心技术卷一》P372，chap9.3：映射"></a>2.《Java核心技术卷一》P372，chap9.3：映射</h1><ul>
<li>映射 <strong>MAP</strong> 数据结构= 「HashMap」&amp;&amp;「TreeMap」</li>
<li>存放 {键<strong>KEY</strong>：值<strong>VALUE</strong>}对</li>
<li>都只对 <strong>键（KEY）</strong>进行处理（ <strong>散列</strong>&amp;&amp; <strong>搜索树排序</strong>  ）</li>
</ul>
<h1 id="3-相关方法函数："><a href="#3-相关方法函数：" class="headerlink" title="3.相关方法函数："></a>3.相关方法函数：</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//哈希map初始化，自己定义Key和Value的类型</span></span><br><span class="line">Map&lt;String, Employee&gt; staff = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="comment">//创建一个employee对象，用作Value</span></span><br><span class="line">Employee harry = <span class="keyword">new</span> Employee(<span class="string">"Harry Hacker"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//1.：map.put（key，value）方法：将 键值对 放进HashMap</span></span><br><span class="line">staff.put(<span class="string">"123456"</span>,harry)<span class="comment">//</span></span><br><span class="line"><span class="comment">//同一个key存两次，会覆盖，并且返回的是上一次存储的 Value值；</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//2.：map.get(key) 方法：按照 Key 的值，来从HashMap中获取Value</span></span><br><span class="line">String id = <span class="string">"123456"</span>;</span><br><span class="line">Employee e = staff.get(id);</span><br><span class="line"></span><br><span class="line"><span class="comment">//get()方法还可以人为设置默认值：</span></span><br><span class="line">Map&lt;String, Integer&gt; score = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"><span class="keyword">int</span> score = score.get(id,<span class="number">0</span>);</span><br><span class="line"><span class="comment">//放这个Key对应的Value不存在时，返回 0；</span></span><br></pre></td></tr></table></figure>

<ul>
<li><ol>
<li><strong>import</strong> java.util.HashMap;//导入</li>
<li><strong>HashMap&lt;K, V&gt; map = new HashMap&lt;K, V&gt;（）;</strong>//定义map，K和V是类，<strong><em>不允许是基本类型？</em></strong></li>
<li><strong>put（K， V）</strong></li>
<li><strong>V get（K）</strong></li>
<li><strong>V remove（K）</strong>//移除K键的值，返回的是V，可以不接收</li>
<li><strong>size（）</strong>//返回映射Map中的元素数目</li>
<li><strong>replace（）</strong>//替换</li>
</ol>
</li>
<li><pre><code class="java"> map.replace( Key,Value );
&lt;!--￼<span class="number">1</span>--&gt;</code></pre>
</li>
<li><p><strong>9. computeIfAbsent（）</strong>//</p>
</li>
<li><pre><code class="java"><span class="comment">//如果key键为java的,就添加，并且value为key键的长度</span>
<span class="comment">//这个算子就是一个和put功能差不多的算子，都是往map里面添加数据。</span>

map.computeIfAbsent(<span class="string">"java"</span>, (key)-&gt;((String)key).length());
&lt;!--￼<span class="number">2</span>--&gt;</code></pre>
</li>
<li></li>
</ul>
<hr>
<h1 id="4-关于遍历方法："><a href="#4-关于遍历方法：" class="headerlink" title="4.关于遍历方法："></a>4.关于遍历方法：</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//返回所有 Key-Value 对：</span></span><br><span class="line"><span class="keyword">for</span>(Map.Entry n: map.entrySet())&#123;</span><br><span class="line">		System.out.println(n);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//返回所有 Key：</span></span><br><span class="line"><span class="keyword">for</span>(String n : map.keySet())&#123;</span><br><span class="line">		System.out.println(n);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//返回所有Value：</span></span><br><span class="line"><span class="keyword">for</span>(Integer n: map.values())&#123;</span><br><span class="line">		System.out.println(n);	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<hr>
<h1 id="5-其他："><a href="#5-其他：" class="headerlink" title="5.其他："></a>5.其他：</h1><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200626183135.png" alt="image-20200622181415228"></p>
<ul>
<li><h2 id="HashMap中链表转换成红黑树的操作——treeifyBin"><a href="#HashMap中链表转换成红黑树的操作——treeifyBin" class="headerlink" title="HashMap中链表转换成红黑树的操作——treeifyBin()"></a>HashMap中链表转换成红黑树的操作——treeifyBin()</h2></li>
<li><p><a href="https://www.jianshu.com/p/309ea054cbc9" target="_blank" rel="noopener">https://www.jianshu.com/p/309ea054cbc9</a></p>
</li>
</ul>
<hr>
<h1 id="6-整理下HashMap里面的常见面试考点："><a href="#6-整理下HashMap里面的常见面试考点：" class="headerlink" title="6.整理下HashMap里面的常见面试考点："></a>6.整理下HashMap里面的常见面试考点：</h1><ol>
<li><h2 id="HashMap-默认容量："><a href="#HashMap-默认容量：" class="headerlink" title="HashMap 默认容量："></a>HashMap 默认容量：</h2><ul>
<li><strong>默认容量是：16 = 1 &lt;&lt; 4（位移动 = $1000_2$ =  $16_{10}$）；</strong></li>
<li><strong>默认负载因子是：0.75（根据）</strong>（服从泊松分布）：红黑树部分也是这个原理：</li>
<li>桶中的节点个数服从泊松分布；</li>
<li>取 $\lambda = 0.5$ ，此时 ，每个捅中元素个数为 【0，8】个的概率分别如图所示，大于八个，基本已经到达百万分之一的级别，所以 <strong>Java8</strong> 中选择以 <strong>8</strong> 作为一个临界数字，来决定是否将链表转化为 <strong>红黑树</strong>；</li>
<li>其中，在 最大桶元素个数 = 7 时，不变，作为缓冲，以防止过于频繁的转换消耗；  </li>
</ul>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200626183233.png" alt="image-20200622234017327"></p>
</li>
<li><h2 id="如何扩容？"><a href="#如何扩容？" class="headerlink" title="如何扩容？"></a>如何扩容？</h2><ul>
<li>$2^n$ 的形式，每次翻两倍；（这和 Hash 的工作机制有关：（n - 1）&amp; hash）</li>
<li>这样子的好处是，（$2^n$-1）= 一个全为1 的二进制树，计算更快；</li>
</ul>
</li>
<li><h2 id="为什么HashMap的数组大小一定要是-2-的幂？"><a href="#为什么HashMap的数组大小一定要是-2-的幂？" class="headerlink" title="为什么HashMap的数组大小一定要是 2 的幂？"></a>为什么<strong>HashMap</strong>的数组大小一定要是 2 的幂？</h2><ul>
<li><p>和 Hash 的工作机制有关；HashMap求索引时用&amp;运算,index=(n-1)&amp;hash</p>
</li>
<li><p>n = length : 表长度 = $2^n$ </p>
</li>
<li><p>（HashTable求索引用模运算，index = (hash &amp; 0x7FFFFFFF) % n）</p>
</li>
<li></li>
<li><p>：只有这样才能保证 经过 ( $2^n $ ) 操作后得到全是1 的值；</p>
</li>
<li><p>然后这样才能经过非常快速的位运算，快速拿到数组下标，并且能保证分布均匀</p>
</li>
<li><p>若不是 $2^n$, 则运算过后，会有0存在，那么就会导致，不管 和他进行按位与 运算的数字是多少，都会出现某些位永远是 0，那么就会导致，某些 <strong>桶</strong> 里的元素永远都是 <strong>0个</strong>，不均匀且不合理； </p>
</li>
</ul>
</li>
<li><h2 id="HashMap-为什么是线程不安全的？"><a href="#HashMap-为什么是线程不安全的？" class="headerlink" title="HashMap 为什么是线程不安全的？"></a>HashMap 为什么是线程不安全的？</h2><ul>
<li>在接近临界点时，若此时两个或者多个线程进行put操作，都会进行resize（扩容）和reHash（为key重新计算所在位置），而reHash在并发的情况下可能会形成<code>链表环</code>。</li>
<li>总结来说就是在多线程环境下，使用HashMap进行put操作会引起死循环，导致CPU利用率接近100%，所以在并发情况下不能使用HashMap。</li>
<li>为什么在并发执行put操作会引起死循环？是因为多线程会导致HashMap的Entry链表形成环形数据结构，一旦形成环形数据结构，Entry的next节点永远不为空，就会产生死循环获取Entry。</li>
<li>jdk1.7的情况下，并发扩容时容易形成链表环，此情况在1.8时就好太多太多了。</li>
<li>因为在1.8中当链表长度达到阈值（默认长度为8）时，链表会被改成树形（红黑树）结构。如果删剩节点变成7个并不会退回链表，而是保持不变，删剩6个时就会变回链表，7不变是缓冲，防止频繁变换。</li>
<li>在JDK1.7中，当并发执行扩容操作时会造成环形链和数据丢失的情况。</li>
<li>在JDK1.8中，在并发执行put操作时会发生数据覆盖的情况。</li>
</ul>
</li>
<li><h2 id="Java-7-到-8-做了哪些改进？为什么？"><a href="#Java-7-到-8-做了哪些改进？为什么？" class="headerlink" title="Java 7 到 8 做了哪些改进？为什么？"></a>Java 7 到 8 做了哪些改进？为什么？</h2><ul>
<li>如上题所述：</li>
</ul>
</li>
</ol>
<hr>
<h1 id="7-拓展"><a href="#7-拓展" class="headerlink" title="7.拓展"></a>7.拓展</h1><ol>
<li><p>你能想到的做 HashMap 匹配的方法？ </p>
<ul>
<li><ol>
<li>直接取模：（$-2^{31}$ ~ $2^{31} -1$ ）% n = （0 , $n-1$）</li>
</ol>
</li>
<li>缺点：两个：<ul>
<li>负数对 n求余，答案是负数；（所以需要额外把 负数 变为 正数 ）</li>
<li>速度较慢（相比于位运算）：因为硬件中“求余”的本质是“除法”</li>
</ul>
</li>
</ul>
</li>
<li><p>常考的“坑”：扩容：<strong>resize（）</strong></p>
<ol>
<li>扩容 <strong>resize( )</strong>包括 <strong>rehash ( )</strong></li>
<li>机制是，当原来的容器中，容量达到了 <strong>0.75 * capacity</strong>， 再创建一个 <strong>2 * capacity</strong> 的新的桶；</li>
<li>然后会把旧的桶中的数据 <strong>迁移</strong> 过去，迁移的时候，伴随着重新地对原始数据进行 <strong>rehash</strong> 计算；</li>
<li><strong>resize（）</strong>里面的 <strong>transfer（）</strong>是一切问题的根源！！</li>
</ol>
</li>
<li><ul>
<li><strong>死锁问题：</strong>：本身是线程不安全的；完全是用户的问题；</li>
</ul>
</li>
<li><ul>
<li><strong>哈希表最致命的缺陷：哈希碰撞——&gt;</strong>最差情况下，会变成单链表；链表性能退化</li>
</ul>
</li>
<li><ul>
<li>所以在java7时代的 <strong>Tomcat（2011）</strong> 中引起了问题——&gt;可以通过一组精心设计的 恶意请求，造成 <strong>DoS（Deny of serveice）</strong></li>
</ul>
</li>
<li><pre><code>&quot;Aa&quot;,&quot;BB&quot;,&quot;C#&quot; 的哈希值是相同的！
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">7. ![image-20200622231322114](https:&#x2F;&#x2F;blog-1301959139.cos.ap-beijing.myqcloud.com&#x2F;picGo&#x2F;20200626183234.png)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 8. Java8的改进点 &amp;&amp; 新API</span><br><span class="line"></span><br><span class="line">1. 从 **数组 + 链表**——&gt;**数组 + 链表 &#x2F; 红黑树**</span><br><span class="line"></span><br><span class="line">2. 扩容时，插入顺序的改进：（原来是，从旧的头先取，然后按照“头插法”插入新的桶，导致顺序不稳定）</span><br><span class="line"></span><br><span class="line">3. 函数方法：（java 8 引入了 Lamda 表达式）</span><br><span class="line"></span><br><span class="line">   1. forEach</span><br><span class="line">   2. compute 系列</span><br><span class="line"></span><br><span class="line">4.  Map 的新 API</span><br><span class="line"></span><br><span class="line">   1. Merge</span><br><span class="line">   2. replace</span><br><span class="line"></span><br><span class="line">   </span><br><span class="line"></span><br><span class="line">   ***</span><br><span class="line"></span><br><span class="line">   </span><br><span class="line"></span><br><span class="line">   # 9.补充</span><br><span class="line"></span><br><span class="line">   1. **抑或运算**：可以更简单地理解为 **不进位的 加法 ！**</span><br><span class="line">   2. 红黑树转换，并不是要把整张表都从链表改成红黑树，而是只要 超过 8 个元素的 那个桶，改一下形式，就行了：</span><br><span class="line">   3. ![image-20200623000116947](https:&#x2F;&#x2F;blog-1301959139.cos.ap-beijing.myqcloud.com&#x2F;picGo&#x2F;20200626183235.png)</span><br><span class="line">   4. 二叉平衡树，平均查找时间：O（$log N$）</span><br><span class="line">   5. 单纯的二叉树，有个极端情况：插入顺序是有序的，那么就会造成演化成 **单链表**</span><br><span class="line">   6. 而红黑树，经过一定的旋转，保证了查找的效率（具体再仔细看看书）</span><br><span class="line">   7. **新的 Java8 中的 resize（）函数**：改进成了 **扩容时** 能保持原来的顺序，但是仍然不能保证 **线程安全**，只能说是大搭建撒后了线程冲突的概率。</span><br><span class="line">   8. 所以未来可能不会再多线程情况下遇到问题，但是还是不能放心地在多线程环境下使用它！（**Linux中的任务调度 是多线程的，有用到 HashMap**）</span><br><span class="line">   9. **HashCode** ： 默认使用 **32位** 的 **Int** 的**HashCode**；</span><br><span class="line"></span><br><span class="line">   </span><br><span class="line"></span><br><span class="line">   ***</span><br><span class="line"></span><br><span class="line">   # 10.面试题常见：</span><br><span class="line"></span><br><span class="line">   1. 为什么用 数组 +链表：经典的学院派操作</span><br><span class="line">   2. Hash 冲突你还知道哪些解决办法：可以在冲突的桶里面，再套一层 Hash 表；即，冲突的进行二次分流；（表中再有个表）</span><br><span class="line">   3. 用Lin课的Li身体代替数组结构可以吗？：不可以，数组的随机访问是 O（1）的，不受数组长度的影响，二链表的顺序访问速度是 O（n），不能起到随机访问的效果；</span><br><span class="line">   4. get（）的操作？：如果第一个元素就是要求的话，那么就直接返回它；不是的话，那么，先判断该桶是什么结构，如果是红黑树，那么就用树的查找方法 查找；否则若是链表结构，就采用链表的顺序访问形式访问</span><br><span class="line">   5. 为什么 String 、Integer 这样的 wrapper 类 适合作为键？：因为String是final，具有不变性，而且已经重写了 equals（）和hashcode（）方法了。不变性是必要的！因为 为了要计算 hashcode（），就要防止键改变，如果键再嵌入时和获取时返回不同的 hashcode 的话，就不能从 HashMap 中找到你想要的对象。</span><br><span class="line">   6. 如果HashMap的大小超过了负载因子（load factor）定义的容量怎么办？：扩容：resize（） &amp; rehash（）「注意，resize（）的效率非常低！！！」所以如果预先知道有一个很大的表要创建，那么可以预先再创建时，就指定一个较大的空间，相当于时 **空间换时间**；避免未来的频繁resize（）花费很多时间。</span><br><span class="line"></span><br><span class="line">   ## </span><br><span class="line"></span><br><span class="line">***</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 11.红黑树：自己补充</span><br><span class="line"></span><br><span class="line">![截屏2020-06-23上午12.50.42](&#x2F;Users&#x2F;huangshengjie&#x2F;Desktop&#x2F;截屏2020-06-23上午12.50.42.png)</span><br><span class="line"></span><br><span class="line">* [B站课程](https:&#x2F;&#x2F;www.bilibili.com&#x2F;video&#x2F;BV1tE411f7tP?from&#x3D;search&amp;seid&#x3D;2421763921920035607)：</span><br><span class="line">* [一份链接文章](https:&#x2F;&#x2F;blog.csdn.net&#x2F;Mr_Helloworld_&#x2F;article&#x2F;details&#x2F;106694724)</span><br><span class="line">* ![image-20200624005349275](https:&#x2F;&#x2F;blog-1301959139.cos.ap-beijing.myqcloud.com&#x2F;picGo&#x2F;20200626183236.png)</span><br><span class="line">* ![image-20200624005402070](https:&#x2F;&#x2F;blog-1301959139.cos.ap-beijing.myqcloud.com&#x2F;picGo&#x2F;20200626183237.png)</span><br><span class="line">* ![image-20200624005251467](https:&#x2F;&#x2F;blog-1301959139.cos.ap-beijing.myqcloud.com&#x2F;picGo&#x2F;20200626183238.png)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">***</span><br><span class="line"></span><br><span class="line"># 12.正题：001:两数之和：Java版</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;java</span><br><span class="line">import java.util.*;</span><br><span class="line"></span><br><span class="line">public class twoSum_001 &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">    &#125;</span><br><span class="line">		&#x2F;&#x2F;暴力法</span><br><span class="line">    public int[] twoSum_force(int[] nums, int target)&#123;</span><br><span class="line">        for(int i&#x3D;0;i&lt; nums.length;i++)&#123;</span><br><span class="line">            for(int j&#x3D;i+1;j&lt; nums.length;j++)&#123;</span><br><span class="line">                if(nums[j] &#x3D;&#x3D; target - nums[i])&#123;</span><br><span class="line">                    return new int[] &#123;i, j&#125;;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        throw new IllegalArgumentException(&quot;No two sum soluition&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">		&#x2F;&#x2F;两遍 Hash，一遍存，一遍查取；</span><br><span class="line">    public int[] twoSum_HashTwice(int[] nums, int target)&#123;</span><br><span class="line">        Map&lt;Integer, Integer&gt; map &#x3D; new HashMap&lt;&gt;();</span><br><span class="line">        for(int i&#x3D;0;i&lt; nums.length;i++)&#123;</span><br><span class="line">            map.put(nums[i],i);</span><br><span class="line">        &#125;</span><br><span class="line">        for(int i&#x3D;0; i&lt;nums.length;i++)&#123;</span><br><span class="line">            int complement &#x3D; target - nums[i];</span><br><span class="line">            if(map.containsKey(complement) &amp;&amp; map.get(complement) !&#x3D; i)&#123;</span><br><span class="line">                return new int[]&#123;i,map.get(complement)&#125;;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        throw new IllegalArgumentException(&quot;No two sum solution&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">		&#x2F;&#x2F;一遍 Hash，先查，查不到就接着存；</span><br><span class="line">    public int[] twoSum_HashOnce(int[] nums, int target)&#123;</span><br><span class="line">        Map&lt;Integer, Integer&gt; map &#x3D; new HashMap&lt;&gt;();</span><br><span class="line">        for(int i&#x3D;0;i&lt;nums.length;i++)&#123;</span><br><span class="line">            int complemenmt &#x3D; target - nums[i];</span><br><span class="line">            if(map.containsKey(complemenmt))&#123;</span><br><span class="line">                return new int[]&#123;i,map.get(complemenmt)&#125;;</span><br><span class="line">            &#125;</span><br><span class="line">            map.put(nums[i], i);</span><br><span class="line">        &#125;</span><br><span class="line">        throw new IllegalArgumentException(&quot;No two sum solution.&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>






</code></pre></li>
</ol>
]]></content>
      <categories>
        <category>-[Java, 算法] -[LeetCode]</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title>0830组会分享——几种卷积辨析 &amp;&amp; SELayer论文及代码实现</title>
    <url>/2020/08/31/0830%E7%BB%84%E4%BC%9A%E5%88%86%E4%BA%AB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="几种卷积类型辨析"><a href="#几种卷积类型辨析" class="headerlink" title="几种卷积类型辨析"></a>几种卷积类型辨析</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conv = nn.Conv2d(in_channels=<span class="number">6</span>, out_channels=<span class="number">6</span>, kernel_size=<span class="number">1</span>, groups=<span class="number">3</span>)</span><br><span class="line">conv.weight.data.size()</span><br><span class="line"></span><br><span class="line"><span class="comment"># output = torch.Size([6, 2, 1, 1])</span></span><br></pre></td></tr></table></figure>

<p>一种分类方法：</p>
<p>几种卷积示意：（分组卷积 <strong>group_convolution</strong>；深度卷积 <strong>depthwise convolution</strong>； 全局深度卷积 <strong>global depthwise convolution</strong>）</p>
<ol>
<li>groups 默认值为1， 对应的是<strong>常规卷积</strong>操作</li>
<li>groups &gt; 1， 且能够同时被in_channel / out_channel整除，对应<strong>group_convolution</strong></li>
<li>groups == input_channel == out_channel , 对应<strong>depthwise convolution</strong>,为条件2的特殊情况</li>
<li>在条件3的基础上，各卷积核的 H == input_height; W == input_width, 对应为 <strong>global depthwise convolution</strong>, 为条件3的特殊情况</li>
<li></li>
</ol>
<hr>
<p>另一种分类方法：<strong>主要分三类：正常卷积、分组卷积、深度分离卷积</strong></p>
<a id="more"></a>

<!--more-->





<ol>
<li><h2 id="正常卷积："><a href="#正常卷积：" class="headerlink" title="正常卷积："></a><strong>正常卷积：</strong></h2></li>
<li><p>参数量 = cin *  $K_h$ * $K_w$ * cout</p>
</li>
<li><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200830111253.png" alt="常规卷积示意图"></p>
</li>
<li><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200830103246.jpeg" alt="img"></p>
</li>
<li><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200830103436.png" alt="img"></p>
</li>
<li></li>
<li><h2 id="分组卷积示意图："><a href="#分组卷积示意图：" class="headerlink" title="分组卷积示意图："></a><strong>分组卷积示意图：</strong></h2></li>
<li><p>参数量： (cin * $K_h$ * $K_w$* cout ) / Groups</p>
</li>
<li><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200830111236.png" alt="分组卷积示意图"></p>
</li>
<li><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200830103353.jpeg" alt="img"></p>
</li>
<li><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200830103314.png" alt="img"></p>
</li>
<li><pre><code class="python"><span class="class"><span class="keyword">class</span> <span class="title">GroupConv</span><span class="params">(nn.Module)</span>:</span>
  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_ch, out_ch, groups)</span>:</span>
      super(GroupConv, self).__init__()
      self.conv = nn.Conv2d(
          in_channels=in_ch,
          out_channels=out_ch,
          kernel_size=<span class="number">3</span>,
          stride=<span class="number">1</span>,
          padding=<span class="number">1</span>,
          groups=groups
      )

  <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input)</span>:</span>
      out = self.conv(input)
      <span class="keyword">return</span> out

</code></pre>
</li>
</ol>
<pre><code># 测试
conv = CSDN_Tem(16, 32, 4)
print(summary(conv, (16, 64, 64), batch_size=1))

********************************
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [1, 32, 64, 64]           1,184
================================================================
Total params: 1,184
Trainable params: 1,184
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.25
Forward/backward pass size (MB): 1.00
Params size (MB): 0.00
Estimated Total Size (MB): 1.25
----------------------------------------------------------------

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">13. </span><br><span class="line"></span><br><span class="line">14. </span><br><span class="line"></span><br><span class="line">15. ## [深度可分离卷积(Depthwise Separable Convolution)][https:&#x2F;&#x2F;blog.csdn.net&#x2F;weixin_30793735&#x2F;article&#x2F;details&#x2F;88915612]</span><br><span class="line"></span><br><span class="line">16. 参数量： $C_&#123;in&#125;$ * $K_h$ * $K_w$ + $C_&#123;out&#125;$ * 1 * 1</span><br><span class="line"></span><br><span class="line">17. 理解上，可以看作是， 先做一次 cin &#x3D;&#x3D; cout 的 分组卷积， 并且 groups &#x3D;&#x3D; channels，即每个通道作为一组； 然后再对上述结果，做一次 **逐点卷积(Pointwise Convolution)** 实现通道数改变的，这个过程使用大小为 **Cin * 1 * 1 ** 的卷积核实现，数量为 **Cout** 个</span><br><span class="line"></span><br><span class="line">18. &#96;&#96;&#96;python</span><br><span class="line">    class DepthSepConv(nn.Module):</span><br><span class="line">        def __init__(self, in_ch, out_ch):</span><br><span class="line">            super(DepthSepConv, self).__init__()</span><br><span class="line">            self.depth_conv &#x3D; nn.Conv2d(</span><br><span class="line">                in_channels&#x3D;in_ch,</span><br><span class="line">                out_channels&#x3D;in_ch,</span><br><span class="line">                kernel_size&#x3D;3,</span><br><span class="line">                stride&#x3D;1,</span><br><span class="line">                padding&#x3D;1,</span><br><span class="line">                groups&#x3D;in_ch</span><br><span class="line">            )</span><br><span class="line">            self.point_conv &#x3D; nn.Conv2d(</span><br><span class="line">                in_channels&#x3D;in_ch,</span><br><span class="line">                out_channels&#x3D;out_ch,</span><br><span class="line">                kernel_size&#x3D;1,</span><br><span class="line">                stride&#x3D;1,</span><br><span class="line">                padding&#x3D;0,</span><br><span class="line">                groups&#x3D;1</span><br><span class="line">            )</span><br><span class="line">    </span><br><span class="line">        def forward(self, input):</span><br><span class="line">            out &#x3D; self.depth_conv(input)</span><br><span class="line">            out &#x3D; self.point_conv(out)</span><br><span class="line">            return out</span><br><span class="line">    </span><br><span class="line">          </span><br><span class="line">    # 测试</span><br><span class="line">    conv &#x3D; DepthSepConv(16, 32)</span><br><span class="line">    print(summary(conv, (16, 64, 64), batch_size&#x3D;1))</span><br><span class="line">    </span><br><span class="line">    ************************</span><br><span class="line">    ----------------------------------------------------------------</span><br><span class="line">            Layer (type)               Output Shape         Param #</span><br><span class="line">    &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">                Conv2d-1            [1, 16, 64, 64]             160</span><br><span class="line">                Conv2d-2            [1, 32, 64, 64]             544</span><br><span class="line">    &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">    Total params: 704</span><br><span class="line">    Trainable params: 704</span><br><span class="line">    Non-trainable params: 0</span><br><span class="line">    ----------------------------------------------------------------</span><br></pre></td></tr></table></figure></code></pre><ol start="19">
<li></li>
</ol>
<hr>
<h1 id="SELayer"><a href="#SELayer" class="headerlink" title="SELayer"></a>SELayer</h1><p><strong>Squeeze-and-Excitation Networks</strong></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200830153344.png" alt="image-20200830114911949"></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200830153339.png" alt="image-20200830140039015"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.Size([<span class="number">2</span>, <span class="number">512</span>, <span class="number">64</span>, <span class="number">64</span>])</span><br><span class="line">b = <span class="number">2</span> c = <span class="number">512</span></span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">512</span>])</span><br><span class="line">After LinearFC, tmp.shape = torch.Size([<span class="number">2</span>, <span class="number">32</span>])</span><br><span class="line">After RELU, tmp.shape = torch.Size([<span class="number">2</span>, <span class="number">32</span>])</span><br><span class="line">After LinearFC2, tmp.shape = torch.Size([<span class="number">2</span>, <span class="number">512</span>])</span><br><span class="line">After SIGMOID, tmp.shape = torch.Size([<span class="number">2</span>, <span class="number">512</span>])</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">512</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">----------------------------------------------------------------</span><br><span class="line">        Layer (type)               Output Shape         Param <span class="comment">#</span></span><br><span class="line">================================================================</span><br><span class="line"> AdaptiveAvgPool2d<span class="number">-1</span>            [<span class="number">-1</span>, <span class="number">512</span>, <span class="number">1</span>, <span class="number">1</span>]               <span class="number">0</span></span><br><span class="line">            Linear<span class="number">-2</span>                   [<span class="number">-1</span>, <span class="number">32</span>]          <span class="number">16</span>,<span class="number">384</span></span><br><span class="line">              ReLU<span class="number">-3</span>                   [<span class="number">-1</span>, <span class="number">32</span>]               <span class="number">0</span></span><br><span class="line">            Linear<span class="number">-4</span>                  [<span class="number">-1</span>, <span class="number">512</span>]          <span class="number">16</span>,<span class="number">384</span></span><br><span class="line">           Sigmoid<span class="number">-5</span>                  [<span class="number">-1</span>, <span class="number">512</span>]               <span class="number">0</span></span><br><span class="line">            Linear<span class="number">-6</span>                   [<span class="number">-1</span>, <span class="number">32</span>]          <span class="number">16</span>,<span class="number">384</span></span><br><span class="line">              ReLU<span class="number">-7</span>                   [<span class="number">-1</span>, <span class="number">32</span>]               <span class="number">0</span></span><br><span class="line">            Linear<span class="number">-8</span>                  [<span class="number">-1</span>, <span class="number">512</span>]          <span class="number">16</span>,<span class="number">384</span></span><br><span class="line">           Sigmoid<span class="number">-9</span>                  [<span class="number">-1</span>, <span class="number">512</span>]               <span class="number">0</span></span><br><span class="line">================================================================</span><br><span class="line">Total params: <span class="number">65</span>,<span class="number">536</span></span><br><span class="line">Trainable params: <span class="number">65</span>,<span class="number">536</span></span><br><span class="line">Non-trainable params: <span class="number">0</span></span><br><span class="line">----------------------------------------------------------------</span><br><span class="line">Input size (MB): <span class="number">8.00</span></span><br><span class="line">Forward/backward <span class="keyword">pass</span> size (MB): <span class="number">0.02</span></span><br><span class="line">Params size (MB): <span class="number">0.25</span></span><br><span class="line">Estimated Total Size (MB): <span class="number">8.27</span></span><br><span class="line">----------------------------------------------------------------</span><br></pre></td></tr></table></figure>



<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200830153225.png" alt="image-20200830153224613"></p>
]]></content>
      <categories>
        <category>组会</category>
      </categories>
      <tags>
        <tag>组会</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>杂记</title>
    <url>/2020/11/29/1129%E6%B5%8B%E8%AF%95Torch%20gpu%20%E6%98%AF%E5%90%A6%E5%8F%AF%E7%94%A8/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="1-测试-gpu-可用性"><a href="#1-测试-gpu-可用性" class="headerlink" title="1.测试  gpu 可用性"></a>1.测试  gpu 可用性</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">'CUDA_VISIBLE_DEVICES'</span>]=<span class="string">'1'</span></span><br><span class="line">print(torch.version.cuda)</span><br><span class="line">print(torch.__version__)</span><br><span class="line">print(torch.cuda.is_available())</span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">'CUDA_VISIBLE_DEVICES'</span>]=<span class="string">'0'</span></span><br><span class="line"><span class="keyword">import</span>  time</span><br><span class="line">tf.test.is_gpu_available()</span><br></pre></td></tr></table></figure>



<hr>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">conda install -c conda-forge librosa</span><br></pre></td></tr></table></figure>



<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">conda install tensorflow-gpu&#x3D;&#x3D;1.9.0  # 自动带cudatoolkit</span><br><span class="line"># 版本匹配信息：https:&#x2F;&#x2F;www.tensorflow.org&#x2F;install&#x2F;source#common_installation_problems</span><br></pre></td></tr></table></figure>



<hr>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES&#x3D;&quot;1&quot; python train1.py</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES&#x3D;&quot;1&quot; python train1.py timit -gpu 1</span><br></pre></td></tr></table></figure>







<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.randn(<span class="number">10000</span>, <span class="number">1000</span>)</span><br><span class="line">b = torch.randn(<span class="number">1000</span>, <span class="number">2000</span>)</span><br><span class="line"></span><br><span class="line">t0 = time.time()</span><br><span class="line">c = torch.matmul(a, b)</span><br><span class="line">t1 = time.time()</span><br><span class="line">print(a.device, t1 - t0, c.norm(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">'cuda'</span>)</span><br><span class="line">a = a.to(device)</span><br><span class="line">b = b.to(device)</span><br><span class="line"></span><br><span class="line">t0 = time.time()</span><br><span class="line">c = torch.matmul(a, b)</span><br><span class="line">t2 = time.time()</span><br><span class="line">print(a.device, t2 - t0, c.norm(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">t0 = time.time()</span><br><span class="line">c = torch.matmul(a, b)</span><br><span class="line">t2 = time.time()</span><br><span class="line">print(a.device, t2 - t0, c.norm(<span class="number">2</span>))</span><br></pre></td></tr></table></figure>



<h1 id="2"><a href="#2" class="headerlink" title="2."></a>2.</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">conda -V </span><br><span class="line">conda info  </span><br><span class="line">conda config --get channels</span><br><span class="line">conda config --show</span><br><span class="line">vim ~&#x2F;.condarc    </span><br><span class="line"></span><br><span class="line">conda config --add channels https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;free&#x2F;</span><br><span class="line">conda config --add channels https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;main&#x2F;</span><br><span class="line"></span><br><span class="line">conda config --remove-key channels</span><br></pre></td></tr></table></figure>



<h1 id="3-批处理文件改后缀"><a href="#3-批处理文件改后缀" class="headerlink" title="3. 批处理文件改后缀"></a>3. 批处理文件改后缀</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">BASE = <span class="string">"/Users/huangshengjie/Desktop/TEST/"</span>   <span class="comment"># 所有文件的根目录</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(BASE):</span><br><span class="line">    <span class="keyword">if</span> len(files) &gt; <span class="number">0</span>:  <span class="comment"># 如果此目录有文件</span></span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> files:   <span class="comment"># 遍历此目录下的每一个文件</span></span><br><span class="line">            <span class="keyword">if</span> file.find(<span class="string">".WAV"</span>) != <span class="number">-1</span>:   <span class="comment"># 如果文件名中包含c2字样</span></span><br><span class="line">                new_file = file.replace(<span class="string">".WAV"</span>, <span class="string">".wav"</span>)  <span class="comment"># 则将其改成c1</span></span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    os.chdir(root)   <span class="comment"># 修改之前将当前工作目录切换到文件所在目录，否则os.rename会失败</span></span><br><span class="line">                    os.rename(file, new_file)  <span class="comment"># 调用操作系统的重命名功能</span></span><br><span class="line">                <span class="keyword">except</span> OSError <span class="keyword">as</span> e:</span><br><span class="line">                    <span class="keyword">print</span> (e)</span><br><span class="line">                    quit(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>-[Torch]</category>
      </categories>
      <tags>
        <tag>-[Torch]</tag>
      </tags>
  </entry>
  <entry>
    <title>《AiShell3》</title>
    <url>/2020/11/08/1108%E7%BB%84%E4%BC%9A%EF%BC%9A/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><a id="more"></a>

<h2 id="1108组会："><a href="#1108组会：" class="headerlink" title="1108组会："></a>1108组会：</h2><ul>
<li><input checked disabled type="checkbox"> <p>完成<strong>软著申请</strong></p>
</li>
<li><input checked disabled type="checkbox"> <p>完成 <strong>开题PPT 修改</strong></p>
</li>
<li><input checked disabled type="checkbox"> <p>完成 VC综述 <strong>论文整理</strong></p>
</li>
<li><input disabled type="checkbox"> <p><strong>尚未完成</strong> 开题综述 <strong>主体部分</strong>（花了较多时间看<strong>格式处理</strong>）</p>
</li>
<li><input checked disabled type="checkbox"> <p>阅读<strong>《AiShell-3》</strong>论文：值得分享一个亮点（speaker-embedding-cycle-consistence Loss）</p>
</li>
</ul>
<hr>
<ul>
<li><a href="https://github.com/sos1sos2Sixteen/aishell-3-baseline-fc" target="_blank" rel="noopener">源码</a></li>
<li><a href="https://sos1sos2sixteen.github.io/aishell3/" target="_blank" rel="noopener">Demo</a></li>
<li></li>
</ul>
<p><strong>Boild-polit</strong> 数据集在15043上有？</p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201108153939.png" alt="image-20201108153938426"></p>
<hr>
<ul>
<li><p>前端：Tacotron</p>
</li>
<li><p>后端：MelGAN</p>
</li>
<li><p>🌟特点：在多说话人合成任务上，为了进一步增加相似度，提出了“<strong>speaker identity feedback constraint</strong>”</p>
</li>
<li><p>公式上体现：</p>
<ul>
<li><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201108153544.png" alt="image-20201108153543937"></li>
</ul>
</li>
<li><p><strong>部分</strong>，先<strong>预训练</strong>，然后在训练 <strong>Tacotron</strong> 的时候参数<strong>不再参与训练</strong> <strong>Frozen</strong></p>
</li>
</ul>
<hr>
<h2 id="另一些亮点："><a href="#另一些亮点：" class="headerlink" title="另一些亮点："></a>另一些亮点：</h2><ol>
<li><p>Tacotron2 中，对长序列语音的合成，表现乏力；</p>
<ul>
<li><p>通常改进方法是：从 <strong>hybrid-attention mechanism</strong> 改进为 <strong>purely location-based attention mechanisms</strong> ，即 Attention 机制的改进</p>
</li>
<li><p>但是这么弄，会使得 长句子的 韵律表现很差</p>
</li>
<li><p>本文转用 <strong>data augmentation</strong> <strong>数据增强</strong> 来处理长句子合成问题</p>
</li>
<li><p>扩充后的数据用于<strong>微调收敛于原始数据集</strong>的<strong>TTS模型</strong>。</p>
</li>
</ul>
</li>
<li><p>在语音合成任务中，之前较少看见 VAD 操作，一般在识别任务上用的比较多；</p>
<ul>
<li>本文在数据预处理上，用 基于能量谱的 VAD 来对训练集 语音开始部分的静音帧进行去除</li>
<li>帮助加速后续的 <strong>优化对齐环节</strong> </li>
</ul>
</li>
<li></li>
</ol>
<hr>
<p>🌟备注：</p>
<ol>
<li>在公司里 &amp;&amp; VCC2020中，很多队伍提到，用 <strong>24k</strong> 的生成效果比 <strong>16k</strong> 提升显著，本文是用<strong>16k</strong>，之后可从这个点做稍微提升</li>
<li></li>
</ol>
]]></content>
      <categories>
        <category>论文阅读笔记</category>
      </categories>
      <tags>
        <tag>VC</tag>
        <tag>论文阅读笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>16.最接近的三数之和 &amp;&amp; 数组排序（默认升）</title>
    <url>/2020/06/24/16.%20%E6%9C%80%E6%8E%A5%E8%BF%91%E7%9A%84%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C%20&amp;&amp;%20%E6%95%B0%E7%BB%84%E6%8E%92%E5%BA%8F%EF%BC%88%E9%BB%98%E8%AE%A4%E5%8D%87%EF%BC%89/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="1-知识点："><a href="#1-知识点：" class="headerlink" title="1.知识点："></a>1.知识点：</h1><ul>
<li>双指针</li>
<li>数组排序（默认升序）；自定义降序</li>
</ul>
<h1 id="2-排序代码"><a href="#2-排序代码" class="headerlink" title="2.排序代码"></a>2.排序代码</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Java 中 实现 数组的排序</span></span><br><span class="line"><span class="comment"> * 默认是 上升序列；</span></span><br><span class="line"><span class="comment"> * 若要 下降，则默认需要 Integer 或者 Float 等 "类"类型，不能使用基础类型；</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * */</span></span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> 最接近的三数之和<span class="title">_16</span>  </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//注意，要想改变默认的排列顺序，不能使用基本类型（int,double, char）,而要使用它们对应的类</span></span><br><span class="line">        Integer[] arr = &#123;<span class="number">9</span>, <span class="number">8</span>, <span class="number">7</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">6</span>, <span class="number">5</span>&#125;;</span><br><span class="line">        <span class="comment">//定义一个自定义类MyComparator的对象</span></span><br><span class="line">      <span class="comment">//法一：实现降序；需要类型，不能是基础类型</span></span><br><span class="line"><span class="comment">//        Arrays.sort(arr,Collections.reverseOrder());</span></span><br><span class="line">      <span class="comment">//法二：实现降序</span></span><br><span class="line"><span class="comment">//        Arrays.sort(arr, (a,b) -&gt; (b - a));         </span></span><br><span class="line"></span><br><span class="line">      <span class="comment">//法三：需要自己重写 Comparator</span></span><br><span class="line">        Comparator cmp = <span class="keyword">new</span> MyComparator();      </span><br><span class="line">        Arrays.sort(arr, cmp);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> x : arr) &#123;</span><br><span class="line">            System.out.print(x + <span class="string">" "</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//若得到的是 int ，需要先手动转为 Integer 类型！</span></span><br><span class="line">        <span class="keyword">int</span> scores[] = <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">89</span>,<span class="number">4</span>&#125;;</span><br><span class="line">        Integer newScores[] = <span class="keyword">new</span> Integer [<span class="number">5</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;scores.length;i++)&#123;</span><br><span class="line"><span class="comment">//            newScores[i]= new Integer(scores[i]);</span></span><br><span class="line">            newScores[i] = scores[i];</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println();</span><br><span class="line"></span><br><span class="line">        Arrays.sort(newScores,Collections.reverseOrder());</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> x : newScores) &#123;</span><br><span class="line">            System.out.print(x + <span class="string">" "</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//实现Comparator接口</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyComparator</span> <span class="keyword">implements</span> <span class="title">Comparator</span>&lt;<span class="title">Integer</span>&gt; </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span> <span class="comment">//作用是检查下面的方法名是不是父类中所有的，也起到注释的作用</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(Integer a, Integer b)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a &gt; b ? -<span class="number">1</span> : <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><h2 id="注意点："><a href="#注意点：" class="headerlink" title="注意点："></a>注意点：</h2></li>
<li><pre><code class="java">Collections.reverseOrder()
&lt;!--￼<span class="number">1</span>--&gt;

* 道理同上</code></pre>
</li>
<li><pre><code class="java">自己重写 Comparator
&lt;!--￼<span class="number">2</span>--&gt;

才可以实现 用 <span class="keyword">int</span> 类型直接排序（默认是升序列）</code></pre>
</li>
<li><p>若要降序，基本都需要 Integer 类型；</p>
</li>
<li><p>若是 int 基础类型，那么需要手动 转换一下类型；</p>
</li>
</ul>
<hr>
<h1 id="3-题目："><a href="#3-题目：" class="headerlink" title="3.题目："></a>3.题目：</h1><h2 id="寻找数组中三个数字之和，要求和最接近于目标数值"><a href="#寻找数组中三个数字之和，要求和最接近于目标数值" class="headerlink" title="寻找数组中三个数字之和，要求和最接近于目标数值"></a>寻找数组中三个数字之和，要求和最接近于目标数值</h2><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200626183440.png" alt="image-20200624135415119"></p>
<ul>
<li><p>法一：暴力：O（$N^3$）</p>
</li>
<li><p>```java<br>//法一：暴力 O(n^3)<br> int best = 100000;<br> int diff = 100000;<br> for(int i=0;i&lt;nums.length;i++){</p>
<pre><code>for(int j = i+1;j&lt;nums.length;j++){
    for(int k = j+1;k&lt;nums.length;k++){
        if(Math.abs(nums[i]+nums[j]+nums[k] - target) &lt; diff){
            diff = Math.abs(nums[i]+nums[j]+nums[k] - target);
            best = nums[i]+nums[j]+nums[k];
        }
    }
}</code></pre><p> }<br> return best;</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">* </span><br><span class="line"></span><br><span class="line">* 法二：双指针：第一个元素从头到尾遍历，二、三元素从表头、尾向中间靠拢。</span><br><span class="line"></span><br><span class="line">  * 好处是：省掉了很多没必要的不可能组合；（有点剪枝的意思了）</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;java</span><br><span class="line">import java.util.*;</span><br><span class="line"></span><br><span class="line">public class 最接近的三数之和_16 &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    public int threeSumClosest(int[] nums, int target)&#123;</span><br><span class="line">        Arrays.sort(nums);&#x2F;&#x2F;升序排列</span><br><span class="line">        int n &#x3D; nums.length;</span><br><span class="line">        int best &#x3D; 10001000;</span><br><span class="line"></span><br><span class="line">        for(int i &#x3D; 0;i &lt; n; i++)&#123;</span><br><span class="line">            &#x2F;&#x2F;若下一个元素和当前元素内容一样，则可以跳过；</span><br><span class="line">            &#x2F;&#x2F;continue，直接跳过当前循环，进入下一次循环；</span><br><span class="line">            if(i&gt;0 &amp;&amp; nums[i] &#x3D;&#x3D; nums[i-1])&#123;</span><br><span class="line">                continue;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F;使用双指针，枚举 b 和 c；</span><br><span class="line">            int j &#x3D; i+1, k &#x3D; n-1;</span><br><span class="line">            while(j &lt; k)&#123;</span><br><span class="line">                int sum &#x3D; nums[i] + nums[j] + nums[k];</span><br><span class="line">                &#x2F;&#x2F;如果直接等于target，那么直接返回，最接近；</span><br><span class="line">                if(sum &#x3D;&#x3D; target)&#123;</span><br><span class="line">                    return target;</span><br><span class="line">                &#125;</span><br><span class="line">                if(Math.abs(sum - target) &lt; Math.abs(best - target))&#123;</span><br><span class="line">                    best &#x3D; sum;</span><br><span class="line">                &#125;</span><br><span class="line">                if(sum &gt; target)&#123;</span><br><span class="line">                    int k0 &#x3D; k - 1;</span><br><span class="line">                    &#x2F;&#x2F;开始移动 c 的指针，直到比原本的 c 值要小；</span><br><span class="line">                    &#x2F;&#x2F; 向左移动到下一个不想等的元素；</span><br><span class="line">                    while(j &lt; k0 &amp;&amp; nums[k0] &#x3D;&#x3D; nums[k])&#123;</span><br><span class="line">                        --k0;</span><br><span class="line">                    &#125;</span><br><span class="line">                    k &#x3D; k0;  &#x2F;&#x2F; 如果发生 k &#x3D; k0 &#x3D;&#x3D; j;那么会退出现在的 while(j &lt; k)</span><br><span class="line">                &#125;else&#123;</span><br><span class="line">                    &#x2F;&#x2F;如果 sum &lt; target，那么就把 b 指针向左移动；</span><br><span class="line">                    int j0 &#x3D; j+1;</span><br><span class="line">                    while(j0 &lt; k &amp;&amp; nums[j0] &#x3D;&#x3D; nums[j])&#123;</span><br><span class="line">                        ++j0;</span><br><span class="line">                    &#125;</span><br><span class="line">                    j &#x3D; j0;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return best;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>-[Java, 算法] -[LeetCode]</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>双指针</tag>
      </tags>
  </entry>
  <entry>
    <title>《ONE-SHOT VOICE CONVERSION BY VECTOR QUANTIZATION》</title>
    <url>/2020/10/18/10.18%E7%BB%84%E4%BC%9A-VQVC%20%E7%AE%80%E6%9E%90/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h3 id="1018组会"><a href="#1018组会" class="headerlink" title="1018组会"></a>1018组会</h3><h3 id="VQVC-简析"><a href="#VQVC-简析" class="headerlink" title="VQVC 简析"></a>VQVC 简析</h3><ul>
<li>《ONE-SHOT VOICE CONVERSION BY VECTOR QUANTIZATION》</li>
<li><a href="https://ericwudayi.github.io/VQVC-DEMO/" target="_blank" rel="noopener">https://ericwudayi.github.io/VQVC-DEMO/</a></li>
</ul>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201018132533.png" alt="image-20201018132532040"></p>
<ul>
<li>《VQVC+: One-Shot Voice Conversion by Vector Quantization and U-Net architecture》</li>
</ul>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201018001018.png" alt="image-20201018001016143"></p>
<a id="more"></a>

<hr>
<h2 id="1-特点"><a href="#1-特点" class="headerlink" title="1. 特点"></a>1. 特点</h2><ul>
<li>模型结构：AE 类型，U-Net 框架</li>
<li>常见 VC 特征解纠缠思路：The disentangle capability is achieved by vector quantization (VQ), adversarial training, or instance normalization (IN)<ul>
<li>VQ</li>
<li>对抗</li>
<li>IN</li>
</ul>
</li>
<li>VQVC：对 <strong>隐变量</strong> 进行 <strong>量化</strong></li>
</ul>
<hr>
<h2 id="2-相关"><a href="#2-相关" class="headerlink" title="2. 相关"></a>2. 相关</h2><h3 id="（一）直接转换语音，不需要单独-“特征解纠缠”"><a href="#（一）直接转换语音，不需要单独-“特征解纠缠”" class="headerlink" title="（一）直接转换语音，不需要单独 “特征解纠缠”"></a>（一）直接转换语音，不需要单独 “特征解纠缠”</h3><ol>
<li>CycleGAN &amp;&amp; StarGAN 专注于解决 <strong>“多对多问题”</strong> </li>
<li>BLOW：基于Flow的方式：<strong>直接对 波形 进行转换，而不用转换成 语音特征</strong></li>
</ol>
<h3 id><a href="#" class="headerlink" title></a></h3><h3 id="（二）-speaker-amp-amp-linguistic-解耦"><a href="#（二）-speaker-amp-amp-linguistic-解耦" class="headerlink" title="（二） speaker &amp;&amp; linguistic 解耦"></a>（二） speaker &amp;&amp; linguistic 解耦</h3><ol>
<li>AutoVC—— AE 结构，通过控制 <strong>隐变量</strong> 尺寸（layer dimension）来实现解纠缠</li>
<li>IN 法<img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201101114502.png" alt="image-20201018105402931"></li>
<li>VQVC</li>
</ol>
<hr>
<h2 id="3-加入-U-Net-的原因："><a href="#3-加入-U-Net-的原因：" class="headerlink" title="3. 加入 U-Net 的原因："></a>3. 加入 U-Net 的原因：</h2><ul>
<li>以上这些 特征解纠缠 的思路可行，但是由于这些额外限制，会使得重构音质受损</li>
<li>U-Net 的重构能力超级强，所以本身是没法做 VC 的，因为她 解纠缠 能力不好</li>
<li>本文尝试 结合 U-Net 的强大重构能力，以及 VQ 的 特征解耦能力，使得转换的语音，在相似度提高的同时，解决流畅度问题；</li>
</ul>
<hr>
<h2 id="4-VQVC-思路："><a href="#4-VQVC-思路：" class="headerlink" title="4. VQVC 思路："></a>4. VQVC 思路：</h2><ul>
<li>内容：离散码</li>
<li>说话人信息：连续语音信号 - 离散码</li>
</ul>
<ol>
<li>先做 Encode 得到隐变量 Z；</li>
<li>再对这个隐变量做 量化，（结合 codebook ），提取出 内容向量 C（content embedding）——不同说话人，说同样一句话，得到的向量趋于相似向量值；</li>
<li>将 Z 和 C 做量化减法，得到 Speaker Embedding——S</li>
</ol>
<p>内容：离散码<br>说话人信息：连续语音信号-离散码</p>
<ol start="4">
<li></li>
</ol>
<hr>
<ul>
<li>Codebook 本身是可训练的</li>
<li><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201018152001.png" alt="image-20201018152000315"></li>
<li><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201018152107.png" alt="image-20201018152105943"></li>
</ul>
<p>公式（1）：</p>
<ul>
<li><p>x（带帽）表示的是 语音 x 中的一个小片段；</p>
</li>
<li><p><strong>argmin</strong> 函数：求取 使得函数 y = f(x) 取得最小值的 x 值集合</p>
</li>
<li><p>将 Encode 之后的 隐变量 z，拿来和 Codebook 中的向量 求取差值最小项（欧式距离）</p>
</li>
<li><p>最后的 $C_x$ 是将上述 x^ 做一个整体的 concate 得到的</p>
</li>
</ul>
<p>公式（2）：</p>
<p>结合（VQVC+）的部分公式 来看：<img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201018152951.png" alt="image-20201018152950185"></p>
<ul>
<li>$E_t$ 表示的是，在所有 T 帧上，求取 Z 和 C 的<strong>期望值 s</strong>，最后将 s 重复 T 次，以此表征 speaker embedding；</li>
<li>重复 T 次是为了让 s 的尺寸 和 C 一样，并方便后续操作</li>
</ul>
<p>公式（3）：</p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201018153359.png" alt="image-20201018153358420"></p>
<ul>
<li>第一个损失： <strong>重构损失</strong> </li>
</ul>
<p>公式（4）、（5）：</p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201018153716.png" alt="image-20201018153714828"></p>
<ul>
<li>第二个损失：隐变量损失 L(latent)</li>
<li>目的是更好地从 隐变量Z 中提取 Content Embedding，来代表整个语音片段的内容部分</li>
<li>🌟值得一提的是：为了让 C 更好地表征内容，在这个环节中，Codebook不做更新：防止网络为了缩小 Loss，而把 Codebook 往 说话人信息方向靠，使得提取出来的 Content Embedding 含有 Spealer 信息；</li>
</ul>
<p>公式（5）：</p>
<ul>
<li>两个 Loss 的叠加</li>
</ul>
<hr>
<h2 id="关于-IN："><a href="#关于-IN：" class="headerlink" title="关于 IN："></a>关于 IN：</h2><ul>
<li>本图来自（VQVC+）：</li>
</ul>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201018154453.png" alt="image-20201018154451621"></p>
<ul>
<li>在 Encode 得到隐变量 z 之后，在进一步提取 content embedding 之前，需要先做一次 IN（Instant Norm）</li>
<li>IN 本身也被其他论文证明，具有</li>
<li>特征解耦 的功效（这里 IN 是必须操作）</li>
<li>这样能预先一步过滤 说话人信息</li>
</ul>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201018160224.png" alt="image-20201018160153595"></p>
<hr>
<h2 id="一些特征处理细节："><a href="#一些特征处理细节：" class="headerlink" title="一些特征处理细节："></a>一些特征处理细节：</h2><ul>
<li>n_mels = 160</li>
<li>GriffinLim</li>
<li>24K</li>
<li>一些额外的规范化normalize 处理：<ul>
<li>减去均值，除以均方差，处理到【0，1】</li>
</ul>
</li>
</ul>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201018155430.png" alt="image-20201018155429424"></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201018155439.png" alt="image-20201018155438508"></p>
<hr>
<h2 id="结果："><a href="#结果：" class="headerlink" title="结果："></a>结果：</h2><ol>
<li>消融实验</li>
</ol>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201018162111.png" alt="image-20201018162109398"></p>
<ol start="2">
<li>ABX 实验<img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201018162140.png" alt="image-20201018162138602"></li>
</ol>
<ol start="3">
<li><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201018162224.png" alt="image-20201018162222357"></p>
</li>
<li><p>Speaker Embedding 区分度：语音片段长度120帧；CodeBook 尺寸 32；训练使用数据 20 人<img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201018162242.png" alt="image-20201018162241525"></p>
</li>
</ol>
<h2 id="疑问点："><a href="#疑问点：" class="headerlink" title="疑问点："></a>疑问点：</h2><ul>
<li><p>量化部分的具体操作看不懂，说的不详细</p>
</li>
<li><p>没有代码对照</p>
</li>
</ul>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201018155903.png" alt="image-20201018155901510"></p>
<hr>
<h2 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h2><ul>
<li>创新意义 &gt; 实用意义</li>
<li>没脱离 AE 结构，还是在隐变量 特征解耦上做文章，效果不突出；</li>
<li>Demo 听起来，语气语调信息损失严重</li>
<li>当作已有方法总结中的一种，不建议使用</li>
</ul>
<hr>
<ul>
<li>开题报告</li>
<li>PPT</li>
<li></li>
</ul>
]]></content>
      <categories>
        <category>论文阅读笔记</category>
      </categories>
      <tags>
        <tag>VC</tag>
        <tag>论文阅读笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>3. 无重复字符的 最长子串</title>
    <url>/2020/06/24/3.%20%E6%97%A0%E9%87%8D%E5%A4%8D%E5%AD%97%E7%AC%A6%E7%9A%84%E6%9C%80%E9%95%BF%E5%AD%90%E4%B8%B2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="1-题目："><a href="#1-题目：" class="headerlink" title="1.题目："></a>1.题目：</h1><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200626183412.png" alt="image-20200624145409923"></p>
<h1 id="2-思路："><a href="#2-思路：" class="headerlink" title="2.思路："></a>2.思路：</h1><ul>
<li><p>见过了那么多 <strong>子串</strong> 系列的题目，这次一起做个总结吧；</p>
</li>
<li><p><a href="https://blog.csdn.net/qq_19446965/article/details/81668047" target="_blank" rel="noopener">最长子序列&amp;最长子串的题型汇总</a></p>
</li>
<li><p><a href="https://blog.csdn.net/wangdd_199326/article/details/76464333" target="_blank" rel="noopener">史上最全最丰富的“最长公共子序列”、“最长公共子串”问题的解法与思路</a></p>
</li>
<li></li>
</ul>
<h1 id="3-滑动窗口的概念："><a href="#3-滑动窗口的概念：" class="headerlink" title="3.滑动窗口的概念："></a>3.滑动窗口的概念：</h1><ul>
<li>利用 <strong>双指针</strong> 来实现；即左指针 表示窗口左边界，右指针 表示窗口右边界；</li>
<li>然后滑动，即意味着 <strong>有序地，左右指针移动</strong></li>
</ul>
<h1 id="4-判断重复字符："><a href="#4-判断重复字符：" class="headerlink" title="4.判断重复字符："></a>4.判断重复字符：</h1><ul>
<li>除了之前学到的 HashMap，还有一个 HashSet（集合）</li>
<li><a href="https://blog.csdn.net/chen213wb/article/details/84647179" target="_blank" rel="noopener">HashMap 和 Hash Set 的差别</a></li>
</ul>
<h1 id="5-代码："><a href="#5-代码：" class="headerlink" title="5.代码："></a>5.代码：</h1><h2 id="法一：用HashSet直接查（里面只存一个值对象）"><a href="#法一：用HashSet直接查（里面只存一个值对象）" class="headerlink" title="法一：用HashSet直接查（里面只存一个值对象）"></a>法一：用HashSet直接查（里面只存一个值对象）</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> 无重复字符的最长子串<span class="title">_3</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">lengthOfLongestSubstring</span><span class="params">(String s)</span></span>&#123;</span><br><span class="line">        <span class="comment">//HashSet:记录每个字符是否出现过</span></span><br><span class="line">        Set&lt;Character&gt; occ = <span class="keyword">new</span> HashSet&lt;Character&gt;();</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">        · set.remove()</span></span><br><span class="line"><span class="comment">        · set.add()</span></span><br><span class="line"><span class="comment">        · srt.contains()</span></span><br><span class="line"><span class="comment">        * */</span></span><br><span class="line">        <span class="comment">//对比：</span></span><br><span class="line"><span class="comment">//        Map&lt;String, String&gt; map = new HashMap&lt;&gt;();</span></span><br><span class="line">        <span class="keyword">int</span> rk = -<span class="number">1</span>,ans = <span class="number">0</span>;<span class="comment">//rk:右指针；</span></span><br><span class="line">        <span class="keyword">int</span> n = s.length();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n ; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(i != <span class="number">0</span>)&#123;<span class="comment">//左指针右移</span></span><br><span class="line">                occ.remove(s.charAt(i-<span class="number">1</span>));</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">while</span>(rk + <span class="number">1</span> &lt; n &amp;&amp; !occ.contains(s.charAt(rk+<span class="number">1</span>)))&#123;</span><br><span class="line">                occ.add(s.charAt(rk+<span class="number">1</span>));</span><br><span class="line">                ++rk;</span><br><span class="line">            &#125;</span><br><span class="line">            ans = Math.max(ans, rk - i + <span class="number">1</span>);<span class="comment">//返回最长的长度值；</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="法二：，更简洁的滑动"><a href="#法二：，更简洁的滑动" class="headerlink" title="法二：，更简洁的滑动"></a>法二：，<a href="https://leetcode-cn.com/problems/longest-substring-without-repeating-characters/solution/hua-jie-suan-fa-3-wu-zhong-fu-zi-fu-de-zui-chang-z/" target="_blank" rel="noopener">更简洁的滑动</a></h2><h2 id="HashMap（Key，-Value）"><a href="#HashMap（Key，-Value）" class="headerlink" title="HashMap（Key， Value）"></a>HashMap（Key， Value）</h2><ul>
<li><p>标签：滑动窗口</p>
</li>
<li><p>暴力解法时间复杂度较高，会达到 O($N^2$)</p>
</li>
<li><p>故而采取滑动窗口的方法降低时间复杂度</p>
</li>
<li><p>定义一个 map 数据结构存储 (k, v)，其中 key 值为字符，value 值为字符位置 +1，加 1 表示从字符位置后一个才开始不重复</p>
</li>
<li><p>我们定义不重复子串的开始位置为 start，结束位置为 end</p>
</li>
<li><p>随着 end 不断遍历向后，会遇到与 [start, end] 区间内字符相同的情况，此时将字符作为 key 值，获取其 value 值，并更新 start，此时 [start, end] 区间内不存在重复字符</p>
</li>
<li><p>无论是否更新 start，都会更新其 map 数据结构和结果 ans。</p>
</li>
<li><p>时间复杂度：O(n)</p>
</li>
<li><pre><code class="java"><span class="keyword">public</span> <span class="keyword">int</span> lengthOfLongestSubstring_滑动窗口(String s){
  <span class="keyword">int</span> n = s.length(), ans = <span class="number">0</span>;
  Map&lt;Character, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();
  <span class="keyword">for</span>(<span class="keyword">int</span> end=<span class="number">0</span>,start=<span class="number">0</span>; end&lt;n; end++){
    <span class="keyword">char</span> alpha = s.charAt(end);
    <span class="keyword">if</span>(map.containsKey(alpha)){
      start = Math.max(map.get(alpha), start);<span class="comment">//这个很重要</span>
    }
    <span class="comment">/*</span>
<span class="comment">    * if(map.containsKey(s.charAt(i)))</span>
<span class="comment">    * j = Math.max(map.get(s.charAt(i)),j);</span>
<span class="comment">    * 为什么有这个判断，是因为在滑动过程中会出现当前loop出现的重复元素之间的区间，</span>
<span class="comment">    * 可能还有其他元素也是重复的。</span>
<span class="comment">    * 如果仅仅 j =map.get(s.charAt(i)) </span>
<span class="comment">    * 则你会忽略两个重复元素之间还有的其他元素也是重复的，</span>
<span class="comment">    * 例如 a bba ，如果没有max，则答案会是3，因为最后一个a和前一个a的间距是3，</span>
<span class="comment">    * 不加max就考虑不到中间两个b也是重复的。）</span>
<span class="comment">    * */</span>
    ans = Math.max(ans, end - start + <span class="number">1</span>);
    map.put(s.charAt(end), end+<span class="number">1</span>);
  }
  <span class="keyword">return</span> ans;
}
&lt;!--￼<span class="number">1</span>--&gt;</code></pre>
</li>
<li><p>返回从 fromIndex 位置开始查找指定字符在字符串中第一次出现处的索引，如果此字符串中没有这样的字符，则返回 -1。</p>
</li>
<li><pre><code class="java"><span class="function"><span class="keyword">int</span> <span class="title">indexOf</span><span class="params">(String str)</span></span>;
&lt;!--￼<span class="number">2</span>--&gt;
</code></pre>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">lengthOfLongestSubstring</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">int</span> flag = <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">int</span> length = <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">int</span> result = <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">while</span> (i &lt; s.length()) &#123;</span><br><span class="line">			<span class="keyword">int</span> pos = s.indexOf(s.charAt(i),flag);</span><br><span class="line">			<span class="keyword">if</span> (pos &lt; i) &#123;</span><br><span class="line">				<span class="keyword">if</span> (length &gt; result) &#123;</span><br><span class="line">					result = length;</span><br><span class="line">				&#125;</span><br><span class="line">				<span class="keyword">if</span> (result &gt;= s.length() - pos - <span class="number">1</span>) &#123;</span><br><span class="line">					<span class="keyword">return</span> result;</span><br><span class="line">				&#125;</span><br><span class="line">				length = i - pos - <span class="number">1</span>;</span><br><span class="line">				flag = pos + <span class="number">1</span>;</span><br><span class="line">			&#125;</span><br><span class="line">			length++;</span><br><span class="line">			i++;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> length;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">作者：VioletKiss</span><br><span class="line">链接：https:<span class="comment">//leetcode-cn.com/problems/longest-substring-without-repeating-characters/solution/javati-jie-3wu-zhong-fu-zi-fu-de-zui-chang-zi-chua/</span></span><br><span class="line">来源：力扣（LeetCode）</span><br><span class="line">著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</span><br></pre></td></tr></table></figure>



]]></content>
      <categories>
        <category>-[Java, 算法] -[LeetCode]</category>
      </categories>
      <tags>
        <tag>-[LeetCode] -[最长子串系列] -[滑动窗口]</tag>
      </tags>
  </entry>
  <entry>
    <title>445.两数相加(顺) II &amp;&amp; 002(逆)</title>
    <url>/2020/06/25/1143.%20%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%AD%90%E5%BA%8F%E5%88%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="1-最长公共子序列："><a href="#1-最长公共子序列：" class="headerlink" title="1.最长公共子序列："></a>1.最长公共子序列：</h1><h2 id="最长公共子序列-LCS-Longest-Common-Subsequence"><a href="#最长公共子序列-LCS-Longest-Common-Subsequence" class="headerlink" title="最长公共子序列(LCS):Longest Common Subsequence"></a>最长公共子序列(LCS):<code>Longest Common Subsequence</code></h2><ul>
<li><p>对于两个子序列 S1 和 S2，找出它们最长的公共子序列。</p>
</li>
<li><p>定义一个二维数组 dp 用来存储最长公共子序列的长度，其中 dp[i][j] 表示 S1 的前 i 个字符与 S2 的前 j 个字符最长公共子序列的长度。考虑 S1i 与 S2j 值是否相等，分为两种情况：</p>
</li>
</ul>
<ol>
<li>当 S1i==S2j 时，那么就能在 S1 的前 i-1 个字符与 S2 的前 j-1 个字符最长公共子序列的基础上再加上 S1i 这个值，最长公共子序列长度加 1，即 dp[i][j] = dp[i-1][j-1] + 1。</li>
<li>当 S1i != S2j 时，此时最长公共子序列为 S1 的前 i-1 个字符和 S2 的前 j 个字符最长公共子序列，或者 S1 的前 i 个字符和 S2 的前 j-1 个字符最长公共子序列，取它们的最大者，即 dp[i][j] = max{ dp[i-1][j], dp[i][j-1] }。</li>
<li>综上，最长公共子序列的状态转移方程为：</li>
</ol>
<p><img src="https://pic.leetcode-cn.com/d8555d9231c57efc399b47af4c358d43df0e45d71bc65a235479d9fb091d4af9-4c4ff66ed0decdde711678563728e0cf_ecd89a22-c075-4716-8423-e0ba89230e9a.jpg" alt="4c4ff66ed0decdde711678563728e0cf_ecd89a22-c075-4716-8423-e0ba89230e9a.jpg"></p>
<ul>
<li>对于长度为 N 的序列 S1 和长度为 M 的序列 S2，dp[N][M] 就是序列 S1 和序列 S2 的最长公共子序列长度。</li>
</ul>
<p>作者：bryank-3<br>链接：<a href="https://leetcode-cn.com/problems/longest-common-subsequence/solution/jian-dan-yi-dong-zui-chang-gong-gong-zi-xu-lie-by-/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/longest-common-subsequence/solution/jian-dan-yi-dong-zui-chang-gong-gong-zi-xu-lie-by-/</a><br>来源：力扣（LeetCode）<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
<h1 id="2-代码"><a href="#2-代码" class="headerlink" title="2.代码"></a>2.代码</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">longestCommonSubsequence</span><span class="params">(String text1, String text2)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n1 = text1.length(), n2 = text2.length();</span><br><span class="line">    <span class="keyword">int</span>[][] dp = <span class="keyword">new</span> <span class="keyword">int</span>[n1 + <span class="number">1</span>][n2 + <span class="number">1</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= n1; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">1</span>; j &lt;= n2; j++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (text1.charAt(i - <span class="number">1</span>) == text2.charAt(j - <span class="number">1</span>)) &#123;</span><br><span class="line">              dp[i][j] = dp[i - <span class="number">1</span>][j - <span class="number">1</span>] + <span class="number">1</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">              dp[i][j] = Math.max(dp[i - <span class="number">1</span>][j], dp[i][j - <span class="number">1</span>]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> dp[n1][n2];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h1 id="3-几种解法："><a href="#3-几种解法：" class="headerlink" title="3.几种解法："></a>3.几种解法：</h1><ol>
<li><h2 id="暴力递归（不用DP-Table）"><a href="#暴力递归（不用DP-Table）" class="headerlink" title="暴力递归（不用DP Table）"></a>暴力递归（不用DP Table）</h2></li>
</ol>
<ul>
<li>是 <strong>从后往前</strong> 比较计数的；</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">longestCommonSubsequence</span><span class="params">(str1, str2)</span> -&gt; int:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dp</span><span class="params">(i, j)</span>:</span></span><br><span class="line">        <span class="comment"># 空串的 base case</span></span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">-1</span> <span class="keyword">or</span> j == <span class="number">-1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> str1[i] == str2[j]:</span><br><span class="line">            <span class="comment"># 这边找到一个 lcs 的元素，继续往前找</span></span><br><span class="line">            <span class="keyword">return</span> dp(i - <span class="number">1</span>, j - <span class="number">1</span>) + <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 谁能让 lcs 最长，就听谁的</span></span><br><span class="line">            <span class="keyword">return</span> max(dp(i<span class="number">-1</span>, j), dp(i, j<span class="number">-1</span>))</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># i 和 j 初始化为最后一个索引</span></span><br><span class="line">    <span class="keyword">return</span> dp(len(str1)<span class="number">-1</span>, len(str2)<span class="number">-1</span>)</span><br></pre></td></tr></table></figure>



<h2 id="2-法二，借用DP-Table来记录（也可用备忘录）"><a href="#2-法二，借用DP-Table来记录（也可用备忘录）" class="headerlink" title="2. 法二，借用DP Table来记录（也可用备忘录）"></a>2. 法二，借用DP Table来记录（也可用备忘录）</h2><ul>
<li>双层遍历：</li>
<li>判断：当前两个字符一样吗？<ul>
<li>一样：左斜上角空格数字（dp[i-1][i-1]） 加1;</li>
<li>不一样：比较 <strong>上</strong> &amp;&amp; <strong>下</strong> 的最大值，取大的那一个来填充当前dp[ i ][ j ]</li>
<li></li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">longestCommonSubsequence</span><span class="params">(str1, str2)</span> -&gt; int:</span></span><br><span class="line">    m, n = len(str1), len(str2)</span><br><span class="line">    <span class="comment"># 构建 DP table 和 base case</span></span><br><span class="line">    dp = [[<span class="number">0</span>] * (n + <span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> range(m + <span class="number">1</span>)]</span><br><span class="line">    <span class="comment"># 进行状态转移</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, m + <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>, n + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> str1[i - <span class="number">1</span>] == str2[j - <span class="number">1</span>]:</span><br><span class="line">                <span class="comment"># 找到一个 lcs 中的字符</span></span><br><span class="line">                dp[i][j] = <span class="number">1</span> + dp[i<span class="number">-1</span>][j<span class="number">-1</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                dp[i][j] = max(dp[i<span class="number">-1</span>][j], dp[i][j<span class="number">-1</span>])</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> dp[<span class="number">-1</span>][<span class="number">-1</span>]</span><br></pre></td></tr></table></figure>

<h2 id="3-优化：用动态数组（一维数组）来解决："><a href="#3-优化：用动态数组（一维数组）来解决：" class="headerlink" title="3. 优化：用动态数组（一维数组）来解决："></a>3. 优化：用动态数组（一维数组）来解决：</h2><ol>
<li>在利用二维dp数组记录dp[ i ][ j ]时，需要用到dp[ i-1 ][ j-1 ] (左上方),dp[ i-1 ][ j ] (上边),dp[ i ][ j-1 ] (左边)。</li>
<li>优化为滚动数组记录dp[ j ] (dp[ i ][ j ]) 时，dp[ j-1 ] ( i-1 ) 已被更新为dp[ j-1 ]（ i ），所以需定义变量last去记录未被更新前的dp[ j-1 ]（ i-1 ）;</li>
<li>所以计算dp[j]的当前值时，会用到last（dp[ i-1 ][ j-1 ]）、dp[ j ] (dp[ i-1 ][ j ])和dp[ j-1 ] (dp[ i ][ j-1 ]);<br><strong>注意：计算每一行的第一个元素时候，last需要初始化为0。</strong></li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">longestCommonSubsequence</span><span class="params">(string text1, string text2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n=text1.size(),m=text2.size();</span><br><span class="line">				<span class="keyword">int</span> dp[m+<span class="number">1</span>],last=<span class="number">0</span>,temp;</span><br><span class="line">				fill(dp,dp+m+<span class="number">1</span>,<span class="number">0</span>);<span class="comment">//fill(数组名，起始地【包括】，结束地【不包括】，填充值)</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=n;++i,last=<span class="number">0</span>)&#123;</span><br><span class="line">						<span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">1</span>;j&lt;=m;++j)&#123;</span><br><span class="line">            	    temp=dp[j];</span><br><span class="line">		   						<span class="keyword">if</span>(text1[i-<span class="number">1</span>]==text2[j-<span class="number">1</span>])	dp[j]=last+<span class="number">1</span>; </span><br><span class="line">		   						<span class="keyword">else</span>	 dp[j]=max(dp[j],dp[j-<span class="number">1</span>]);</span><br><span class="line">        	  			last=temp;</span><br><span class="line">						&#125;</span><br><span class="line">        &#125;</span><br><span class="line">	<span class="keyword">return</span> dp[m];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>



<hr>
<ul>
<li><strong>画一下流程图你就懂了</strong>，顺着 DP Table，按着上面的代码（一维数组）推一遍：</li>
<li><ol>
<li>先用 <strong>temp</strong> 保存当前节点，然后更新当前节点；</li>
<li>其中更新的时候，有两种情况：<ol>
<li>不相等：用 <strong>左边</strong> （体现在一维数组的前一个位置）和 <strong>上面</strong>（体现在一维数组的当前位置）进行比较，取更大的值来刷新当前节点（体现在一维数组当前的位置）</li>
<li>相等：用 <strong>last + 1</strong> ，其中 <strong>last</strong> 表征左上角（是在每一轮结束之后，把之前保存的 <strong>旧的</strong> <strong>当前位置值</strong> 给保存下来；从二位数组角度看来，就是左上角：因为 temp 下一轮已经右移，但是 last 还在上一个位置；）</li>
</ol>
</li>
<li>更新完当前节点位置数据之后，用 <strong>last</strong> 把当前的节点 旧的信息保存下来，last = temp，从二位数组角度看，就像是左上角数据；</li>
<li>然后循环1，2，3步骤</li>
</ol>
</li>
<li>注意，每一行结束更新之后，要把 <strong>last</strong> 重新归零！相当于 左上角数据从零开始重新移动（默认第零行、第零列 全为零）</li>
<li><img src="https://pic.leetcode-cn.com/5722d0bb29dfdf4ba276424fa0901b49ac69a75b32cb009514dca50e2a43c1c4-file_1578114778808" alt="img"></li>
</ul>
]]></content>
      <categories>
        <category>-[Java, 算法] -[LeetCode]</category>
      </categories>
      <tags>
        <tag>-[LeetCode] -[动态规划]</tag>
      </tags>
  </entry>
  <entry>
    <title>139. 单词拆分</title>
    <url>/2020/06/26/139.%20%E5%8D%95%E8%AF%8D%E6%8B%86%E5%88%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="1-解题思路："><a href="#1-解题思路：" class="headerlink" title="1.解题思路："></a>1.解题思路：</h1><ul>
<li>动态规划听上去非常高大上，但是其实都是源自于一个很自然的想法，就拿这道题来说，假如需要判断”onetwothreefour”这一个字符串能不能满足条件，我们很自然的想法就是：</li>
<li>如果”onetwothree”这一段可以拆分，再加上four如果也可以，那不就行了；</li>
<li>或者</li>
<li>如果”onetwothre”这一段可以拆分，再加上efour如果也可以，那不就行了；</li>
<li>这其实已经抓住了动态规划的最核心的东西了，换成式子来表达，就是</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">dp[<span class="string">"onetwothreefour"</span>] = dp[<span class="string">"onetwothree"</span>这一段] &amp;&amp; 判断一下<span class="string">"four"</span></span><br><span class="line">dp[<span class="string">"onetwothreefour"</span>] = dp[<span class="string">"onetwothre"</span>这一段] &amp;&amp; 判断一下<span class="string">"efour"</span></span><br></pre></td></tr></table></figure>



<h1 id="2-代码："><a href="#2-代码：" class="headerlink" title="2.代码："></a>2.代码：</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> 单词拆分<span class="title">_139</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> Map&lt;String, Boolean&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">wordBreak</span><span class="params">(String s, List&lt;String&gt; wordDict)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">boolean</span>[] dp = <span class="keyword">new</span> <span class="keyword">boolean</span>[s.length() + <span class="number">1</span>];</span><br><span class="line">        <span class="comment">//Java boolean数组默认值为False</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//将List中单词放进 HashMap</span></span><br><span class="line">        <span class="keyword">for</span>(String word:wordDict)&#123;</span><br><span class="line">            map.put(word, <span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//初始化</span></span><br><span class="line">        dp[<span class="number">0</span>] = <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//遍历</span></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">        * public String substring(int beginIndex, int endIndex)</span></span><br><span class="line"><span class="comment">        * beginIndex -- 起始索引（包括）, 索引从 0 开始</span></span><br><span class="line"><span class="comment">        * endIndex -- 结束索引（不包括）</span></span><br><span class="line"><span class="comment">        * 索引：读取数组时的下标</span></span><br><span class="line"><span class="comment">        * */</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;s.length();i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=i-<span class="number">1</span>;j&gt;=<span class="number">0</span>;j--)&#123;</span><br><span class="line">                dp[i] = dp[j] &amp;&amp; check(s.substring(j, i));</span><br><span class="line">                <span class="keyword">if</span>(dp[i]) <span class="keyword">break</span>;<span class="comment">//这句也很精髓</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[s.length()];</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">check</span><span class="params">(String s)</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> map.getOrDefault(s, <span class="keyword">false</span>);</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="3-Refrence"><a href="#3-Refrence" class="headerlink" title="3.Refrence"></a>3.<a href="https://leetcode-cn.com/problems/word-break/solution/dan-ci-chai-fen-ju-jue-zhuang-xcong-jian-dan-de-xi/" target="_blank" rel="noopener">Refrence</a></h1>]]></content>
      <categories>
        <category>-[Java, 算法] -[LeetCode]</category>
      </categories>
      <tags>
        <tag>-[LeetCode] -[动态规划]</tag>
      </tags>
  </entry>
  <entry>
    <title>445.两数相加(顺) II &amp;&amp; 002(逆)</title>
    <url>/2020/06/23/445.%20%E4%B8%A4%E6%95%B0%E7%9B%B8%E5%8A%A0%20II%20(%E9%A1%BA)%20&amp;&amp;%20001(%E9%80%86)/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="1-445题目"><a href="#1-445题目" class="headerlink" title="1.445题目"></a>1.<a href="https://leetcode-cn.com/problems/add-two-numbers-ii/" target="_blank" rel="noopener">445题目</a></h1><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200626183507.png" alt="image-20200623182854483"></p>
<h1 id="2-类型：链表-amp-amp-栈"><a href="#2-类型：链表-amp-amp-栈" class="headerlink" title="2.类型：链表 &amp;&amp; 栈"></a>2.类型：链表 &amp;&amp; 栈</h1><p>正序的数字链表，求和时希望从个位开始算（逆序算），所以应该想到利用 <strong>栈</strong>（FILO）</p>
<h1 id="3-与002区别："><a href="#3-与002区别：" class="headerlink" title="3.与002区别："></a>3.与002区别：</h1><ul>
<li><p>002采用的是直接逆序存储的数字链表，所以可以直接从数字的尾巴开始求和，另外增加一个 <strong>进位标志符号</strong> 就可以；</p>
</li>
<li></li>
</ul>
<hr>
<h1 id="4-代码-Java"><a href="#4-代码-Java" class="headerlink" title="4.代码 Java"></a>4.代码 Java</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">twoSum_445</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ListNode</span> </span>&#123;</span><br><span class="line">         <span class="keyword">int</span> val;</span><br><span class="line">         ListNode next;</span><br><span class="line">         ListNode(<span class="keyword">int</span> x) &#123; val = x; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment">     * public class ListNode &#123;</span></span><br><span class="line"><span class="comment">     *     int val;</span></span><br><span class="line"><span class="comment">     *     ListNode next;</span></span><br><span class="line"><span class="comment">     *     ListNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment">     * &#125;</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ListNode <span class="title">addTwoNumbers</span><span class="params">(ListNode l1, ListNode l2)</span> </span>&#123;</span><br><span class="line">        Stack&lt;Integer&gt; stack1 = <span class="keyword">new</span> Stack&lt;&gt;();</span><br><span class="line">        Stack&lt;Integer&gt; stack2 = <span class="keyword">new</span> Stack&lt;&gt;();</span><br><span class="line">        <span class="keyword">while</span>( l1 != <span class="keyword">null</span>)&#123;</span><br><span class="line">            stack1.push(l1.val);</span><br><span class="line">            l1 = l1.next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span>( l2 != <span class="keyword">null</span>)&#123;</span><br><span class="line">            stack2.push(l2.val);</span><br><span class="line">            l2 = l2.next;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> carry = <span class="number">0</span>;<span class="comment">//进位符号</span></span><br><span class="line">        ListNode head = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">while</span>(!stack1.empty() || !stack2.empty())&#123;</span><br><span class="line">            <span class="keyword">int</span> sum = carry;</span><br><span class="line">            sum += stack1.isEmpty()? <span class="number">0</span>:stack1.pop();</span><br><span class="line">            sum += stack1.isEmpty()? <span class="number">0</span>:stack2.pop();</span><br><span class="line">            ListNode node = <span class="keyword">new</span> ListNode(sum % <span class="number">10</span>);</span><br><span class="line">            node.next = head;</span><br><span class="line">            head = node;</span><br><span class="line">            carry = sum / <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> head;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<hr>
<h1 id="5-比较-002-代码："><a href="#5-比较-002-代码：" class="headerlink" title="5.比较 002 代码："></a>5.比较 002 代码：</h1><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200626183508.png" alt="image-20200623182835143"></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * public class ListNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     ListNode next;</span></span><br><span class="line"><span class="comment"> *     ListNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">twoSum_002</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ListNode</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> val;</span><br><span class="line">        ListNode next;</span><br><span class="line">        ListNode(<span class="keyword">int</span> x) &#123; val = x; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//这份写的更漂亮，更优美，学习一个！</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ListNode <span class="title">addTwoNumbers</span><span class="params">(ListNode l1, ListNode l2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> carry = <span class="number">0</span>;</span><br><span class="line">        ListNode dummyHead = <span class="keyword">new</span> ListNode(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        ListNode p = l1, q = l2, curr = dummyHead;</span><br><span class="line">        <span class="keyword">while</span>(p != <span class="keyword">null</span> || q!= <span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">int</span> x = (p != <span class="keyword">null</span>)? p.val : <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">int</span> y = (q != <span class="keyword">null</span>)? q.val : <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">int</span> sum = x + y + carry;</span><br><span class="line">            carry = sum / <span class="number">10</span>;</span><br><span class="line">            curr.next = <span class="keyword">new</span> ListNode(sum % <span class="number">10</span>);</span><br><span class="line">            curr = curr.next;</span><br><span class="line">            <span class="keyword">if</span>(p != <span class="keyword">null</span>) p = p.next;</span><br><span class="line">            <span class="keyword">if</span>(q != <span class="keyword">null</span>) q = q.next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(carry &gt; <span class="number">0</span>)&#123;</span><br><span class="line">            curr.next = <span class="keyword">new</span> ListNode(carry);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dummyHead.next;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//这个我自己写的，改了好多地方才对，细节很多</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ListNode <span class="title">addTwoNumber_HSJ</span><span class="params">(ListNode l1, ListNode l2)</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> carry = <span class="number">0</span>;</span><br><span class="line">        ListNode head = <span class="keyword">new</span> ListNode(<span class="number">0</span>);</span><br><span class="line">        ListNode curr = head;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span>( l1 != <span class="keyword">null</span> || l2 != <span class="keyword">null</span>)&#123;<span class="comment">//细节，不是 l1.next !!!</span></span><br><span class="line">            <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">            sum += carry;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span>( l1 != <span class="keyword">null</span>)</span><br><span class="line">                sum += l1.val;</span><br><span class="line">            <span class="keyword">if</span>( l2 != <span class="keyword">null</span>)</span><br><span class="line">                sum += l2.val;</span><br><span class="line"></span><br><span class="line">            ListNode node = <span class="keyword">new</span> ListNode(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">            carry = sum / <span class="number">10</span>;</span><br><span class="line">            node.val = sum % <span class="number">10</span>;</span><br><span class="line">            curr.next = node;</span><br><span class="line">            curr = node;</span><br><span class="line"><span class="comment">//            node.next = head;</span></span><br><span class="line"><span class="comment">//            head = node;</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span>(l1 != <span class="keyword">null</span>) l1 = l1.next;</span><br><span class="line">            <span class="keyword">if</span>(l2 != <span class="keyword">null</span>) l2 = l2.next;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(carry &gt; <span class="number">0</span>)&#123;<span class="comment">//细节！</span></span><br><span class="line">            curr.next = <span class="keyword">new</span> ListNode(carry);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> head.next;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>-[Java, 算法] -[LeetCode]</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title>67. 二进制求和</title>
    <url>/2020/06/23/67.%20%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%B1%82%E5%92%8C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="1-一些新的知识点："><a href="#1-一些新的知识点：" class="headerlink" title="1.一些新的知识点："></a>1.一些新的知识点：</h1><ul>
<li>当对字符串进行修改的时候，需要使用 StringBuffer 和 StringBuilder 类。</li>
</ul>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200626183450.png" alt="image-20200623191413447"></p>
<ul>
<li>“charAt() 方法用于返回指定索引处的字符。索引范围为从 0 到 length() - 1。”</li>
<li><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200626183451.png" alt="image-20200623191946701"></li>
<li>Java 的反转函数 reverse() 将字符串反转</li>
<li>string.reverse（）；</li>
<li><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200626183452.png" alt="image-20200623192245991"></li>
<li>位运算符：</li>
<li><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200626183453.png" alt="image-20200623193029996"></li>
<li>^ : 按位抑或：不进位的加法：</li>
</ul>
<h1 id="2-想法"><a href="#2-想法" class="headerlink" title="2.想法"></a>2.想法</h1><ul>
<li>突然看到string字符串求和，想起了以前的各种题目，但是很没有头绪；</li>
<li>印象中，都是用最笨的 <strong>数组</strong> 的方式来进行，从没有尝试过用string来进行处理；</li>
</ul>
<p>是个学习的机会；</p>
<hr>
<h1 id="3"><a href="#3" class="headerlink" title="3."></a>3.</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">addBinary</span><span class="params">(String a, String b)</span> </span>&#123;</span><br><span class="line">        StringBuffer ans = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">        <span class="keyword">int</span> carry = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> n = Math.max(a.length(),b.length());</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">            <span class="comment">//string.charAt（）:寻找当前string在指定位置的 字符 char；</span></span><br><span class="line">            <span class="comment">// 细节： string.length() 需要用上括号！ 别忘记括号！</span></span><br><span class="line">            carry += i &lt; a.length()? (a.charAt(a.length() - <span class="number">1</span> - i) - <span class="string">'0'</span>) : <span class="number">0</span>;</span><br><span class="line">            carry += i &lt; b.length()? (b.charAt(b.length() - <span class="number">1</span> - i) - <span class="string">'0'</span>) : <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">            ans.append((<span class="keyword">char</span>)(carry % <span class="number">2</span> + <span class="string">'0'</span>));</span><br><span class="line">            carry /= <span class="number">2</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(carry &gt; <span class="number">0</span>)&#123;</span><br><span class="line">            ans.append(<span class="string">'1'</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        ans.reverse();<span class="comment">// 这个方法实现的功能是，将 StringBuffer 字符串进行反转！！！</span></span><br><span class="line">        <span class="keyword">return</span> ans.toString();</span><br><span class="line">      <span class="comment">//因为是 StringBuffer 类型，而返回类型要求是 String，所以调用 toString（）方法；</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



]]></content>
      <categories>
        <category>-[Java, 算法] -[LeetCode]</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title>《Voice Conversion with transformer network-samsung》论文总结</title>
    <url>/2020/08/15/NVAE%EF%BC%8C%E7%AC%94%E8%AE%B0%E4%B8%8E%E6%B7%B1%E6%8C%96/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="NVAE"><a href="#NVAE" class="headerlink" title="NVAE"></a>NVAE</h1><ol>
<li><p>先大致搞清楚 VAE<img src="https://spaces.ac.cn/usr/uploads/2018/03/4168876662.png" alt="为了使模型具有生成能力，vae要求每个p(https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200810181426.png)都向正态分布看齐"></p>
<a id="more"></a>
</li>
<li><p>有两个 <strong>Encoder</strong>，一个求 $\mu$， 一个求 $\sigma$<img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200810171034.png" alt="img"></p>
</li>
<li><p>说一下 VAE 中的「正态分布拟合」以及「从拟合的正态分布中采样」（Box-Muller 等等方法）<img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200810171405.png" alt="image-20200810171404665"></p>
</li>
<li><p>VAE的名字中“变分”，是因为它的推导过程用到了<strong>KL散度及其性质</strong></p>
</li>
<li><p>说一说 <strong>VAE中的噪声</strong>（方差）</p>
<ol>
<li>增加重构难度，所以想减小它，让生成的数据更清晰</li>
<li>但是正是这个噪声，才是VAE精髓，增加了随机性</li>
</ol>
</li>
<li><p>噪声的好处（增加随机性） 和 坏处（导致采样结果成为确定性结果——均值 u ）</p>
</li>
<li><p>对噪声的处理：</p>
<ol>
<li>不直接让 方差 变为0（导致退化成 <strong>AE</strong> ）</li>
<li>而是配合着，让每段语音数据的 <strong>后验分布</strong> 朝着正态分布区靠近</li>
<li><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200810162409.png" alt="image-20200810162407100"></li>
<li><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200810162445.png" alt="image-20200810162443056"></li>
</ol>
</li>
<li><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200810170403.png" alt="image-20200810170401384"></p>
</li>
<li><p><strong>关于 后验分布 &amp;&amp; 先验分布 的理解</strong>（公式（2））</p>
<ol>
<li>后：单独的一段语音的高斯分布（标准正态）</li>
<li>先：某个说话人，所有语音的高斯分布集合（也是符合标准正态）</li>
</ol>
</li>
<li><p>VAE 中的 KL-loss <img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200810171818.png" alt="image-20200810171816918"></p>
</li>
<li><p>CVAE中的KL-loss（一类方法：实现标签的加入，从 <strong>无监督</strong> 转为 <strong>有监督</strong>）<img src="/2020/08/15/NVAE%EF%BC%8C%E7%AC%94%E8%AE%B0%E4%B8%8E%E6%B7%B1%E6%8C%96/huangshengjie/Documents/2020/%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99hexo%E6%B5%8B%E8%AF%95/Typora%E5%8D%9A%E5%AE%A2%E5%9B%BE%E7%89%87%E6%96%87%E4%BB%B6%E5%A4%B9/20200810172007.png" alt="image-20200810172006118"><strong>我们可以希望同一个类的样本都有一个专属的均值 $μ^Y$， （方差不变，还是单位方差），这个$μ^Y$让模型自己训练出来</strong></p>
</li>
<li><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200810172258.png" alt="img">【CVAE结构图】</p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python preprocess.py --resample_rate 16000 \</span><br><span class="line">                     --origin_wavpath .&#x2F;data&#x2F;VCTK-Data&#x2F;VCTK-Corpus&#x2F;wav48 \</span><br><span class="line">                     --target_wavpath .&#x2F;data&#x2F;VCTK-Data&#x2F;VCTK-Corpus&#x2F;wav16 \</span><br><span class="line">                     --mc_dir_train .&#x2F;data&#x2F;VCTK-Data&#x2F;mc&#x2F;train \</span><br><span class="line">                     --mc_dir_test .&#x2F;data&#x2F;VCTK-Data&#x2F;mc&#x2F;test \</span><br><span class="line">                     --speaker_dirs p262 p272 p229 p232 p292 p293 p360 p361 p248 p251</span><br></pre></td></tr></table></figure>





<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python main.py --train_data_dir .&#x2F;data&#x2F;VCTK-Data&#x2F;mc&#x2F;train \</span><br><span class="line">               --test_data_dir .&#x2F;data&#x2F;VCTK-Data&#x2F;mc&#x2F;test \</span><br><span class="line">               --use_tensorboard False \</span><br><span class="line">               --wav_dir .&#x2F;data&#x2F;VCTK-Data&#x2F;VCTK-Corpus&#x2F;wav16 \</span><br><span class="line">               --model_save_dir .&#x2F;data&#x2F;aca16sjb&#x2F;VCTK-Data&#x2F;models \</span><br><span class="line">               --sample_dir .&#x2F;data&#x2F;VCTK-Data&#x2F;samples \</span><br><span class="line">               --num_iters 200000 \</span><br><span class="line">               --batch_size 8 \</span><br><span class="line">               --speakers p262 p272 p229 p232 \</span><br><span class="line">               --num_speakers 4</span><br></pre></td></tr></table></figure>



<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python convert.py --resume_model 120000 \</span><br><span class="line">                  --num_speakers 4 \</span><br><span class="line">                  --speakers p262 p272 p229 p232 \</span><br><span class="line">                  --train_data_dir .&#x2F;data&#x2F;VCTK-Data&#x2F;mc&#x2F;train&#x2F; \</span><br><span class="line">                  --test_data_dir .&#x2F;data&#x2F;VCTK-Data&#x2F;mc&#x2F;test&#x2F; \</span><br><span class="line">                  --wav_dir .&#x2F;data&#x2F;VCTK-Data&#x2F;VCTK-Corpus&#x2F;wav16 \</span><br><span class="line">                  --model_save_dir .&#x2F;data&#x2F;aca16sjb&#x2F;VCTK-Data&#x2F;models \</span><br><span class="line">                  --convert_dir .&#x2F;data&#x2F;VCTK-Data&#x2F;converted</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>论文阅读笔记</category>
      </categories>
      <tags>
        <tag>VC</tag>
        <tag>论文阅读笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>Clion中的EOF</title>
    <url>/2020/06/21/Clion%E4%B8%AD%E7%9A%84EOF/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="1-问题："><a href="#1-问题：" class="headerlink" title="1.问题："></a>1.问题：</h1><p>在Mac &amp; Clion 中尝试使用 </p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="built_in">cin</span> &gt;&gt; varient)&#123;&#125;</span><br></pre></td></tr></table></figure>

<p>来作为输入结束判断时，由于判断的是“流”结束与否（具体不钻牛角尖），即在win环境下，一般是使用 <strong>CTRL+C</strong>结束，而在Clion中这个方法不行。</p>
<h1 id="2-解决："><a href="#2-解决：" class="headerlink" title="2.解决："></a>2.解决：</h1><ul>
<li><p>有很多博客说使用 <strong>CTRL+D</strong> /<strong>Command + D</strong>，均失败</p>
</li>
<li><p>有效方法：以 <strong>Debug模式</strong> 运行程序，正确输入数据之后—&gt;回车—&gt; command +D</p>
</li>
</ul>
<hr>
<p>以上，谨此纪念C++修习结束。</p>
<p>很多人说Python 比Cpp好学，我觉得不然。这句话可能只能仅限于 使用单纯语言自身特性上；若是要再加上语言的各种外载功能包，还指不定孰优孰劣呢。</p>
<p>在学习TF、Torch的路上，被各种乱七八糟的工具包整的落花流水。</p>
<p>实习实习找的不顺，想来也是自己基础实在没有打扎实，虽说自己是反抗成为上班族的，但是在发觉自己在想衡量自己的市场价值的时候竟然这么不值钱，就心里不爽万分。</p>
<p>再把合成相关的东西学学吧，没啥学不会的。</p>
<hr>
<p>06_21_2020 Sunday</p>
<p>@PT</p>
]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>PGAN 训练笔记</title>
    <url>/2020/12/08/PGAN%20%E8%AE%AD%E7%BB%83%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>PGAN 训练笔记</p>
<hr>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201208221357.png" alt="image-20201208221355969"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;path&#x2F;to&#x2F;database  &#x3D;  &#x2F;big_data&#x2F;hsj&#x2F;ParallelWaveGAN&#x2F;egs&#x2F;aishell3&#x2F;wav</span><br></pre></td></tr></table></figure>



<hr>
<ul>
<li>目前使用的是，所有 AiShell3数据集，但是用的是 single_speaker 的代码</li>
<li>数据的处理用到了 sklearn.StandardScaler 的 「均值、方差」归一化，（对训练集），所以咱们StarGAN-vc2中也暂时不自己写 数据预处理的环节了，用他处理好的 .npy 来读取，然后再做 【截取固定帧数】的操作</li>
</ul>
<hr>
<h2 id="StarGAN-VC2-一些参数："><a href="#StarGAN-VC2-一些参数：" class="headerlink" title="StarGAN-VC2 一些参数："></a>StarGAN-VC2 一些参数：</h2><ul>
<li><strong>batch_size</strong>=8</li>
<li><strong>learning_rate_G</strong> = 0.0002 ｜ <strong>learning_rate_D</strong> = 0.0001</li>
<li>每条句子切成 ：<strong>128 帧</strong> </li>
</ul>
<ul>
<li><strong>22050Hz</strong></li>
<li><strong>34 维度 sp</strong></li>
<li><strong>帧移</strong>： 5ms</li>
<li></li>
</ul>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201209191607.png" alt="image-20201209191606378"></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201209191843.png" alt="image-20201209191842901"></p>
<hr>
<h2 id="VC-2-结构："><a href="#VC-2-结构：" class="headerlink" title="VC 2 结构："></a>VC 2 结构：</h2><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201209193704.png" alt="image-20201209193703036"></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201209193747.png" alt="image-20201209193746702"></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201209193731.png" alt="image-20201209193730230"></p>
<hr>
<h2 id="VC-1-结构"><a href="#VC-1-结构" class="headerlink" title="VC 1 结构"></a>VC 1 结构</h2><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201209193905.png" alt="image-20201209193903655"></p>
<hr>
<h2 id="Torch官方算卷积的公式"><a href="#Torch官方算卷积的公式" class="headerlink" title="Torch官方算卷积的公式"></a>Torch官方算卷积的公式</h2><p><a href="https://pytorch.org/docs/master/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" target="_blank" rel="noopener">https://pytorch.org/docs/master/generated/torch.nn.Conv2d.html#torch.nn.Conv2d</a></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201209202938.png" alt="image-20201209202936687"></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201209202948.png" alt="image-20201209202947175"></p>
<hr>
<p><a href="https://blog.csdn.net/qiu931110/article/details/104292129![image-20201210134725352](https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201210134726.png)" target="_blank" rel="noopener">https://blog.csdn.net/qiu931110/article/details/104292129![image-20201210134725352](https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201210134726.png)</a></p>
<p><a href="https://www.jianshu.com/p/d8b77cc02410" target="_blank" rel="noopener">https://www.jianshu.com/p/d8b77cc02410</a></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201210134801.png" alt="image-20201210134800412"></p>
<hr>
<h2 id="Tensorflow-版本的-CIN"><a href="#Tensorflow-版本的-CIN" class="headerlink" title="Tensorflow 版本的 CIN"></a>Tensorflow 版本的 <a href="https://github.com/MingtaoGuo/Conditional-Instance-Norm-for-n-Style-Transfer/blob/master/ops.py#L5" target="_blank" rel="noopener">CIN</a></h2><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201210152752.png" alt="image-20201210152751386"></p>
<p>参考这两份：</p>
<ul>
<li><strong>Torch</strong>：<a href="https://github.com/ChinmayLad/neural-style-transfer/blob/dc44cd261fd9bdf684440ef104cec65fe5be15c5/normalization.py" target="_blank" rel="noopener">https://github.com/ChinmayLad/neural-style-transfer/blob/dc44cd261fd9bdf684440ef104cec65fe5be15c5/normalization.py</a></li>
<li><strong>TensorFlow</strong>:<a href="https://github.com/MingtaoGuo/Conditional-Instance-Norm-for-n-Style-Transfer/blob/master/ops.py#L5" target="_blank" rel="noopener">https://github.com/MingtaoGuo/Conditional-Instance-Norm-for-n-Style-Transfer/blob/master/ops.py#L5</a></li>
<li><a href="https://github.com/MingtaoGuo/Conditional-Instance-Norm-for-n-Style-Transfer/issues/1" target="_blank" rel="noopener">对应回答</a> issue</li>
<li><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201210163236.png" alt="image-20201210163234409"></li>
<li></li>
</ul>
<p>1211:</p>
<h1 id="CIN-个人理解："><a href="#CIN-个人理解：" class="headerlink" title="CIN 个人理解："></a>CIN 个人理解：</h1><p><strong>输入：</strong>one-hot = 【1，0，0，0，】 ；特征 x =【8，512，32】=【batch， channel=每个单词用多少特征来表示俄mbedding， 句子长度=含有32个单词】</p>
<p><strong>过程：</strong></p>
<ol>
<li>先是构造一张特征表，尺寸为【说话人数目 / 特征种类， 每个说话人 用多少维度的embedding 来表示 / 每个单词的特征通道数「一维角度来看」】 = 【4， 512】</li>
<li>然后，用对应的一个说话人的 one-hot 来取这张表上的特征值 【1，num_styles=4】x【num_styles=4，num_in=特征数=512】</li>
<li>在这个过程中，我们用Torch实现时，可以用 $nn.linear()$ 函数（看作全连接）来表示矩阵乘法：nn.linears（in_channel = 4, out_channel = 512）——<strong>nn.linear（）中的参数是可训练的！会加入到整张图的参数列表中去</strong></li>
<li>然后把 one-hot 特征送进全连接网络，得到对应的一个特征【512维】，$\gamma$ 和 $\beta$ 都是这么处理的</li>
<li>最后 ， 两个特征参数，和前面送进来的并经过 <strong>均值 &amp; 归一化 处理过的 x</strong> ，相互配合起来，得到当前层的 <strong>CIN</strong> 结果</li>
</ol>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201211171011.png" alt="image-20201211171010810"></p>
<hr>
<h2 id="关于PixelShuffle"><a href="#关于PixelShuffle" class="headerlink" title="关于PixelShuffle"></a>关于PixelShuffle</h2><ol>
<li><a href="https://blog.csdn.net/g11d111/article/details/82855946" target="_blank" rel="noopener">https://blog.csdn.net/g11d111/article/details/82855946</a></li>
<li><a href="https://blog.csdn.net/u014636245/article/details/98071626" target="_blank" rel="noopener">https://blog.csdn.net/u014636245/article/details/98071626</a></li>
<li><a href="https://pytorch.org/docs/0.3.1/_modules/torch/nn/modules/pixelshuffle.html" target="_blank" rel="noopener">https://pytorch.org/docs/0.3.1/_modules/torch/nn/modules/pixelshuffle.html</a></li>
</ol>
<hr>
<h2 id="关于-GSP：global-sum-pooling"><a href="#关于-GSP：global-sum-pooling" class="headerlink" title="关于 GSP：global sum pooling"></a>关于 GSP：global sum pooling</h2><hr>
<h2 id="关于-inner-product-向量内积-https-zhuanlan-zhihu-com-p-212461087"><a href="#关于-inner-product-向量内积-https-zhuanlan-zhihu-com-p-212461087" class="headerlink" title="关于 inner product 向量内积 https://zhuanlan.zhihu.com/p/212461087"></a>关于 inner product 向量内积 <a href="https://zhuanlan.zhihu.com/p/212461087" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/212461087</a></h2><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201211013638.png" alt="image-20201211013636895"></p>
<hr>
<h1 id="整个模型-尺寸信息："><a href="#整个模型-尺寸信息：" class="headerlink" title="整个模型 尺寸信息："></a>整个模型 尺寸信息：</h1><ol>
<li>原本 <strong>Generator</strong> 尺寸：<img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201211172645.png" alt="image-20201211172644404"></li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>Shell_find命令备忘小结</title>
    <url>/2020/11/27/Shell_find%E5%91%BD%E4%BB%A4%E5%A4%87%E5%BF%98%E5%B0%8F%E7%BB%93/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id><a href="#" class="headerlink" title></a></h2><p><a href="https://www.cnblogs.com/huyuanblog/p/10136286.html" target="_blank" rel="noopener">参考文章</a></p>
<h2 id="问题来源：Kaldi-librispeech-example：数据预处理脚本文件："><a href="#问题来源：Kaldi-librispeech-example：数据预处理脚本文件：" class="headerlink" title="问题来源：Kaldi librispeech example：数据预处理脚本文件："></a>问题来源：<strong>Kaldi</strong> librispeech example：数据预处理脚本文件：</h2><p><strong>path = kaldi/egs/librispeech/s5/local/da ta_prep.sh</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 双重<span class="keyword">for</span>循环</span></span><br><span class="line"><span class="meta">#</span><span class="bash">第一层循环，按说话人</span></span><br><span class="line">for reader_dir in $(find -L $src -mindepth 1 -maxdepth 1 -type d | sort); do</span><br><span class="line">  reader=$(basename $reader_dir)</span><br><span class="line">  if ! [ $reader -eq $reader ]; then  # not integer.</span><br><span class="line">    echo "$0: unexpected subdirectory name $reader"</span><br><span class="line">    exit 1;</span><br><span class="line">  fi</span><br><span class="line">  </span><br><span class="line"><span class="meta">	#</span><span class="bash"> 从说话人信息文件中提取性别</span></span><br><span class="line">  reader_gender=$(egrep "^$reader[ ]+\|" $spk_file | awk -F'|' '&#123;gsub(/[ ]+/, ""); print tolower($2)&#125;')</span><br><span class="line">  if [ "$reader_gender" != 'm' ] &amp;&amp; [ "$reader_gender" != 'f' ]; then</span><br><span class="line">    echo "Unexpected gender: '$reader_gender'"</span><br><span class="line">    exit 1;</span><br><span class="line">  fi</span><br><span class="line">  </span><br><span class="line"><span class="meta">	#</span><span class="bash">第二重<span class="keyword">for</span>循环，按章节</span></span><br><span class="line">  for chapter_dir in $(find -L $reader_dir/ -mindepth 1 -maxdepth 1 -type d | sort); do</span><br><span class="line">    chapter=$(basename $chapter_dir)</span><br><span class="line">    if ! [ "$chapter" -eq "$chapter" ]; then</span><br><span class="line">      echo "$0: unexpected chapter-subdirectory name $chapter"</span><br><span class="line">      exit 1;</span><br><span class="line">    fi</span><br><span class="line"></span><br><span class="line">    find -L $chapter_dir/ -iname "*.flac" | sort | xargs -I% basename % .flac | \</span><br><span class="line">      awk -v "dir=$chapter_dir" '&#123;printf "%s flac -c -d -s %s/%s.flac |\n", $0, dir, $0&#125;' &gt;&gt;$wav_scp|| exit 1</span><br><span class="line"></span><br><span class="line">    chapter_trans=$chapter_dir/$&#123;reader&#125;-$&#123;chapter&#125;.trans.txt</span><br><span class="line">    [ ! -f  $chapter_trans ] &amp;&amp; echo "$0: expected file $chapter_trans to exist" &amp;&amp; exit 1</span><br><span class="line">    cat $chapter_trans &gt;&gt;$trans</span><br><span class="line"></span><br><span class="line">    # NOTE: For now we are using per-chapter utt2spk. That is each chapter is considered</span><br><span class="line">    #       to be a different speaker. This is done for simplicity and because we want</span><br><span class="line">    #       e.g. the CMVN to be calculated per-chapter</span><br><span class="line">    awk -v "reader=$reader" -v "chapter=$chapter" '&#123;printf "%s %s-%s\n", $1, reader, chapter&#125;' \</span><br><span class="line">      &lt;$chapter_trans &gt;&gt;$utt2spk || exit 1</span><br><span class="line"></span><br><span class="line">    # reader -&gt; gender map (again using per-chapter granularity)</span><br><span class="line">    echo "$&#123;reader&#125;-$&#123;chapter&#125; $reader_gender" &gt;&gt;$spk2gender</span><br><span class="line">  done</span><br><span class="line">done</span><br></pre></td></tr></table></figure>



<h3 id="命令语句解析"><a href="#命令语句解析" class="headerlink" title="命令语句解析"></a>命令语句解析</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">(find -L $src -mindepth 1 -maxdepth 1 -type d | sort)</span><br></pre></td></tr></table></figure>

<blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash"><span class="comment"># 使用格式</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">find [-H] [-L] [-P] [-D debugopts] [-Olevel] [path...] [expression]</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">和符号链接相关的选项:</span></span><br><span class="line">   -P   不跟踪符号链接(默认行为)</span><br><span class="line">   -L   当 find 检查或打印有关文件的信息时, 所使用的信息应取自链接指向的文件的属性, 而不是链接本身</span><br><span class="line">   -H   和 -L 参数刚好相反, 当 find 检查或打印有关文件的信息时, 所使用的信息应取自符号链接的属性</span><br></pre></td></tr></table></figure>



<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">EXPRESSIONS(表达式):</span></span><br><span class="line"> OPTIONS(选项):</span><br><span class="line">   -d、-depth       在查找文件时, 首先查找当前目录中的文件, 然后再在其子目录中查找</span><br><span class="line">   -maxdepth n       find 查找目录的最大深度</span><br><span class="line">   -mindepth n       find 从指定的目录的第几层深度开始查找</span><br><span class="line">   -mount         查找文件时不跨越文件系统的 mount 点</span><br><span class="line">   -follow         和 ``-``L 参数类似</span><br><span class="line">   -regextype       指定后面所使用的正则表达式语法, 默认为 emacs</span><br><span class="line">     posix-awk        类 awk 的正则表达式语法 </span><br><span class="line">     posix-basic       基本正则表达式</span><br><span class="line">     posix-egrep       不使用正则表达式</span><br><span class="line">     posix-extended     扩展正则表达式</span><br></pre></td></tr></table></figure>



<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">-<span class="built_in">type</span></span></span><br><span class="line">       b   块设备</span><br><span class="line">       c   字符设备</span><br><span class="line">       d   目录</span><br><span class="line">       p   命名管道</span><br><span class="line">       f   文件</span><br><span class="line">       l   链接文件</span><br><span class="line">       s   socket 文件</span><br></pre></td></tr></table></figure>


</blockquote>
<hr>
<p>🌟 想起顾芯怡教的一招</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hdfs dfs -ls     - hdfs://haruna/home/byte_arnold_hl_speech_asr/user/huanglu.thu19/corpus/edu/chinglish_haitian_2kh_16k/wav_ark/k190/*.scp | wc -l</span><br></pre></td></tr></table></figure>

<blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">🌟 wc -l  <span class="comment"># 统计文件个数</span></span></span><br></pre></td></tr></table></figure>



<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">🌟 ls -l *.wav | wc -l  <span class="comment"># 统计某个目录下 某种后缀的文件个数</span></span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">ls -l *.wav | grep <span class="string">"^-"</span> | wc -l</span></span><br></pre></td></tr></table></figure>
</blockquote>
<blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">grep <span class="string">"^-"</span>  <span class="comment"># 过滤ls的输出信息，只保留一般文件，只保留目录是grep "^d"。</span></span></span><br></pre></td></tr></table></figure>
</blockquote>
<p>🌟 在自己电脑下，还是得 <strong>cd 到指定路径下</strong>才行，字节的 HDFS 数据库是只能那么读取列表，所以才可以那么用</p>
<hr>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> basename /tmp/<span class="built_in">test</span>/file.txt</span></span><br><span class="line">file.txt</span><br><span class="line"><span class="meta">$</span><span class="bash"> basename /tmp/<span class="built_in">test</span>/file.txt .txt</span></span><br><span class="line">file</span><br></pre></td></tr></table></figure>

<blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">basename [pathname] [suffix]</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">basename [string] [suffix]</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">suffix为后缀，如果suffix被指定了，basename会将pathname或string中的suffix去掉。</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">$ basename <span class="variable">$PWD</span>/1027.md </span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">1027.md</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">$ basename <span class="variable">$PWD</span>/1027.md .md</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">1027</span></span><br></pre></td></tr></table></figure>
</blockquote>
<hr>
<h3 id="🌟awk-命令：一种处理文本文件的语言"><a href="#🌟awk-命令：一种处理文本文件的语言" class="headerlink" title="🌟awk 命令：一种处理文本文件的语言"></a><strong>🌟awk</strong> 命令：一种处理文本文件的语言</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 从说话人信息文件中提取性别</span></span><br><span class="line">reader_gender=$(egrep "^$reader[ ]+\|" $spk_file | awk -F'|' '&#123;gsub(/[ ]+/, ""); print tolower($2)&#125;')</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>-[Kaldi] -[Shell]</category>
      </categories>
      <tags>
        <tag>-[Shell] -[Kaldi]</tag>
      </tags>
  </entry>
  <entry>
    <title>Sox环境解决办法</title>
    <url>/2020/11/29/Sox%E7%8E%AF%E5%A2%83%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><a href="https://www.bbsmax.com/A/ZOJPRymxdv/" target="_blank" rel="noopener">参考文章</a></p>
<ol>
<li>下载<a href="https://sourceforge.net/projects/sox/" target="_blank" rel="noopener">sox-14.4.1.tar.gz</a></li>
</ol>
<p>🌟（不能简单通过pip install 来安装）</p>
<ol start="2">
<li>安装sox文件</li>
</ol>
<p>　　1）解压　　tar -zxvf sox-14.4.1.tar.gz</p>
<p>　　2）进入sox14.4.1目录中执行./configure</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./configure --prefix=/ssd3/other/huangsj/sox_install</span><br><span class="line"><span class="meta">#</span><span class="bash"> 加上prefix，在自定义目录安装，不然机器环境太乱，会找不到</span></span><br></pre></td></tr></table></figure>

<p>　　3）执行 make命令</p>
<p>　　4）执行make install命令</p>
<ol start="3">
<li>添加环境变量</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim ~/.bash_profile</span><br><span class="line"></span><br><span class="line">export PATH=/ssd3/other/huangsj/sox_install/bin:$PATH</span><br><span class="line"></span><br><span class="line">source ~/.bash_profile</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>ok，再来运行一下 librispeech  ./run.sh</li>
</ol>
<hr>
]]></content>
      <categories>
        <category>-[kaldi]</category>
      </categories>
      <tags>
        <tag>-[Sox] -[kaldi]</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch —— tensor 乘法的笔记</title>
    <url>/2020/12/11/Pytorch%20%E2%80%94%E2%80%94%20tensor%20%E4%B9%98%E6%B3%95%E7%9A%84%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="Pytorch-——-tensor-乘法的笔记"><a href="#Pytorch-——-tensor-乘法的笔记" class="headerlink" title="Pytorch —— tensor 乘法的笔记"></a>Pytorch —— tensor 乘法的笔记</h2><hr>
<p>参考链接：</p>
<ul>
<li><p><a href="https://blog.csdn.net/zjhao666/article/details/97756377" target="_blank" rel="noopener">一个关于pytorch的tensor点乘的小问题</a></p>
</li>
<li><p><a href="https://blog.csdn.net/qq_36704378/article/details/108173371" target="_blank" rel="noopener">torch.Tensor的4种乘法</a></p>
</li>
<li><p><a href="https://blog.csdn.net/sinat_35907936/article/details/105329984" target="_blank" rel="noopener">Pytorch张量操作（包括torch.stack()理解、广播(broadcastable)的理解）</a></p>
</li>
<li><p>🌟<a href="https://pytorch.org/docs/stable/torch.html?highlight=mul#torch.mul" target="_blank" rel="noopener">官方链接</a></p>
</li>
</ul>
<hr>
]]></content>
  </entry>
  <entry>
    <title>《Voice Conversion with transformer network-samsung》论文总结</title>
    <url>/2020/06/14/Voice%20Conversion%20with%20transformer%20network-samsung%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>![image-20200617224333150](./Voice Conversion with transformer network-samsung论文总结/image-20200617224333150.png)</p>
<hr>
<a id="more"></a>

<h1 id="特点："><a href="#特点：" class="headerlink" title="特点："></a>特点：</h1><ol>
<li>应用场景是： 一对一、平行数据</li>
<li>不需要文本辅助</li>
<li>适用的场景，类似于小爱同学，用于在已有的预训练的 <strong>TTS</strong> 语音合成系统，实现音色转换。</li>
<li>技术上，以 LSTM-RNN 作为 base line 。</li>
<li>实现上，动用了 <strong>Transformer Architecture &amp;&amp; Context Preservation and Model Adaptation in an Attentional Seq2seq VC.</strong></li>
<li>闪光点：训练速度快了 2.72 倍（每个 step） &amp;&amp; 流畅度、相似度 比 base line 好一点</li>
</ol>
<hr>
<h1 id="注意点："><a href="#注意点：" class="headerlink" title="注意点："></a>注意点：</h1><ol>
<li>提到了一篇 2017 年的 <strong>VC 综述文章</strong>，之前没见到过，再过一遍；</li>
<li>![image-20200617225134062](./Voice Conversion with transformer network-samsung论文总结/image-20200617225134062.png)</li>
</ol>
<hr>
<h1 id="模型："><a href="#模型：" class="headerlink" title="模型："></a>模型：</h1><p>![image-20200617231000814](./Voice Conversion with transformer network-samsung论文总结/image-20200617231000814.png)</p>
<hr>
<ol>
<li>介绍了一些 Attention 和 Transformer 相关背景信息，以及在语音场景的常见应用</li>
<li>本文 用 Transformer 来进行 基于 sp 特征的 句到句的 音色转换</li>
</ol>
<hr>
<h1 id="三个Loss"><a href="#三个Loss" class="headerlink" title="三个Loss"></a>三个Loss</h1><ol>
<li>类似Transformer 的Loss</li>
<li>额外的：在Transformer 上进行的 MultiHead 数目的调整（以此加快训练速度）</li>
<li>![image-20200621184615655](/Users/huangshengjie/Library/Application Support/typora-user-images/image-20200621184615655.png)</li>
<li>目标真实 &amp; 转换出来的目标</li>
<li>![image-20200621184636954](/Users/huangshengjie/Library/Application Support/typora-user-images/image-20200621184636954.png)</li>
<li>Attention 的损失（Guided attention）：</li>
<li>![image-20200621184700921](/Users/huangshengjie/Library/Application Support/typora-user-images/image-20200621184700921.png)</li>
<li>内容保存程度 损失： source 和 恢复预测的 source  &amp;&amp; target 和恢复预测的 target </li>
</ol>
<hr>
<h1 id="学到的："><a href="#学到的：" class="headerlink" title="学到的："></a>学到的：</h1><ul>
<li><strong>消融实验</strong>：更换单一变量：观察指标是 <strong>固定训练步数，以 正确转换的语句数目 作为衡量指标</strong></li>
</ul>
<hr>
<h1 id="另一篇"><a href="#另一篇" class="headerlink" title="另一篇"></a>另一篇</h1><p><strong>（未看完）</strong></p>
<p>![image-20200621182450382](/Users/huangshengjie/Library/Application Support/typora-user-images/image-20200621182450382.png)</p>
<ul>
<li>谈到 WaveNet 的自适应改进，对她不够熟悉</li>
<li></li>
<li>另外看招聘需求大都是要做<strong>合成</strong>的，<strong>转换</strong>没有需求；</li>
<li>所以 花点时间 跑了一下 Tacotron（源码后端是用griff-Lim），花时间 再弄懂一下代码</li>
<li>接下来再弄懂一下 <strong>r9y9</strong> 的 <strong>WaveNET</strong> 代码</li>
</ul>
<hr>
]]></content>
      <categories>
        <category>论文阅读笔记</category>
        <category>test</category>
      </categories>
      <tags>
        <tag>VC</tag>
        <tag>论文阅读笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo一些基础指令备忘</title>
    <url>/2020/06/16/hexo%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%8C%87%E4%BB%A4%E5%A4%87%E5%BF%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="1-创建文章"><a href="#1-创建文章" class="headerlink" title="1. 创建文章"></a>1. 创建文章</h2><ul>
<li><h4 id="在hexo下创建一个新的文章"><a href="#在hexo下创建一个新的文章" class="headerlink" title="在hexo下创建一个新的文章"></a>在hexo下创建一个新的文章</h4></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo new &quot;文章名称&quot;</span><br></pre></td></tr></table></figure>

<h2 id="2-创建标签"><a href="#2-创建标签" class="headerlink" title="2. 创建标签"></a>2. 创建标签</h2><ul>
<li>创建分类页面</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo new page categories</span><br></pre></td></tr></table></figure>

<ul>
<li>基本设置</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">title: tags</span><br><span class="line">date: </span><br><span class="line">type: &quot;tags&quot;</span><br></pre></td></tr></table></figure>

<h2 id="3-创建分类"><a href="#3-创建分类" class="headerlink" title="3.创建分类"></a>3.创建分类</h2><ul>
<li>创建分类页面</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo new page categories</span><br></pre></td></tr></table></figure>

<ul>
<li>基本设置</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">title: categories</span><br><span class="line">date: </span><br><span class="line">type: &quot;categories&quot;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2020/06/07/hello-world/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>1103——WaveNet &amp; 机器学习 考点小结</title>
    <url>/2020/11/03/WaveNet%E5%B0%8F%E7%BB%93/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="WaveNet小结"><a href="#WaveNet小结" class="headerlink" title="WaveNet小结"></a>WaveNet小结</h2><a id="more"></a>

<ol>
<li><h4 id="WaveNet-一种语音合成的模型-https-www-pianshen-com-article-43431455160-image-20201016164508908-https-blog-1301959139-cos-ap-beijing-myqcloud-com-picGo-20201016164510-png"><a href="#WaveNet-一种语音合成的模型-https-www-pianshen-com-article-43431455160-image-20201016164508908-https-blog-1301959139-cos-ap-beijing-myqcloud-com-picGo-20201016164510-png" class="headerlink" title="WaveNet:一种语音合成的模型 https://www.pianshen.com/article/43431455160/![image-20201016164508908](https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201016164510.png)"></a>WaveNet:一种语音合成的模型 <a href="https://www.pianshen.com/article/43431455160/![image-20201016164508908](https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201016164510.png)" target="_blank" rel="noopener">https://www.pianshen.com/article/43431455160/![image-20201016164508908](https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201016164510.png)</a></h4></li>
<li><h3 id="WaveNet，一种端到端的语音合成模型https-zhuanlan-zhihu-com-p-51359150"><a href="#WaveNet，一种端到端的语音合成模型https-zhuanlan-zhihu-com-p-51359150" class="headerlink" title="WaveNet，一种端到端的语音合成模型https://zhuanlan.zhihu.com/p/51359150"></a>WaveNet，一种端到端的语音合成模型<img src="/2020/11/03/WaveNet%E5%B0%8F%E7%BB%93/huangshengjie/Documents/2020/%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99hexo%E6%B5%8B%E8%AF%95/Typora%E5%8D%9A%E5%AE%A2%E5%9B%BE%E7%89%87%E6%96%87%E4%BB%B6%E5%A4%B9/20201016164427.png" alt="image-20201016164426034"><a href="https://zhuanlan.zhihu.com/p/51359150" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/51359150</a></h3></li>
</ol>
<hr>
<h3 id="预测："><a href="#预测：" class="headerlink" title="预测："></a>预测：</h3><ol>
<li><p>机器学习各种 Loss 总结：</p>
<ol>
<li><a href="https://blog.csdn.net/perfect1t/article/details/88199179" target="_blank" rel="noopener">https://blog.csdn.net/perfect1t/article/details/88199179</a></li>
<li><a href="https://www.cnblogs.com/guoyaohua/p/9217206.html" target="_blank" rel="noopener">https://www.cnblogs.com/guoyaohua/p/9217206.html</a></li>
<li><a href="https://www.cnblogs.com/lliuye/p/9549881.html" target="_blank" rel="noopener">https://www.cnblogs.com/lliuye/p/9549881.html</a></li>
</ol>
</li>
<li><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201016181353.png" alt="image-20201016181352142"></p>
</li>
<li><p><img src="/2020/11/03/WaveNet%E5%B0%8F%E7%BB%93/huangshengjie/Documents/2020/%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99hexo%E6%B5%8B%E8%AF%95/Typora%E5%8D%9A%E5%AE%A2%E5%9B%BE%E7%89%87%E6%96%87%E4%BB%B6%E5%A4%B9/image-20201019005049252.png" alt="image-20201019005049252"><a href="https://zhuanlan.zhihu.com/p/74874291" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/74874291</a></p>
</li>
<li><p>常见优化算法及其优缺点：</p>
<ol>
<li><p><a href="https://blog.csdn.net/qq_19446965/article/details/81591521" target="_blank" rel="noopener">https://blog.csdn.net/qq_19446965/article/details/81591521</a> </p>
</li>
<li><p><a href="http://www.julyedu.com/question/big/kp_id/23/ques_id/1524![image-20201016181800596](https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201016181802.png)![image-20201016181557363](https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201016181558.png)" target="_blank" rel="noopener">http://www.julyedu.com/question/big/kp_id/23/ques_id/1524![image-20201016181800596](https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201016181802.png)![image-20201016181557363](https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201016181558.png)</a></p>
</li>
<li><h3 id="深度学习中优化方法——momentum、Nesterov-Momentum、AdaGrad、Adadelta、RMSprop、Adam"><a href="#深度学习中优化方法——momentum、Nesterov-Momentum、AdaGrad、Adadelta、RMSprop、Adam" class="headerlink" title="深度学习中优化方法——momentum、Nesterov Momentum、AdaGrad、Adadelta、RMSprop、Adam"></a>深度学习中优化方法——momentum、Nesterov Momentum、AdaGrad、Adadelta、RMSprop、Adam</h3><ol>
<li><h3 id="https-blog-csdn-net-u012328159-article-details-80311892-image-20201019162755198-Users-huangshengjie-Documents-2020-个人网站hexo测试-Typora博客图片文件夹-20201019162757-png"><a href="#https-blog-csdn-net-u012328159-article-details-80311892-image-20201019162755198-Users-huangshengjie-Documents-2020-个人网站hexo测试-Typora博客图片文件夹-20201019162757-png" class="headerlink" title="https://blog.csdn.net/u012328159/article/details/80311892![image-20201019162755198](/Users/huangshengjie/Documents/2020/个人网站hexo测试/Typora博客图片文件夹/20201019162757.png)"></a><a href="https://blog.csdn.net/u012328159/article/details/80311892![image-20201019162755198](/Users/huangshengjie/Documents/2020/个人网站hexo测试/Typora博客图片文件夹/20201019162757.png)" target="_blank" rel="noopener">https://blog.csdn.net/u012328159/article/details/80311892![image-20201019162755198](/Users/huangshengjie/Documents/2020/个人网站hexo测试/Typora博客图片文件夹/20201019162757.png)</a></h3></li>
<li><p><a href="https://blog.csdn.net/u012328159/article/details/80252012![image-20201019162915626](https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201019162916.png)" target="_blank" rel="noopener">https://blog.csdn.net/u012328159/article/details/80252012![image-20201019162915626](https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201019162916.png)</a></p>
</li>
<li><p><a href="https://www.cnblogs.com/yangmang/p/7477802.html![image-20201019165031144](https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201019165036.png)" target="_blank" rel="noopener">https://www.cnblogs.com/yangmang/p/7477802.html![image-20201019165031144](https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201019165036.png)</a></p>
</li>
</ol>
</li>
</ol>
</li>
<li><p>常用激活函数：<a href="https://zhuanlan.zhihu.com/p/32610035![image-20201016224701337](/Users/huangshengjie/Documents/2020/个人网站hexo测试/Typora博客图片文件夹/20201016224703.png)" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32610035![image-20201016224701337](/Users/huangshengjie/Documents/2020/个人网站hexo测试/Typora博客图片文件夹/20201016224703.png)</a></p>
</li>
<li><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201016224719.jpg" alt="img"></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/73214810![image-20201016224906446](https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201016224907.png)" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/73214810![image-20201016224906446](https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201016224907.png)</a></p>
</li>
<li><p><a href="https://www.cnblogs.com/itmorn/p/11132494.html![image-20201019170355380](https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201019170356.png)" target="_blank" rel="noopener">https://www.cnblogs.com/itmorn/p/11132494.html![image-20201019170355380](https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201019170356.png)</a></p>
</li>
<li><p><a href="https://www.cnblogs.com/itmorn/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%A2%98/default.html?page=2![image-20201019170708536](https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201019170710.png)" target="_blank" rel="noopener">https://www.cnblogs.com/itmorn/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%A2%98/default.html?page=2![image-20201019170708536](https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201019170710.png)</a></p>
</li>
</ol>
<hr>
<ol>
<li><h6 id="A率13折线PCM编码的C语言实现-https-blog-csdn-net-u010480899-article-details-51172633-image-20201017001812322-Users-huangshengjie-Documents-2020-个人网站hexo测试-Typora博客图片文件夹-20201017001813-png"><a href="#A率13折线PCM编码的C语言实现-https-blog-csdn-net-u010480899-article-details-51172633-image-20201017001812322-Users-huangshengjie-Documents-2020-个人网站hexo测试-Typora博客图片文件夹-20201017001813-png" class="headerlink" title="A率13折线PCM编码的C语言实现 https://blog.csdn.net/u010480899/article/details/51172633![image-20201017001812322](/Users/huangshengjie/Documents/2020/个人网站hexo测试/Typora博客图片文件夹/20201017001813.png)"></a>A率13折线PCM编码的C语言实现 <a href="https://blog.csdn.net/u010480899/article/details/51172633![image-20201017001812322](/Users/huangshengjie/Documents/2020/个人网站hexo测试/Typora博客图片文件夹/20201017001813.png)" target="_blank" rel="noopener">https://blog.csdn.net/u010480899/article/details/51172633![image-20201017001812322](/Users/huangshengjie/Documents/2020/个人网站hexo测试/Typora博客图片文件夹/20201017001813.png)</a></h6></li>
<li><p><a href="https://blog.csdn.net/u012323667/article/details/79214336?utm_medium=distribute.pc_relevant_download.none-task-blog-blogcommendfrombaidu-1.nonecase&amp;depth_1-utm_source=distribute.pc_relevant_download.none-task-blog-blogcommendfrombaidu-1.nonecas![image-20201017003241394](https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201017003242.png)" target="_blank" rel="noopener">https://blog.csdn.net/u012323667/article/details/79214336?utm_medium=distribute.pc_relevant_download.none-task-blog-blogcommendfrombaidu-1.nonecase&amp;depth_1-utm_source=distribute.pc_relevant_download.none-task-blog-blogcommendfrombaidu-1.nonecas![image-20201017003241394](https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201017003242.png)</a></p>
</li>
<li><p>!                              <a href="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201017003854.png" target="_blank" rel="noopener">image-20201017003852920</a><a href="https://wenku.baidu.com/view/725f75bf1a37f111f1855b3c.html#![image-20201017003821332](https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201017003822.png)" target="_blank" rel="noopener">https://wenku.baidu.com/view/725f75bf1a37f111f1855b3c.html#![image-20201017003821332](https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201017003822.png)</a></p>
</li>
</ol>
<p><strong>1</strong></p>
]]></content>
      <categories>
        <category>语音</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>语音合成</tag>
      </tags>
  </entry>
  <entry>
    <title>ppg-ac &amp; Deep-Voice操作手册</title>
    <url>/2020/11/29/ppg-ac%20&amp;%20Deep-Voice%E6%93%8D%E4%BD%9C%E6%89%8B%E5%86%8C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES&#x3D;0 python generate_synthesis.py --ppg2mel_model &#x2F;ssd3&#x2F;other&#x2F;huangsj&#x2F;fac-via-ppg&#x2F;interspeech19-stage&#x2F;ppg2speech-si-am-si-tacotron-bdl2ykwk-final&#x2F;tacotron_checkpoint_11000 --waveglow_model &#x2F;ssd3&#x2F;other&#x2F;huangsj&#x2F;fac-via-ppg&#x2F;interspeech19-stage&#x2F;ppg2speech-si-am-si-tacotron-bdl2ykwk-final&#x2F;waveglow_270000 --teacher_utterance_path &#x2F;ssd3&#x2F;other&#x2F;huangsj&#x2F;fac-via-ppg&#x2F;teacher_data&#x2F;YKWK --output_dir &#x2F;ssd3&#x2F;other&#x2F;huangsj&#x2F;fac-via-ppg&#x2F;output</span><br></pre></td></tr></table></figure>





<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES&#x3D;0 python generate_synthesis.py --ppg2mel_model &#x2F;ssd3&#x2F;other&#x2F;huangsj&#x2F;fac-via-ppg&#x2F;interspeech19-stage&#x2F;ppg2speech-si-am-si-tacotron-bdl2ykwk-final&#x2F;tacotron_checkpoint_11000 --waveglow_model &#x2F;ssd3&#x2F;other&#x2F;huangsj&#x2F;fac-via-ppg&#x2F;interspeech19-stage&#x2F;ppg2speech-si-am-si-tacotron-bdl2ykwk-final&#x2F;waveglow_270000 --teacher_utterance_path &#x2F;ssd3&#x2F;other&#x2F;huangsj&#x2F;fac-via-ppg&#x2F;teacher_data --output_dir &#x2F;ssd3&#x2F;other&#x2F;huangsj&#x2F;fac-via-ppg&#x2F;output</span><br></pre></td></tr></table></figure>

<p>teacher_data/YKWK</p>
<hr>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export PYTHONPATH&#x3D;&#x2F;ssd3&#x2F;other&#x2F;huangsj&#x2F;fac-via-ppg&#x2F;src:$PYTHONPATH</span><br><span class="line"></span><br><span class="line">--teacher_utterance_path  : 输入的是待矫正的语音</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES&#x3D;1 python generate_synthesis.py --ppg2mel_model &#x2F;ssd3&#x2F;other&#x2F;huangsj&#x2F;fac-via-ppg&#x2F;interspeech19-stage&#x2F;ppg2speech-si-am-si-tacotron-bdl2ykwk-final&#x2F;tacotron_checkpoint_11000 --waveglow_model &#x2F;ssd3&#x2F;other&#x2F;huangsj&#x2F;fac-via-ppg&#x2F;interspeech19-stage&#x2F;ppg2speech-si-am-si-tacotron-bdl2ykwk-final&#x2F;waveglow_270000 --teacher_utterance_path &#x2F;ssd3&#x2F;other&#x2F;huangsj&#x2F;fac-via-ppg&#x2F;teacher_data&#x2F;YKWK&#x2F;0023.wav --output_dir &#x2F;ssd3&#x2F;other&#x2F;huangsj&#x2F;fac-via-ppg&#x2F;output</span><br></pre></td></tr></table></figure>

<p> <a href="../fsdownload/韩式0001.wav">韩式0001.wav</a> </p>
<p> <a href="../fsdownload/美式0001.wav">美式0001.wav</a> </p>
<p> <a href="../fsdownload/韩式转美式.wav">韩式转美式.wav</a> </p>
<hr>
<h1 id="Deep-Voice-Conversion训练手册"><a href="#Deep-Voice-Conversion训练手册" class="headerlink" title="Deep-Voice-Conversion训练手册"></a><a href="https://github.com/andabi/deep-voice-conversion/issues/115" target="_blank" rel="noopener">Deep-Voice-Conversion训练手册</a></h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python train1.py timit -gpu 0</span><br></pre></td></tr></table></figure>



<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python train2.py timit -gpu 0</span><br></pre></td></tr></table></figure>







<p><a href="https://github.com/andabi/deep-voice-conversion/issues/39#issuecomment-476074396" target="_blank" rel="noopener">链接1</a></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201205192750.png" alt="image-20201205192749348"></p>
<p><a href="https://github.com/andabi/deep-voice-conversion/issues/93" target="_blank" rel="noopener">链接2</a></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201205192845.png" alt="image-20201205192844846"></p>
<p><a href="https://github.com/andabi/deep-voice-conversion/issues/115" target="_blank" rel="noopener">链接3</a></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201205193002.png" alt="image-20201205193001370"></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20201205193103.png" alt="image-20201205193102248"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 为了更通用，写了个代码来转换文件格式：</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">BASE = <span class="string">"/Users/huangshengjie/Desktop/TEST/"</span>   <span class="comment"># 所有文件的根目录</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(BASE):</span><br><span class="line">    <span class="keyword">if</span> len(files) &gt; <span class="number">0</span>:  <span class="comment"># 如果此目录有文件</span></span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> files:   <span class="comment"># 遍历此目录下的每一个文件</span></span><br><span class="line">            <span class="keyword">if</span> file.find(<span class="string">".WAV"</span>) != <span class="number">-1</span>:   <span class="comment"># 如果文件名中包含c2字样</span></span><br><span class="line">                new_file = file.replace(<span class="string">".WAV"</span>, <span class="string">".wav"</span>)  <span class="comment"># 则将其改成c1</span></span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    os.chdir(root)   <span class="comment"># 修改之前将当前工作目录切换到文件所在目录，否则os.rename会失败</span></span><br><span class="line">                    os.rename(file, new_file)  <span class="comment"># 调用操作系统的重命名功能</span></span><br><span class="line">                <span class="keyword">except</span> OSError <span class="keyword">as</span> e:</span><br><span class="line">                    <span class="keyword">print</span> (e)</span><br><span class="line">                    quit(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

]]></content>
  </entry>
  <entry>
    <title>test</title>
    <url>/2020/06/07/test/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>ceshi</p>
<p>插入html链接</p>
<p><a href="https://blog-1301959139.cos.ap-beijing.myqcloud.com/2020/%E5%8D%9A%E5%AE%A2/061421180327/061421180327.html" target="_blank" rel="noopener">https://blog-1301959139.cos.ap-beijing.myqcloud.com/2020/%E5%8D%9A%E5%AE%A2/061421180327/061421180327.html</a></p>
<p>用iframe插入html链接</p>
<iframe width="86%" height="460" scrolling="auto" frameborder="0" src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/2020/%E5%8D%9A%E5%AE%A2/061421180327/061421180327.html"></iframe>



<p>插入mp3:</p>
<p>1.aplayer</p>

			<script>
				console.error("Error: [hexo-tag-aplayer] Unrecognized tag argument(2): autoplay=false");
			</script>

<p>2.文件直接拖拽，本地存储</p>
<p> <a href="./30003.wav">30003.wav</a> </p>
<p>3.aplayer不稳定，还是应该用iframe标签</p>

			<script>
				console.error("Error: [hexo-tag-aplayer] Unrecognized tag argument(2): autoplay=false");
			</script>

<hr>
<p>4.aplayer meeting，产生歌单，用网易云的连接id</p>

    <div id="aplayer-LYXbqsPP" class="aplayer aplayer-tag-marker meting-tag-marker" data-id="523845661" data-server="netease" data-type="playlist" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#FF4081"></div>



<hr>
<p>5.用iframe插入</p>
<iframe frameborder="yes" border="1" marginwidth="100" marginheight="100" width="600" height="100" src="http://qbjun0qc6.bkt.clouddn.com/30001.wav">
</iframe>

<p>插入pdf</p>
<a id="more"></a>

<p>插入腾讯云pdf测试：</p>
<div class="pdfobject-container" data-target="https://blog-1301959139.cos.ap-beijing.myqcloud.com/2020/%E5%8D%9A%E5%AE%A2/VC%E8%AE%BA%E6%96%87202005.pdf" data-height="500px"></div>



<p>用iframe插入：</p>
<iframe width="86%" height="460" scrolling="auto" frameborder="0" src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/2020/%E5%8D%9A%E5%AE%A2/VC%E8%AE%BA%E6%96%87202005.pdf"></iframe>



<p>本地路径插入：pdf ./vc.pdf</p>
<div class="pdfobject-container" data-target="./vc.pdf" data-height="500px"></div>





<p>谷歌网址外链插入</p>
<div class="pdfobject-container" data-target="https://drive.google.com/file/d/0B6qSwdwPxPRdTEliX0dhQ2JfUEU/preview" data-height="500px"></div>



<p><img src="/2020/06/07/test/1.png" alt="1"></p>
<iframe frameborder="yes" border="1" marginwidth="1" marginheight="1" width="330" height="100" src="//music.163.com/outchain/player?type=2&id=444267925 & auto=1 & height=60 "></iframe>

<p><img src="https://s1.ax1x.com/2020/06/07/t2bJ56.png" alt="t2bJ56.png"></p>
<p><img src="/2020/06/07/test/stargan/StarGAN-VC2_files/network.png" alt="stargan.png"></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">iframe</span> <span class="attr">frameborder</span>=<span class="string">"no"</span> <span class="attr">border</span>=<span class="string">"0"</span> <span class="attr">marginwidth</span>=<span class="string">"0"</span> <span class="attr">marginheight</span>=<span class="string">"0"</span> <span class="attr">width</span>=<span class="string">330</span> <span class="attr">height</span>=<span class="string">86</span> <span class="attr">src</span>=<span class="string">"//music.163.com/outchain/player?type=3&amp;id=2066166810&amp;auto=1&amp;height=66"</span>&gt;</span><span class="tag">&lt;/<span class="name">iframe</span>&gt;</span></span><br></pre></td></tr></table></figure>


			<script>
				console.error("Error: [hexo-tag-aplayer] Specified asset file not found (picture.jpg)");
			</script>


			<script>
				console.error("Error: [hexo-tag-aplayer] Specified asset file not found ([picture_url,)");
			</script>

]]></content>
      <tags>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title>《EFFECTIVE WAVENET ADAPTATION FOR VOICE CONVERSION WITH LIMITED DATA》</title>
    <url>/2020/06/27/%E3%80%8AEFFECTIVE%20WAVENET%20ADAPTATION%20FOR%20VOICE%20CONVERSION%20WITH%20LIMITED%20DATA%E3%80%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200627153546.png" alt="image-20200627153541122"></p>
<a id="more"></a>

<h1 id="1-模型"><a href="#1-模型" class="headerlink" title="1.模型"></a>1.模型</h1><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200627153718.png" alt="image-20200627153716639"></p>
<hr>
<h1 id="2-模型特点-amp-amp-训练需求"><a href="#2-模型特点-amp-amp-训练需求" class="headerlink" title="2.模型特点 &amp;&amp; 训练需求"></a>2.模型特点 &amp;&amp; 训练需求</h1><ul>
<li>大数据集 + 少数据集（target）、many-to-many（没强调）</li>
<li>不采用“独立模型”的思路（e.g.不根据性别来分组训练），而是先用 多说话人的大量数据集，训练 <strong>Speaker Independent (SI) WaveNet model</strong></li>
<li>再用 少量<strong>Target Speaker</strong>数据进行微调；</li>
<li>（和上一篇 三星论文 思路有点像，但三星侧重转换模型（引入MultiHead Attention），他的 <strong>WaveNet</strong> 就用现成的；</li>
<li>本文则 侧重后端声码器 <strong>WaveNet</strong> 的优化：<strong>速度</strong> 和 <strong>质量</strong>）</li>
</ul>
<hr>
<h1 id="3-改进-WaveNet-的思路"><a href="#3-改进-WaveNet-的思路" class="headerlink" title="3.改进 WaveNet 的思路"></a>3.改进 WaveNet 的思路</h1><ul>
<li><strong>phonetic posteriorgram (PPG)</strong> （<strong>音素后验概率</strong>）和 语音波形（时域信号） 直接映射（本来呢？）</li>
<li><strong>🌟singular value decomposition (SVD)</strong>（<strong>奇异值分解</strong>）：减少 WaveNet 的训练参数量（<strong>重点</strong>）</li>
<li><strong>between PPGs and the corresponding time-domain speech signals of the same speaker.</strong>：模型的预训练，是在同一个说话人的 <strong>PPG</strong> 特征 和对应的 <strong>时域信号</strong> 之间进行训练；</li>
<li></li>
</ul>
<hr>
<h1 id="4-关于PPG-amp-amp-SVD"><a href="#4-关于PPG-amp-amp-SVD" class="headerlink" title="4.关于PPG &amp;&amp; SVD"></a>4.关于PPG &amp;&amp; SVD</h1><ul>
<li><del>PPG 有一个其他人自己写的 python 包，但是没有正规的开源工具包，很多论文都直接说用到了这个特征，却从没交代怎么提取，从哪来的。【<strong>请教老师</strong>】</del></li>
<li><strong>在Deep VC项目里面的 Train1.py 部分，出来的就是语音的 PPG</strong>，（它是想预先训一个ASR模型）</li>
<li>或者用Kaldi来求；</li>
<li>本质都是，训练一个 <strong>phonetic recognition system.</strong>，然后用这个识别网络去识别（过程和识别出MFCC特征很像）；<strong>怎么 VC 领域又给牵扯到 ASR 领域去了，四不像</strong></li>
</ul>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200627162338.png" alt="image-20200627162336086"></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200627175055.png" alt="image-20200627174816852"></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200627175051.png" alt="image-20200627175049966"></p>
<hr>
<h1 id="5-其他"><a href="#5-其他" class="headerlink" title="5.其他"></a>5.其他</h1><h2 id="这类模型：-原本的转换流程："><a href="#这类模型：-原本的转换流程：" class="headerlink" title="* 这类模型： 原本的转换流程："></a>* 这类模型： 原本的转换流程：</h2><h3 id="一句话——-gt-PPG特征不是直接合成出语音，而要经过转换；"><a href="#一句话——-gt-PPG特征不是直接合成出语音，而要经过转换；" class="headerlink" title="* 一句话——&gt;PPG特征不是直接合成出语音，而要经过转换；"></a>* 一句话——&gt;PPG特征不是直接合成出语音，而要经过转换；</h3><ol>
<li>从 .wav 中提取 <strong>source</strong> 的 PPG 特征（自注：需要额外训练一个声学模型，用来提取PPG）</li>
<li>用 “提前用大量 多说话人数据集 训练的” <strong>SI</strong> <strong>Conversion</strong> <strong>Model</strong>， 将 PPG 特征转化成 声学特征（<strong>mel ？</strong>）</li>
<li>再将 前一步骤的声学特征，扔进 <strong>经过（用 Target 语音）适应性调整的 WavaNet 声码器</strong>，以此合成最终转换语音；</li>
</ol>
<hr>
<h2 id="本文改进的转换流程："><a href="#本文改进的转换流程：" class="headerlink" title="*本文改进的转换流程："></a>*本文改进的转换流程：</h2><h3 id="特征转换模型-和-语音生成模型-是分开训练的；"><a href="#特征转换模型-和-语音生成模型-是分开训练的；" class="headerlink" title="* 特征转换模型 和 语音生成模型 是分开训练的；"></a>* 特征转换模型 和 语音生成模型 是分开训练的；</h3><h3 id="但是训练完之后，在转换步骤里，它利用（PPG）作为-本地条件-直接生成🌟时域语音信号"><a href="#但是训练完之后，在转换步骤里，它利用（PPG）作为-本地条件-直接生成🌟时域语音信号" class="headerlink" title="* 但是训练完之后，在转换步骤里，它利用（PPG）作为 本地条件 直接生成🌟时域语音信号"></a>* 但是训练完之后，在转换步骤里，它利用（PPG）作为 本地条件 <strong>直接生成🌟时域语音信号</strong></h3><p>即：输入 source 语音（提取特征后）给WaveNet 模型，然后WaveNet<strong>直接转换出来</strong> Target 语音；</p>
<ol>
<li><strong>SI</strong> WaveNet Conversion Model 的训练（用多说话人大数据量训练）(其实就是让WaveNet学会根据给定特征，<strong>重建出语音波形</strong>，模型的输入就是大量独立的语音，从而实现：让模型学会 <strong>与说话人无关的波形重建能力</strong>)</li>
<li>上述模型的适应性调整 <strong>adaption</strong>（基于target语料）</li>
<li><strong>run-time conversion</strong></li>
</ol>
<p>具体的，结合图片：</p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200627194348.png" alt="image-20200627194342790"></p>
<h2 id="在第一步中："><a href="#在第一步中：" class="headerlink" title="在第一步中："></a>在第一步中：</h2><p>五个特征【<strong>PPG、Energy、F0、V/UV、BAP</strong>】（BAP 待查）</p>
<ol>
<li><p>为了训练说话人无关的 SI WaveNet Conversion Model，先从多说话人的数据集中，读取 <strong>PPG</strong> 特征（另外训练的声学特征提取模型），用来表征 <strong>说话内容</strong></p>
</li>
<li><p><strong>Energy</strong> 用的是 <strong>梅尔倒谱</strong> 的<strong>第一维度</strong>用来表征 能量轮廓（这和我们说的 mel-cepstral 用来代表<strong>频谱图的轮廓信息</strong> 相联系）</p>
<p><img src="/2020/06/27/%E3%80%8AEFFECTIVE%20WAVENET%20ADAPTATION%20FOR%20VOICE%20CONVERSION%20WITH%20LIMITED%20DATA%E3%80%8B/huangshengjie/Documents/2020/%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99hexo%E6%B5%8B%E8%AF%95/Typora%E5%8D%9A%E5%AE%A2%E5%9B%BE%E7%89%87%E6%96%87%E4%BB%B6%E5%A4%B9/20200627195116.png" alt="image-20200627195114177"></p>
</li>
<li><p><strong>F0</strong> 取 log 对树</p>
</li>
<li><p><strong>V/UV</strong> 用来表示 发声/不发声 的一个标志（实现的话，我想可以用 f0 来判断当前帧 有没有人声；只有发声了，f0 才大于 0 ）</p>
</li>
<li><p><strong>BAPs</strong> ：还没查，指向一篇 06 年日本的文章，说法是，这个特征对语音波形的 <strong>重建</strong> 很有帮助</p>
</li>
</ol>
<p>这五个特征，concate 到一起，输入 SI WaveNet Conv Model 训练；</p>
<hr>
<h2 id="步骤二"><a href="#步骤二" class="headerlink" title="步骤二"></a>步骤二</h2><ul>
<li>用少量的 Target 内容语音，重复上述过程；</li>
<li>作用就是在前述的 SI 模型中，添加一点 SD（依赖于当前的 Target Speaker）</li>
</ul>
<hr>
<h2 id="步骤三："><a href="#步骤三：" class="headerlink" title="步骤三："></a>步骤三：</h2><p>具体转换实现时：</p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200627201313.png" alt="image-20200627201311810"></p>
<ul>
<li>转换时，输入source语音；</li>
<li>提取该source语音的五个特征；</li>
<li>对其中的 $logf0$ 做微调：其中 $\mu$ 表示均值，$\sigma$ 表示方差，$logf0_y$ 表示转换好的Target $ logf0 $</li>
<li>上述$logf0_y$和其他四个 source 的特征，一起送入第二步微调完的模型，做转换；</li>
<li>完事了；</li>
</ul>
<h2 id="以上是整体的优化方案；"><a href="#以上是整体的优化方案；" class="headerlink" title="以上是整体的优化方案；"></a>以上是整体的优化方案；</h2><h2 id="以下还有一点：对-SI-WaveNet-结构本身再做调整："><a href="#以下还有一点：对-SI-WaveNet-结构本身再做调整：" class="headerlink" title="以下还有一点：对 SI WaveNet 结构本身再做调整："></a>以下还有一点：对 SI WaveNet 结构本身再做调整：</h2><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200627204424.png" alt="image-20200627204422535"></p>
<ul>
<li><p>在 2019 也是这群人，发了一篇关于 WaveNet 内部结构改造：</p>
<ul>
<li><strong>data-efﬁcient SD WaveNet vocoder</strong></li>
</ul>
</li>
<li><p>本文则对上面的改造再做优化： <strong>SD</strong> 改造为 <strong>SVD</strong>（singular value decomposition）<strong>奇异值分解</strong></p>
</li>
<li><p>以期降低复杂度，减少训练参数</p>
</li>
<li><p>具体实现上：</p>
</li>
<li><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200627204710.png" alt="image-20200627204708474"></p>
</li>
<li><p><strong>：</strong>在 每一个 <strong>扩展卷积层</strong> 后面，再加一个 <strong>1 x 1</strong> 的卷积层；</p>
</li>
<li><p>说是这样就能显著减少 <strong>模型参数量</strong>；</p>
</li>
<li><p>——&gt;训练时间减少，效果还和19年的文章效果差不多；</p>
</li>
</ul>
<p><strong>Ps</strong>.（TF 当中倒是有一个单独的 SVD 工具，但是应该是针对更具体的计算公式的，和这里的 在WaveNet 模型内部优化方法不太一样？不确定？）</p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200627230800.png" alt="image-20200627230757346"></p>
<hr>
<h1 id="6-杂项整理"><a href="#6-杂项整理" class="headerlink" title="6.杂项整理"></a>6.杂项整理</h1><ul>
<li>数据集：VC的常规数据集两个：CMU-ARCTIC  &amp;&amp;  <strong>CSTR-VCTK</strong>（跑过torch版stargan了：109人，44 h，每人三百条左右语音，都是平行数据；两个大类：16K &amp; 48K；另外还配有文本，还可以用作合成数据）</li>
<li>本文把 VCTK 全拿来训练 SI WaveNet 了；</li>
<li>转换步骤，用的 ARCTIC 数据集；</li>
<li>其他一些实现细节：</li>
<li><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200627212421.png" alt="image-20200627212417782"></li>
<li>其他需要的作为对比的 <strong>Baseline</strong> 模型的构建参数给了挺多；不展开了；<ul>
<li>• AMA-WORLD:</li>
<li>• AMA-WaveNet:</li>
<li>• WaveNet-adp:</li>
<li>•WaveNet-SVD-adp:【本文提出的】</li>
</ul>
</li>
</ul>
<h2 id="新增一个-主观评价指标"><a href="#新增一个-主观评价指标" class="headerlink" title="* 新增一个 主观评价指标"></a>* 新增一个 主观评价指标</h2><h3 id="AB-and-XAB-测试：【A-B】中选一个-【不选-A-B】-三个中选一个"><a href="#AB-and-XAB-测试：【A-B】中选一个-【不选-A-B】-三个中选一个" class="headerlink" title="AB and XAB 测试：【A/B】中选一个 / 【不选/A/B】 三个中选一个"></a>AB and XAB 测试：【A/B】中选一个 / 【不选/A/B】 三个中选一个</h3><ul>
<li>multiple stimuli with hidden reference and anchor (<strong>MUSHRA</strong>)</li>
<li>“主观评估中间声音质量的方法”</li>
<li>–：让听众在两者之间选择一个更优秀的结果；置信区间取 95%</li>
<li></li>
</ul>
<h2 id="新增一个-Objective-evaluation-客观评价指标"><a href="#新增一个-Objective-evaluation-客观评价指标" class="headerlink" title="* 新增一个 Objective evaluation 客观评价指标"></a>* 新增一个 Objective evaluation 客观评价指标</h2><ul>
<li><p><strong>RMSE</strong>（root mean squared error）：均方根误差；【单位（dB）】</p>
</li>
<li><p>：evaluate distortion between the target and converted speech.</p>
</li>
<li><p>原理和 MCD 差不多；MCD 评测的是经过 DTW 的语音 Mel 谱特征；</p>
</li>
<li><p>🌟<a href="https://www.w3cschool.cn/tensorflow_python/tensorflow_python-15ev2z8o.html" target="_blank" rel="noopener"><strong>Tensorflow 有对应的 API</strong></a>：</p>
</li>
<li><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200627225534.png" alt="image-20200627225531701"></p>
</li>
<li><p>RMSE 他在这里处理的对象比较细致：</p>
</li>
<li><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200627213700.png" alt="image-20200627213656629"></p>
</li>
<li><h2 id="疑问："><a href="#疑问：" class="headerlink" title="疑问："></a>疑问：</h2></li>
</ul>
<ol>
<li><strong>frequency bin</strong>：频率槽；这个参数的 <strong>频率间隔</strong> 一般设置多少？</li>
</ol>
<ul>
<li>是按照 <strong>1HZ</strong> 来分隔吗？？？</li>
<li>【WORLD特征的帧长是 5ms（5ms frame shift）】</li>
</ul>
<ol start="2">
<li>这个 <strong>magnitude</strong> 值，是直接用 <strong>当前频率的 频谱图幅值</strong> 吗？</li>
</ol>
<h1 id="7-其他疑问点："><a href="#7-其他疑问点：" class="headerlink" title="7.其他疑问点："></a>7.其他疑问点：</h1><ul>
<li><ol>
<li><strong>The speech is encoded by 8 bits µ -law.</strong> ： 8 bits µ -law 是什么规范；</li>
</ol>
</li>
<li><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200627213249.png" alt="image-20200627213248518"></p>
</li>
<li><ol start="2">
<li><strong>PPG</strong> 的 <strong>具体构建网络</strong> 应该是怎么样的，有统一的代码模型吗。有点凌乱；</li>
</ol>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200627214950.png" alt="image-20200627214947808"></p>
</li>
<li></li>
</ul>
]]></content>
      <categories>
        <category>论文阅读笔记</category>
        <category>test</category>
      </categories>
      <tags>
        <tag>VC</tag>
        <tag>论文阅读笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>关于 WORLD 中 code_spectral_envelope 和 MFCC 关系的理解</title>
    <url>/2020/07/23/%E5%85%B3%E4%BA%8E%20WORLD%20%E4%B8%AD%20code_spectral_envelope%20%E5%92%8C%20MFCC%20%E5%85%B3%E7%B3%BB%E7%9A%84%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h1><ol>
<li><a href="https://github.com/mmorise/World/issues/90" target="_blank" rel="noopener">https://github.com/mmorise/World/issues/90</a> （有人提问 WORLD 提取得到的 mel spectrum 梅尔谱和传统概念上 经过一系列stft之后还要经过“三角滤波器组”的过程区别？）</li>
<li><a href="https://github.com/mmorise/World/issues/33" target="_blank" rel="noopener">https://github.com/mmorise/World/issues/33</a> （r9y9 在<a href="https://github.com/mmorise" target="_blank" rel="noopener">mmorise</a>/<strong><a href="https://github.com/mmorise/World" target="_blank" rel="noopener">World</a></strong> 下提问关于 编码/解码后音色变化问题；代码bug已解决；学习一下画图和使用特点）</li>
</ol>
<hr>
<a id="more"></a>

<h1 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h1><ol>
<li><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200723190241.png" alt="image-20200723190240435"></p>
</li>
<li><p>简言之，传统论文  <a href="https://www.sp.nitech.ac.jp/~tokuda/selected_pub/pdf/conference/tokuda_icslp1994.pdf" target="_blank" rel="noopener">Mel-cepstral analysis</a> 提到的方法，也就是正常思路的经过 FFT 后再经过三角滤波器组 得到的 mel 谱，之所以需要三角滤波，可以理解为是，因为MFCC是在 <strong>频谱图</strong> 上进行的操作，所以是未经过 <strong>平滑</strong> 操作的，所以需要滤波器；</p>
</li>
<li><p>而WORLD，是在频谱包络上进行的操作，本身已经是顺滑过的，所以得到的 sp 特征，看似流程上没有三角滤波，但是它在使用的时候，效果和SPTK、librosa、merlin之类工具得到的 MFCC 来处理的音频效果是差不多的。</p>
</li>
<li><p>所以，就可以理解，很多论文的实现上，作者们在遇到：MFCC 这个特征需要时，若非论文着重强调，是可以用 <strong>code_spectral_envelope</strong> ，并取维度参数为 36 等，来表示36维度（bin）的MFCC特征的。</p>
</li>
</ol>
<hr>
<p>以上，解决了一直没人能帮我说清楚的问题疑惑。</p>
<p>还是要多看看源码和 issue，和大佬们交流才进步的多。</p>
<hr>
<p>这行里，可能大佬很多，但是能真正带领小白入门的系统专家真的少。sigh。我可能适合做老师，喜欢把大家难懂的东西，娓娓道来，教会孩子们。😁</p>
]]></content>
      <categories>
        <category>-[语音]</category>
      </categories>
      <tags>
        <tag>语音</tag>
      </tags>
  </entry>
  <entry>
    <title>《《ONE-SHOT VOICE CONVERSION USING STAR-GAN》》论文总结</title>
    <url>/2020/07/14/%E3%80%8AONE-SHOT%20VOICE%20CONVERSION%20USING%20STAR-GAN%E3%80%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200712160845.png" alt="image-20200712160843097"></p>
<a id="more"></a>

<ol>
<li><h2 id="解决的问题："><a href="#解决的问题：" class="headerlink" title="解决的问题："></a>解决的问题：</h2><ol>
<li>在原本的StarGan-VC中，实现了“<strong>未知speaker：source/target 都未知</strong>”的转换。称作“<strong>One-Shot</strong>”</li>
<li>其他文章其实也有做过类似功能：基于“<strong>超大数据集的  VC 模型</strong>”做自适应adaption调整：比如之前谢磊团队那篇 <strong>对WaveNet的改进模型</strong>，在处理未知说话人时，采用的是 额外20到50条数据的进一步收敛；</li>
</ol>
</li>
<li><h2 id="采用的主要方法："><a href="#采用的主要方法：" class="headerlink" title="采用的主要方法："></a>采用的主要方法：</h2><ol>
<li>把说话人信息看作 embedding。</li>
<li>但是不同于原本 StarGan-VC 代码实现中（非官方）用 One-Hot来做embedding。</li>
<li>也不是用的后来咱们讨论中，改用 embedding_lookup（）的方式（虽然已经比One-Hot concate 方式要好很多了）</li>
<li>而是采用2018年google的一篇文章，提取embedding的单独网络；（<strong>Global Style Token (GST)</strong>），用这个网络提取出来的embedding信息，可以表征说话人身份信息。</li>
<li>具体细节接下来说：</li>
</ol>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200712162828.png" alt="image-20200712162827085"></p>
</li>
<li><h2 id="有价值的细节："><a href="#有价值的细节：" class="headerlink" title="有价值的细节："></a>有价值的细节：</h2><ol>
<li>这个GST 训练时，先有一堆说话人，每个人有很多数据（1⃣️）；</li>
<li>然后这个网络的功能就是：能把一个新来的 集合外数据（人/内容），扔进去，照样得到一个 speaker_embedding 信息；</li>
<li>这个embedding信息怎么来的呢？原来是由模型（1⃣️）训练集中的说话人embedding 融合出来的；所以最终的效果上，会是：新说话人声音特征，由训练集说话人特征组合而成；</li>
<li>这个GST当中， speaker ID 实现上，同样采用 one-hot 形式。</li>
</ol>
</li>
</ol>
<ol start="4">
<li><h2 id="以上三点，其实都只是前人的工作，本文拿来创新性应用。"><a href="#以上三点，其实都只是前人的工作，本文拿来创新性应用。" class="headerlink" title="以上三点，其实都只是前人的工作，本文拿来创新性应用。"></a>以上三点，其实都只是前人的工作，本文拿来创新性应用。</h2><ol>
<li>本文的细节创新：</li>
</ol>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200712164238.png" alt="image-20200712164236074"></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200712164302.png" alt="image-20200712164301003"></p>
<ol>
<li>原本的 StarGan-VC 中，在Generator部分 的BottelNect部分，采用正常的 【Conv，Norm，GLU】结构，其中的Conv采用 <strong>5 个channel</strong>；</li>
<li>本文作者实验证明，这个 5 channel 太小了，影响了 reconstruction 音频质量；</li>
<li>但是尝试放大这个channel数，会发现有“<strong>信息泄露：information leakage</strong>”，有点像信号处理中的“<strong>频率泄漏：frequency leak</strong>”（后者采用加窗的方式规避这个问题）；</li>
<li>所谓的泄漏，就是出现了无关的信息：Generator 没能把source中的身份信息过滤干净，最后的声音四不像；（频率泄漏则是，在没加窗函数之前，做FFT会出现 本没有的 频率）<img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200712165144.png" alt="image-20200712165142509"></li>
<li>最后的效果上：<img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200712165232.png" alt="image-20200712165230066"></li>
<li>作者说，用了这种方式（SoftMax 代替 conv-2d 做 BottleNeck），在转换结果上，<strong>共振峰频率</strong>（<strong>frequencies of formants</strong>）会低一点：显示在能量图上，就是高频部分（上面）颜色会浅一点。</li>
<li><strong>🌟疑问点</strong>：这个 <strong>共振峰频率</strong> 低一点，<strong>能说明什么</strong>？？？？这样就能说明 说话内容信息泄漏会少一点吗？没搞懂；</li>
</ol>
</li>
</ol>
<h2 id="5-另一个操作改进点："><a href="#5-另一个操作改进点：" class="headerlink" title="5.  另一个操作改进点："></a>5.  另一个操作改进点：</h2><ol>
<li><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200712172438.png" alt="image-20200712172437528"></p>
</li>
<li><p>在Generator的修改上如图：</p>
</li>
<li><p>对比原型：<img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200712171700.png" alt="image-20200712171657257"></p>
</li>
<li><p>小细节：</p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200713175103.png" alt="image-20200713175101061"></p>
<ul>
<li><p>偶数：同时更新 D &amp;&amp; G</p>
</li>
<li><p>奇数：只更新 D</p>
</li>
<li><p>特征选用上：由实验经验，<strong>由36维 MFCC</strong> 改为用 <strong>96维 sp 谱包络（96-bin Mel spectral envelope）</strong></p>
</li>
<li><p>（这个和合成的应用上也有呼应， Mel 的训练合成，比MFCC reconstrruction 效果要好，更深原理 <strong>模糊</strong>）</p>
</li>
</ul>
</li>
</ol>
<h2 id="6-结果上："><a href="#6-结果上：" class="headerlink" title="6. 结果上："></a>6. 结果上：</h2><p>其实就是 VC 领域两个主观评价指标：Reconstruction 质量 和 Conversion 质量。</p>
<ol>
<li>这份Demo里，Reconstruction 的效果也不怎么好，在Conversion 转换效果上还凑合；这个和StarGan-VC 差不多；</li>
<li>Reconstruction 上，target 已知或 “增量式训练”过，数据效果上，提升不少；Conversion 效果也大差不差；<img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200712181558.png" alt="image-20200712181557111"></li>
</ol>
<h2 id="7-VC改进思路小结："><a href="#7-VC改进思路小结：" class="headerlink" title="7. VC改进思路小结："></a>7. VC改进思路小结：</h2><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200713132212.png" alt="image-20200713132210312"></p>
<ul>
<li>在想能否写<strong>WorkShop</strong>论文</li>
<li>不知还有什么可改进的点，咱们可以接<strong>上WaveNet后端</strong>，类似谢磊上篇用的；</li>
<li>然后<strong>重构损失</strong>上，模型结构学习一下网易这篇。</li>
<li><strong>embedding</strong> 上，为的是实现 <strong>one-shot</strong>，再考虑是否有其他方法；</li>
</ul>
]]></content>
      <categories>
        <category>论文阅读笔记</category>
      </categories>
      <tags>
        <tag>VC</tag>
        <tag>论文阅读笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>关于pyworld.load 读取音频和soundfile.read 差别</title>
    <url>/2020/07/29/%E5%85%B3%E4%BA%8Epyworld.load%20%E8%AF%BB%E5%8F%96%E9%9F%B3%E9%A2%91%E5%92%8Csoundfile.read%20%E5%B7%AE%E5%88%AB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><a id="more"></a>

<h1 id="问题："><a href="#问题：" class="headerlink" title="问题："></a>问题：</h1><p>在pyworld使用前，一般需要读取音频文件：</p>
<ul>
<li><p>librosa.load() 默认得到的是float32类型的数据，所以一般会再跟上 x.astype(np.float64)</p>
<ul>
<li>而恰恰是这么一个Numpy类型转换，会导致得到的 ap 特征中会含有 Nan 数据，这会导致最终的计算出现不必要的偏差；</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(<span class="string">f"ap <span class="subst">&#123;np.isnan(ap).any()&#125;</span>"</span>)  <span class="comment"># 返回True</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#统计nan个数</span></span><br><span class="line">t = ap</span><br><span class="line">t = t[np.isnan(t)]  <span class="comment"># 用切片法 + 条件限制，来得到 nan 值的切片</span></span><br><span class="line"><span class="comment"># t = t[np.where(np.isnan(t))]</span></span><br><span class="line">print(t.shape)  <span class="comment"># （4k+, ）</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>（这个问题和怎么计算得到ap无关：尝试了 world.wav2worl（）和 pyworld.harvest + cheaptrick + d4c路径，结果都一样）</p>
</li>
<li><p>Soundfile.read()  # 默认的数据返回值是 float64，所以可以直接得到所要求的数据格式</p>
</li>
<li><p>其中，对应的函数参数调整：sr 变为 samplerate ， mono 的单通道 改用 channels=1</p>
</li>
</ul>
<h2 id="Ps-附上代码和-issue网址"><a href="#Ps-附上代码和-issue网址" class="headerlink" title="Ps.附上代码和 issue网址"></a>Ps.附上代码和 issue网址</h2><p>[issue][<a href="https://github.com/JeremyCCHsu/Python-Wrapper-for-World-Vocoder/issues/50]" target="_blank" rel="noopener">https://github.com/JeremyCCHsu/Python-Wrapper-for-World-Vocoder/issues/50]</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pyworld <span class="keyword">as</span> world</span><br><span class="line"><span class="keyword">import</span> pyworld</span><br><span class="line"><span class="keyword">import</span> librosa</span><br><span class="line"><span class="keyword">import</span> librosa.display</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> soundfile</span><br><span class="line"></span><br><span class="line"><span class="comment"># wav,fs = librosa.load(os.getcwd()+"/bed (537).wav")</span></span><br><span class="line">wav, fs = soundfile.read(os.getcwd()+<span class="string">"/bed (537).wav"</span>)</span><br><span class="line"><span class="comment"># wav = wav.astype(np.float64)</span></span><br><span class="line"><span class="comment"># print(wav[0].type)  # 'numpy.float64' object has no attribute 'type'</span></span><br><span class="line">frame_period = <span class="number">5.0</span></span><br><span class="line">hop_length = int(fs * frame_period * <span class="number">0.001</span>)</span><br><span class="line">fftlen = world.get_cheaptrick_fft_size(fs)</span><br><span class="line"></span><br><span class="line">f0, timeaxis = pyworld.harvest(wav, fs, frame_period=frame_period, f0_floor=<span class="number">71.0</span>, f0_ceil=<span class="number">800.0</span>)</span><br><span class="line">sp = pyworld.cheaptrick(wav, f0, timeaxis, fs)</span><br><span class="line">ap = pyworld.d4c(wav, f0, timeaxis, fs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># f0, sp, ap = world.wav2world(x,sr,fftlen,frame_period)</span></span><br><span class="line">print(ap.shape)</span><br><span class="line">print(<span class="string">f"ap <span class="subst">&#123;np.isnan(ap).any()&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line">wav = pyworld.synthesize(f0, sp, ap, fs, frame_period)</span><br><span class="line"><span class="comment"># wav = wav.astype(np.float32)</span></span><br><span class="line">soundfile.write(<span class="string">'test.wav'</span>, wav, fs)</span><br><span class="line"></span><br><span class="line">x, sr = soundfile.read(os.getcwd()+<span class="string">"/bed (537).wav"</span>)</span><br><span class="line"><span class="comment"># print(x[0].type)  # 'numpy.float64' object has no attribute 'type'</span></span><br><span class="line">f01, timeaxis1 = pyworld.harvest(x, sr, frame_period=frame_period, f0_floor=<span class="number">71.0</span>, f0_ceil=<span class="number">800.0</span>)</span><br><span class="line">sp1 = pyworld.cheaptrick(x, f01, timeaxis1, fs)</span><br><span class="line">ap1 = pyworld.d4c(x, f01, timeaxis1, fs)</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">以上这样，直接用soundfile 读取成float64 数据，</span></span><br><span class="line"><span class="string">然后再直接用 soundfile.write 保存float64的文件 或者是 先转化成float32 再保存成文件， </span></span><br><span class="line"><span class="string">保存出来的文件再次用soundfile 读取出来，</span></span><br><span class="line"><span class="string">再次用测试ap是否有 nan值，都没有问题。</span></span><br><span class="line"><span class="string">综上，能用soundfile就避免用librosa，读取和写入文件都是这个道理；ßå</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'************'</span>)</span><br><span class="line">print(ap1.shape)</span><br><span class="line">print(<span class="string">f"ap1 <span class="subst">&#123;np.isnan(ap1).any()&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">f"ap <span class="subst">&#123;np.isnan(ap).any()&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># # print(np.isnan(ap))</span></span><br><span class="line"><span class="comment"># t = ap</span></span><br><span class="line"><span class="comment"># t = t[np.isnan(t)]</span></span><br><span class="line"><span class="comment"># # t = t[np.where(np.isnan(t))]</span></span><br><span class="line"><span class="comment"># print(t.shape)</span></span><br><span class="line"></span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> ap:</span><br><span class="line">    <span class="comment"># if np.isnan(x):</span></span><br><span class="line">    count = count+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">print(count)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> np.isnan(ap).any():</span><br><span class="line"></span><br><span class="line">    f0, sp, ap = world.wav2world(np.absolute(x),fs,fftlen,frame_period)</span><br><span class="line">    print(<span class="string">f"ap abs <span class="subst">&#123;np.isnan(ap).any()&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line">exit()</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>-[语音]</category>
      </categories>
      <tags>
        <tag>语音</tag>
      </tags>
  </entry>
  <entry>
    <title>关于ssh本地查看Tensorboard记录</title>
    <url>/2020/06/21/%E5%85%B3%E4%BA%8Essh%E6%9C%AC%E5%9C%B0%E6%9F%A5%E7%9C%8BTensorboard%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="1-需求：在本地查看Tensorboard"><a href="#1-需求：在本地查看Tensorboard" class="headerlink" title="1.需求：在本地查看Tensorboard"></a>1.需求：在本地查看Tensorboard</h1><ul>
<li><pre><code class="ssh">ssh -L 16006:127.0.0.1:6006 hsj@student.is99kdf.xyz -p 15203
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  * 作用：将远程的服务器**6006**端口转发到本地的 **16006**端口</span><br><span class="line"></span><br><span class="line">*</span><br></pre></td></tr></table></figure>
cd /home/sdb3/home/hsj/taco1_tf/tacotron
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  * 作用：进入所要运行的 logs 文件夹所在路径</span><br><span class="line"></span><br><span class="line">*</span><br></pre></td></tr></table></figure>
source activate py36
tensorboard --logdir ./logs-tacotron
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  * 开启有 Tensorboard 的环境</span><br><span class="line">  * 运行 ，打开logs文件</span><br><span class="line"></span><br><span class="line">*</span><br></pre></td></tr></table></figure>
本地浏览器打开 127.0.0.1:16006</code></pre>
<ul>
<li>成功实现本地查看 Tensorboard</li>
<li>再也不用像之前那样傻傻滴每次要手动下载 log 文件到本地之后才执行</li>
</ul>
</li>
</ul>
<hr>
<h1 id="2-待解决："><a href="#2-待解决：" class="headerlink" title="2.待解决："></a>2.待解决：</h1><ul>
<li>再进一步了解一下 Tensorboard 上方的各种功能：<ul>
<li>Distributions</li>
<li>Histograms</li>
<li>Projector ：这个很有意思啊，貌似是吧训练过程中数据点的变化，以动图的形式表现出来；</li>
</ul>
</li>
</ul>
<hr>
<h1 id="备注："><a href="#备注：" class="headerlink" title="备注："></a>备注：</h1><p>tensorflow 和 Numpy 对应关系：</p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200626183013.png" alt="image-20200626175304169"></p>
]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Tensorboard，Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title>散文诗</title>
    <url>/2020/06/16/%E6%95%A3%E6%96%87%E8%AF%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>
        <div id="aplayer-CQeMkWly" class="aplayer aplayer-tag-marker" style="margin-bottom: 20px;">
            <pre class="aplayer-lrc-content"></pre>
        </div>
        <script>
          var ap = new APlayer({
            element: document.getElementById("aplayer-CQeMkWly"),
            narrow: false,
            autoplay: false,
            showlrc: false,
            music: {
              title: "父亲写的散文诗",
              author: "许飞",
              url: "https://blog-1301959139.cos.ap-beijing.myqcloud.com/2020/%E5%8D%9A%E5%AE%A2/%E8%AE%B8%E9%A3%9E%20-%20%E7%88%B6%E4%BA%B2%E5%86%99%E7%9A%84%E6%95%A3%E6%96%87%E8%AF%97.flac",
              pic: "http://qbjun0qc6.bkt.clouddn.com/Stay%20with%20me%E4%BA%94%E7%BA%BF%E8%B0%B1",
              lrc: ""
            }
          });
          window.aplayers || (window.aplayers = []);
          window.aplayers.push(ap);
        </script>



<hr>
<p>不知怎么的，每次听这首歌都会泪目</p>
<a id="more"></a>

<p>\当下的社会环境很浊。我没觉得很乱，就是纯粹的很浊。只不过因为我个人的眼界原因，我有点看不清了。</p>
<p>28岁的ByteDance-郭宇，实现了财务自由，选择退休成为温泉旅行作家。</p>
<p>第一时间看到这个信息，我和所有人一样，着实感到震撼，并为之颤抖。想想自己，27才能硕士毕业，估计还要为 进入大厂 / 找份舒适工作 而发愁，缺有个同龄人完成了你的所有梦想。</p>
<p>和泽奇说的一样，当下要实现财务自由，只能想方设法拿到股权，通过分红的方式来获取财富。只单纯工作、打工的形式，是永远得不到想要的境界。</p>
<p>而普通人，能获得股份期权的途径，可能就是读博，技术入股。</p>
<hr>
<p>其实很多时候，发现自己的想法也并没有比别人有很多高明之处，往往我能想到的，大家都会明白，或早或晚。</p>
<p>最年少时，希冀能改变一点点世界。</p>
<p>后来，本科时期，觉得自己太太太普通，想做个普通人，安安稳稳，上了研，开始有意识地探索“铁饭碗”。</p>
<p>但是经过一段时间，尝试完全不投入学习，以自己能想象的最随意的方式生活，发觉有点讨厌。生活的细碎繁琐，还是会让我耳朵起茧子，心里起皱褶。尽管和同龄人相比，肯定是和父母相处的很融洽的了，但长时间相处，还是会发觉自己不逃习惯过度的关心。或者应该说，自己受宠若惊而有点烦，不喜欢被过度关怀，嘴上得花很多唾沫来拒绝别人的安排和说辞。</p>
<hr>
<p>类似这篇文章这样，比较随意地袒露自己心里想法的文字，我应该永远不会在所谓的“朋友圈”来表达，更不会通过公众号来写文章。</p>
<p>没必要。</p>
<p>所以我会觉得在自己的博客抒发情感会很舒适自然。</p>
<p>相比之前，wordpress繁琐、丑陋的后台文章写作环境，我太喜欢本地md编写，然后保存即可轻松推流的方式。</p>
<p>像之后尝试写写随笔杂文，以后有机会整理成册，发些书玩玩。</p>
<p>晚安</p>
<p>06/17/2020 凌晨</p>
<p>@PT</p>
<hr>
]]></content>
      <categories>
        <category>作家计划</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>关于深度学习中模型矢量图的绘制、剪裁、保存 小结</title>
    <url>/2020/06/14/%E5%85%B3%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E6%A8%A1%E5%9E%8B%E7%9F%A2%E9%87%8F%E5%9B%BE%E7%9A%84%E7%BB%98%E5%88%B6%E3%80%81%E5%89%AA%E8%A3%81%E3%80%81%E4%BF%9D%E5%AD%98-%E5%B0%8F%E7%BB%93/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="几个概念"><a href="#几个概念" class="headerlink" title="几个概念"></a>几个概念</h1><ol>
<li>矢量图（.EPS）格式，不会失真</li>
<li>参考文章<a href="https://www.zhihu.com/question/58540942" target="_blank" rel="noopener">知乎</a></li>
<li>需要的工具：<a href="https://www.macwk.com/soft/adobe-acrobat-pro-dc" target="_blank" rel="noopener">Adobe Acrobat Pro DC</a> &amp;&amp; <a href="https://www.macwk.com/article/adobe-zii" target="_blank" rel="noopener">Adobe Zii 激活工具</a></li>
</ol>
<hr>
<a id="more"></a>

<h2 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤"></a>操作步骤</h2><ol>
<li>将画好的 PPT 模板导出成 pdf 文件格式，用 DC 打开</li>
<li>搜索 DC 功能 <strong>裁剪</strong>，选定图像区域（去掉白边）</li>
<li>然后打开 DC 侧边栏，选取要到处的图片所在界面，<strong>右击</strong>，<strong>提取页面</strong>，<strong>输入要导出的界面</strong> <em>（这是为了在很庞大的所有ppt页面中，单独拎出需要的页面，方便下一步的导出为 .eps 格式而服务的）</em></li>
<li>保存这个由新选取的页面们所组成的新 PDF，然后点击：<strong>文件</strong>—&gt;<strong>另存为</strong>—&gt;<strong>内嵌式PostScript</strong> 格式</li>
<li>Duang！就这样完成了，尽情滴放大她，也不会失真啦！</li>
<li>Ps.如果是在 LaTex 写作中，插入图片时，可以直接选择使用 PDF 格式哦！就省去了转为 EPS 格式的过程（如果没有 DC 软件的话）</li>
</ol>
<hr>
<p>最后，本博客开始正式运营，相比于之前使用庞杂、臃肿的 WorldPress，我并不需要多么复杂的后台管理功能，能让我安心地在本地快快乐乐写文字输出就ok，还没有了租服务器的额外开销（汇率提升，我的钱包实在扛不住了，太贵了）</p>
<hr>
<ul>
<li>发现的一个小问题就是，插入pdf，在手机端没法查看，所以之后可以尝试用 html 形式专门做成一个界面栏目，像 VC 比赛 demo 界面那样。clone一下大神们的个人主页</li>
<li>或者再找找看 .md 格式怎么写一个漂亮的简历</li>
</ul>
<hr>
<h1 id="找到了！！！"><a href="#找到了！！！" class="headerlink" title="找到了！！！"></a>找到了！！！</h1><ul>
<li><a href="http://www.pdfdo.com/pdf-to-html.aspx" target="_blank" rel="noopener">pdf 转 html 文件格式</a></li>
<li>使用方法：导入 pdf 之后，转换，点击下载（千万别直接右键保存，那样不完整！）</li>
<li>然后本地 WebStorm 打开，在 body 标签体后面加一对 center 标签，就能全体文字 &amp; 图片居中啦！</li>
</ul>
<hr>
<ul>
<li>另一个<a href="https://www.aconvert.com/cn/pdf/" target="_blank" rel="noopener"><strong>大全能格式转换工具网站</strong></a></li>
<li>有一个致命缺点：转出来的 html 文件在 body 中间加入 center 之后，文字和图片会歪，很不理想，不知什么原因；</li>
</ul>
<ul>
<li><del><strong>原因找到了：</strong></del></li>
<li><del>这个网站没有直接提供下载功能，先点击压缩，然后选择下载压缩文件</del></li>
<li><del>千万别直接打开htm之后，直接右键保存，注意到直接保存的是 .htm 格式，不是 .html （这个在之前的侧边栏环节也遇到这个问题），查查什么区别。</del></li>
<li><del>这个网站下载的很慢，还是不如上面那个网站。</del></li>
<li>这个网站还是垃圾，下载了之后内部语法乱的一笔，只有单一的一个html文件，图片也不知道给👴整哪里去了，center 居中之后又是乱糟糟，别玩了，就用上面那个吧，太漂亮了！</li>
</ul>
<p>真的 OK 了，本文结束。</p>
<p>真的结束了#2</p>
<p>以上</p>
<p>June / 14 / 2020</p>
<p>@PT</p>
]]></content>
      <categories>
        <category>写作</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title>python 切片的一些混淆点（备忘）</title>
    <url>/2020/07/16/%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="1-经常混淆的py切片细节"><a href="#1-经常混淆的py切片细节" class="headerlink" title="1.经常混淆的py切片细节"></a>1.经常混淆的py切片细节</h2><a id="more"></a>

<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200716200314.png" alt="image-20200716200313100"></p>
<h1 id="python-中的-1-和-1"><a href="#python-中的-1-和-1" class="headerlink" title="python 中的 [:-1] 和 [::-1]"></a>python 中的 [:-1] 和 [::-1]</h1><ul>
<li><p><a href="https://www.runoob.com/note/51257" target="_blank" rel="noopener">https://www.runoob.com/note/51257</a></p>
</li>
<li><pre><code class="python">a=<span class="string">'python'</span>
b=a[::<span class="number">-1</span>]
print(b) <span class="comment">#nohtyp</span>
c=a[::<span class="number">-2</span>]
print(c) <span class="comment">#nhy</span>
<span class="comment">#从后往前数的话，最后一个位置为-1</span>
d=a[:<span class="number">-1</span>]  <span class="comment">#从位置0到位置-1之前的数</span>
print(d)  <span class="comment">#pytho</span>
e=a[:<span class="number">-2</span>]  <span class="comment">#从位置0到位置-2之前的数</span>
print(e)  <span class="comment">#pyth</span>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">* &#96;&#96;&#96;python</span><br><span class="line">  b &#x3D; a[i:j]   # 表示复制a[i]到a[j-1]，以生成新的list对象</span><br><span class="line">  </span><br><span class="line">  a &#x3D; [0,1,2,3,4,5,6,7,8,9]</span><br><span class="line">  b &#x3D; a[1:3]   # [1,2]</span><br><span class="line">  </span><br><span class="line">  # 当i缺省时，默认为0，即 a[:3]相当于 a[0:3]</span><br><span class="line">  # 当j缺省时，默认为len(alist), 即a[1:]相当于a[1:10]</span><br><span class="line">  # 当i,j都缺省时，a[:]就相当于完整复制一份a</span><br><span class="line">  </span><br><span class="line">  b &#x3D; a[i:j:s]    # 表示：i,j与上面的一样，但s表示步进，缺省为1.</span><br><span class="line">  # 所以a[i:j:1]相当于a[i:j]</span><br><span class="line">  </span><br><span class="line">  # 当s&lt;0时，i缺省时，默认为-1. j缺省时，默认为-len(a)-1</span><br><span class="line">  # 所以a[::-1]相当于 a[-1:-len(a)-1:-1]，也就是从最后一个元素到第一个元素复制一遍，即倒序。</span><br></pre></td></tr></table></figure>


</code></pre>
</li>
</ul>
<hr>
<h2 id="2-关于-torch-的pad：full模式（相对于tf中的same模式）"><a href="#2-关于-torch-的pad：full模式（相对于tf中的same模式）" class="headerlink" title="2.关于 torch 的pad：full模式（相对于tf中的same模式）"></a>2.关于 torch 的pad：full模式（相对于tf中的same模式）</h2><p>$$<br>              H_{out} = \left\lfloor\frac{H_{in}  + 2 \times \text{padding}[0] - \text{dilation}[0]<br>                        \times (\text{kernel_size}[0] - 1) - 1}{\text{stride}[0]} + 1\right\rfloor</p>
<pre><code>W_{out} = \left\lfloor\frac{W_{in}  + 2 \times \text{padding}[1] - \text{dilation}[1]
          \times (\text{kernel_size}[1] - 1) - 1}{\text{stride}[1]} + 1\right\rfloor</code></pre><p>$$</p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200801174740.png" alt="image-20200801174738560"></p>
<h2 id="相比tensorflow，PyTorch需要用户清楚的知道的自己的卷积核选取对结果的影响。"><a href="#相比tensorflow，PyTorch需要用户清楚的知道的自己的卷积核选取对结果的影响。" class="headerlink" title="相比tensorflow，PyTorch需要用户清楚的知道的自己的卷积核选取对结果的影响。"></a>相比tensorflow，PyTorch需要用户清楚的知道的自己的卷积核选取对结果的影响。</h2><ul>
<li><strong>简单一点</strong>：先只看 t = kernel【0】// 2；</li>
<li>Kernel【0】为奇数，那么padding就等于 t;</li>
<li>否则，kernel【0】为偶数，那么padding就等于 【t - 1】</li>
</ul>
<hr>
<h2 id="3-反卷积"><a href="#3-反卷积" class="headerlink" title="3.反卷积"></a>3.反卷积</h2><p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200801184750.png" alt="image-20200801184748828"></p>
<p><a href="https://blog.csdn.net/g11d111/article/details/82665265" target="_blank" rel="noopener">https://blog.csdn.net/g11d111/article/details/82665265</a></p>
<ul>
<li>反卷积这部分用的少，公式其实就是正卷积中，in 和 out 对调；</li>
<li>只不过 反卷积没有了 正卷积 中 的 <strong>向下取整</strong> 的操作</li>
<li>所以在反卷积中， 需要按规矩公式，简单计算一下padding 尺寸参数；</li>
<li>最简单就是用局部代码输出看一下结果，看是否符合输入输出尺寸要求</li>
</ul>
<hr>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200801193707.png" alt="image-20200801193706275"></p>
<p><a href="https://blog.csdn.net/m0_37586991/article/details/87855342" target="_blank" rel="noopener">https://blog.csdn.net/m0_37586991/article/details/87855342</a></p>
<p><img src="https://blog-1301959139.cos.ap-beijing.myqcloud.com/picGo/20200801194743.png" alt="image-20200801194739307"></p>
<hr>
]]></content>
      <categories>
        <category>-[python]</category>
      </categories>
      <tags>
        <tag>-[python] -[编程]</tag>
      </tags>
  </entry>
  <entry>
    <title>第一篇</title>
    <url>/2020/06/07/%E7%AC%AC%E4%B8%80%E7%AF%87/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
      <categories>
        <category>测试categories</category>
      </categories>
      <tags>
        <tag>测试tags</tag>
      </tags>
  </entry>
  <entry>
    <title>未上传-1122组会汇报</title>
    <url>/2020/11/22/%E6%9C%AA%E4%B8%8A%E4%BC%A0-1122%E7%BB%84%E4%BC%9A%E6%B1%87%E6%8A%A5/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="11-22组会"><a href="#11-22组会" class="headerlink" title="11.22组会"></a>11.22组会</h2><hr>
<ol>
<li>身体好多了，这两周都在校内休息</li>
<li>mentor让做 <strong>NER</strong>，没兴趣不想做，直接请一段时间假</li>
</ol>
<hr>
<ol>
<li>琢磨使用 <strong>Kaldi</strong> 来提取<strong>PPGs</strong>，先尝试了跑 demo Librispeech，遇到各种问题，还没全部跑通</li>
<li>NVAE256 官方给了一份 ckpt，可能是因为比较大，在做 Evaluete 的时候，load model 后就出现显存不足，后面再琢磨一下怎么载入</li>
<li>开题材料 <strong>修改完成</strong>了，还剩<strong>两张图</strong>还没重新画，明天搞定</li>
<li>AiShell3 环境配起来还有点问题，晚上再折腾一下</li>
</ol>
<ul>
<li>论文《Generative adversarial interpolative autoencoding》还没看完，争取这两天看完</li>
</ul>
<hr>
<ul>
<li>软著三个月</li>
<li>HDFS：存储音频视频 的数据库</li>
</ul>
<ul>
<li>PPT：少文字，多图</li>
<li></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>跑Kaldi-libspeech遇到的问题</title>
    <url>/2020/11/30/%E8%B7%91Kaldi-libspeech%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>run.pl: job failed, log is in exp/chain_cleaned/tdnn_1d_sp/log/train.0.3.log</p>
<p>kaldi cudaError_t 46 : “all CUDA-capable devices are busy or unavailable” returned from ‘cudaGetLastError()’</p>
<p><img src="/2020/11/30/%E8%B7%91Kaldi-libspeech%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/huangshengjie/Documents/2020/%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99hexo%E6%B5%8B%E8%AF%95/Typora%E5%8D%9A%E5%AE%A2%E5%9B%BE%E7%89%87%E6%96%87%E4%BB%B6%E5%A4%B9/image-20201130104204647.png" alt="image-20201130104204647"></p>
]]></content>
  </entry>
</search>
